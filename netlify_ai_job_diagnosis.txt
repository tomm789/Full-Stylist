

===== netlify/functions/ai-job-runner.js =====
"use strict";

// Main Netlify function for processing AI jobs. This handler
// authenticates the request using the Supabase JWT, retrieves the
// referenced job from the database and dispatches processing to the
// appropriate module based on the job type. Each job type is defined
// in a separate module under ./processes to improve modularity.

const { supabaseAdmin } = require("./supabaseClient");
const { createPerformanceTracker, createTimingTracker, downloadImageFromStorage } = require("./utils");
const { processAutoTag } = require("./processes/auto_tag");
const { processProductShot } = require("./processes/product_shot");
const { processHeadshotGenerate } = require("./processes/headshot_generate");
const { processBodyShotGenerate } = require("./processes/body_shot_generate");
const { processOutfitRender } = require("./processes/outfit_render");
const { processOutfitMannequin } = require("./processes/outfit_mannequin");
const { processOutfitSuggest } = require("./processes/outfit_suggest");
const { processReferenceMatch } = require("./processes/reference_match");

/**
 * Netlify function handler. Validates the HTTP method and the
 * Authorization header, retrieves the job from Supabase, and queues it
 * for asynchronous processing. Returns immediately with a 202 status.
 *
 * @param {object} event - The incoming request context
 * @param {object} context - The Lambda context provided by Netlify
 * @returns {Promise<object>} HTTP response object
 */
exports.handler = async (event, context) => {
  // Netlify runs all functions in a single Lambda; prevent waiting on
  // asynchronous tasks to finish before returning
  context.callbackWaitsForEmptyEventLoop = false;
  const headers = {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Headers": "Content-Type, Authorization",
    "Access-Control-Allow-Methods": "POST, OPTIONS",
    "Content-Type": "application/json"
  };
  // Handle CORS preflight
  if (event.httpMethod === "OPTIONS") {
    return { statusCode: 200, headers, body: "" };
  }
  if (event.httpMethod !== "POST") {
    return {
      statusCode: 405,
      headers,
      body: JSON.stringify({ error: "Method not allowed" })
    };
  }
  try {
    // Extract and verify JWT from Authorization header
    const authHeader = event.headers.authorization || event.headers.Authorization;
    if (!authHeader || !authHeader.startsWith("Bearer ")) {
      return {
        statusCode: 401,
        headers,
        body: JSON.stringify({ error: "Missing authorization header" })
      };
    }
    const token = authHeader.replace("Bearer ", "");
    const {
      data: { user },
      error: authError
    } = await supabaseAdmin.auth.getUser(token);
    if (authError || !user) {
      return {
        statusCode: 401,
        headers,
        body: JSON.stringify({ error: "Invalid token" })
      };
    }
    // Parse the job ID from the request body
    const body = JSON.parse(event.body || "{}");
    const { job_id } = body;
    if (!job_id) {
      return {
        statusCode: 400,
        headers,
        body: JSON.stringify({ error: "job_id is required" })
      };
    }
    // Retrieve the job record and verify ownership
    const { data: job, error: jobError } = await supabaseAdmin
      .from("ai_jobs")
      .select("*")
      .eq("id", job_id)
      .eq("owner_user_id", user.id)
      .single();
    if (jobError || !job) {
      return {
        statusCode: 404,
        headers,
        body: JSON.stringify({ error: "Job not found" })
      };
    }
    if (job.status === "running") {
      return {
        statusCode: 409,
        headers,
        body: JSON.stringify({ error: "Job already running" })
      };
    }
    // Update job status to running and queue asynchronous processing
    await supabaseAdmin
      .from("ai_jobs")
      .update({ status: "running", updated_at: new Date().toISOString() })
      .eq("id", job_id);
    processJobAsync(job, user.id).catch((err) => {
      console.error(`[AIJobRunner] Async processing error for ${job_id}:`, err);
    });
    return {
      statusCode: 202,
      headers,
      body: JSON.stringify({
        success: true,
        message: "Job queued for processing",
        job_id
      })
    };
  } catch (err) {
    console.error("Handler Critical Error:", err);
    return {
      statusCode: 500,
      headers,
      body: JSON.stringify({ error: err.message || "Internal server error" })
    };
  }
};

/**
 * Dispatches the job to the appropriate processor based on its type.
 * Catches errors and records them on the job record. On success,
 * updates the job record with the result. This function is run
 * asynchronously and does not block the HTTP response.
 *
 * @param {object} job - The job record from the database
 * @param {string} userId - ID of the job owner
 */
async function processJobAsync(job, userId) {
  const job_id = job.id;
  
  // Create performance tracker at the start of the request
  const perfTracker = createPerformanceTracker();
  console.log(`[AIJobRunner] Created performance tracker: ${perfTracker.requestId} for job ${job_id} (${job.job_type})`);
  
  // Create timing tracker for detailed step-by-step timing
  const timingTracker = createTimingTracker();
  timingTracker.startJob();
  console.log(`[AIJobRunner] Starting job ${job_id} (${job.job_type})`);
  
  let result;
  let error = null;
  try {
    const input = job.input;
    switch (job.job_type) {
      case "batch":
        result = await processBatchJob(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        throw new Error(`Unknown job type: ${job.job_type}`);
    }
  } catch (err) {
    error = err.message || "Unknown error";
    console.error(`[AIJobRunner] Error processing ${job.job_type} job ${job_id}:`, err);
  }
  
  // Log performance comparison at the end of the request
  perfTracker.logComparison();
  
  // Log detailed timing breakdown
  timingTracker.logBreakdown(job.job_type);
  
  // Build the update payload based on success or failure
  const updateData = {
    updated_at: new Date().toISOString(),
    status: error ? "failed" : "succeeded"
  };
  if (error) {
    updateData.error = error;
  } else {
    updateData.result = result;
  }
  await supabaseAdmin.from("ai_jobs").update(updateData).eq("id", job_id);
}

/**
 * Processes a batch job that runs multiple tasks on the same image in parallel.
 * Downloads the image once and passes it to all tasks to avoid redundant downloads.
 * 
 * Expected input format:
 * {
 *   imageId: string,
 *   tasks: ['product_shot', 'auto_tag'],
 *   wardrobe_item_id: string,
 *   image_ids: string[] (for auto_tag)
 * }
 * 
 * @param {object} input - Batch job input
 * @param {import('@supabase/supabase-js').SupabaseClient} supabase - Supabase client
 * @param {string} userId - ID of the job owner
 * @param {object} perfTracker - Performance tracker
 * @param {object} timingTracker - Timing tracker
 * @returns {Promise<object>} Combined results from all tasks
 */
async function processBatchJob(input, supabase, userId, perfTracker, timingTracker) {
  const { imageId, tasks, wardrobe_item_id, image_ids } = input;
  
  if (!imageId || !tasks || !Array.isArray(tasks) || tasks.length === 0) {
    throw new Error("Batch job requires imageId and tasks array");
  }
  
  if (!wardrobe_item_id) {
    throw new Error("Batch job requires wardrobe_item_id");
  }
  
  console.log(`[BatchJob] Starting batch processing for imageId: ${imageId}, tasks: ${tasks.join(', ')}`);
  
  // Download the image once to a buffer (returns { base64, mimeType } object)
  console.log(`[BatchJob] Downloading image once for shared use...`);
  const imageData = await downloadImageFromStorage(supabase, imageId, timingTracker);
  console.log(`[BatchJob] Image downloaded successfully, length: ${imageData.base64.length}, mimeType: ${imageData.mimeType}`);
  
  // Prepare inputs for both tasks
  const productShotInput = tasks.includes('product_shot') ? {
    image_id: imageId,
    wardrobe_item_id
  } : null;
  
  const autoTagInput = tasks.includes('auto_tag') ? {
    wardrobe_item_id,
    image_ids: image_ids || []
  } : null;
  
  // Validate auto_tag input if needed
  if (tasks.includes('auto_tag')) {
    if (!image_ids || !Array.isArray(image_ids) || image_ids.length === 0) {
      throw new Error("auto_tag task requires image_ids array");
    }
  }
  
  // CRITICAL: Create both promises in the SAME synchronous block - no awaits between them
  // This ensures both async functions start executing immediately and run in parallel
  const batchStart = performance.now();
  console.log(`[BatchJob] Creating both promises simultaneously (parallel execution starts now)...`);
  
  // Create promise array and start BOTH tasks immediately without any await
  const taskPromises = [];
  
  // Create product_shot promise - function starts executing immediately (no await)
  if (productShotInput) {
    console.log(`[BatchJob] Creating product_shot promise (execution starts immediately)...`);
    const productShotPromise = processProductShot(
      productShotInput, 
      supabase, 
      userId, 
      perfTracker, 
      timingTracker, 
      imageData
    ).then(result => {
      const elapsed = ((performance.now() - batchStart) / 1000).toFixed(2);
      console.log(`[BatchJob] product_shot completed in ${elapsed}s`);
      return { task: 'product_shot', result, error: null };
    }).catch(err => {
      const elapsed = ((performance.now() - batchStart) / 1000).toFixed(2);
      console.error(`[BatchJob] product_shot failed after ${elapsed}s:`, err.message);
      return { task: 'product_shot', result: null, error: err.message };
    });
    taskPromises.push(productShotPromise);
  }
  
  // Create auto_tag promise IMMEDIATELY after (no await) - both run in parallel
  if (autoTagInput) {
    console.log(`[BatchJob] Creating auto_tag promise (execution starts immediately, parallel with product_shot)...`);
    const autoTagPromise = processAutoTag(
      autoTagInput, 
      supabase, 
      perfTracker, 
      timingTracker, 
      imageData
    ).then(result => {
      const elapsed = ((performance.now() - batchStart) / 1000).toFixed(2);
      console.log(`[BatchJob] auto_tag completed in ${elapsed}s`);
      return { task: 'auto_tag', result, error: null };
    }).catch(err => {
      const elapsed = ((performance.now() - batchStart) / 1000).toFixed(2);
      console.error(`[BatchJob] auto_tag failed after ${elapsed}s:`, err.message);
      return { task: 'auto_tag', result: null, error: err.message };
    });
    taskPromises.push(autoTagPromise);
  }
  
  // Both promises are now created and executing in parallel
  // Only NOW do we await - Promise.all waits for BOTH to complete
  console.log(`[BatchJob] Both promises created. Awaiting ${taskPromises.length} promises with Promise.all() (both running in parallel)...`);
  const results = await Promise.all(taskPromises);
  
  // Capture end time after Promise.all() completes
  const batchEnd = performance.now();
  const batchDuration = ((batchEnd - batchStart) / 1000).toFixed(2);
  
  // Track the parallel execution time
  if (timingTracker && typeof timingTracker.setBatchAIGenerationTime === 'function') {
    timingTracker.setBatchAIGenerationTime(parseFloat(batchDuration) * 1000); // Convert to ms
  }
  
  console.log(`[BatchJob] All tasks completed in ${batchDuration}s (parallel execution - should be ~max of individual task times, not sum)`);
  
  // Organize results by task name
  const taskResults = {};
  for (const { task, result, error } of results) {
    if (error) {
      taskResults[task] = { error };
      console.error(`[BatchJob] Task ${task} failed:`, error);
    } else {
      taskResults[task] = result;
      console.log(`[BatchJob] Task ${task} completed successfully`);
    }
  }
  
  console.log(`[BatchJob] All tasks completed`);
  return taskResults;
}


===== netlify.toml =====
[build]
  command = "npx expo export --platform web --output-dir web-build"
  publish = "web-build"
  functions = "netlify/functions"

[dev]
  # Use static framework - we only need functions, not a dev server
  framework = "#static"
  # Netlify dev server port
  port = 8888
  # Functions directory
  functions = "netlify/functions"
  # Disable auto-launch of browser
  autoLaunch = false
  # Serve public directory for static files
  publish = "public"

[functions]
  # Ensure TypeScript functions are included and compiled
  node_bundler = "esbuild"
  included_files = ["netlify/functions/**/*.ts"]
  # Use external dependencies (Supabase, etc.) - don't bundle them
  external_node_modules = ["@supabase/supabase-js"]

# AI job runner needs extended timeout for image generation (60-90 seconds)
[functions."ai-job-runner"]
  timeout = 120

[[redirects]]
  from = "/*"
  to = "/index.html"
  status = 200

# Headers for PWA and caching
[[headers]]
  # HTML files - no cache to ensure updates work
  for = "/*.html"
  [headers.values]
    Cache-Control = "no-cache, no-store, must-revalidate"
    Pragma = "no-cache"
    Expires = "0"

[[headers]]
  # Service worker - no cache to ensure updates
  for = "/service-worker.js"
  [headers.values]
    Cache-Control = "no-cache, no-store, must-revalidate"
    Pragma = "no-cache"
    Expires = "0"

[[headers]]
  # Manifest - short cache
  for = "/manifest.webmanifest"
  [headers.values]
    Cache-Control = "public, max-age=3600"

[[headers]]
  # Static assets (hashed) - long cache
  for = "/_expo/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"

[[headers]]
  # Icons and images - medium cache
  for = "/icons/*"
  [headers.values]
    Cache-Control = "public, max-age=86400"

[[headers]]
  # Other static assets - long cache
  for = "/assets/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"



===== package.json =====
{
  "name": "full-stylist",
  "version": "3.1.0",
  "description": "AI styling app for creating virtual headshots and outfits",
  "scripts": {
    "start": "expo start",
    "android": "expo start --android",
    "ios": "expo start --ios",
    "web": "expo start --web",
    "dev": "netlify dev"
  },
  "keywords": [
    "ai",
    "styling",
    "fashion",
    "virtual-stylist"
  ],
  "author": "",
  "license": "MIT",
  "dependencies": {
    "@expo/metro-runtime": "^6.1.2",
    "@react-native-async-storage/async-storage": "^2.2.0",
    "@supabase/ssr": "^0.8.0",
    "@supabase/supabase-js": "^2.90.1",
    "@types/react": "~19.1.10",
    "browser-image-compression": "^2.0.2",
    "date-fns": "^4.1.0",
    "dotenv": "^17.2.3",
    "expo": "^54.0.31",
    "expo-constants": "~18.0.13",
    "expo-file-system": "^19.0.21",
    "expo-image": "~3.0.11",
    "expo-image-picker": "^17.0.10",
    "expo-linking": "~8.0.11",
    "expo-router": "^6.0.21",
    "react": "19.1.0",
    "react-dom": "19.1.0",
    "react-easy-crop": "^5.5.6",
    "react-native": "0.81.5",
    "react-native-gesture-handler": "~2.28.0",
    "react-native-reanimated": "~4.1.1",
    "react-native-safe-area-context": "~5.6.0",
    "react-native-screens": "~4.16.0",
    "react-native-url-polyfill": "^3.0.0",
    "react-native-web": "^0.21.2",
    "react-native-worklets": "0.5.1",
    "sharp": "^0.34.5",
    "typescript": "^5.9.3"
  },
  "devDependencies": {
    "@netlify/functions": "^5.1.2",
    "babel-plugin-module-resolver": "^5.0.2"
  }
}



===== SEARCH: async / await / Gemini =====

--- ./archive/generate.js ---
            // Text only response
        } else {
            generationConfig.response_modalities = ["IMAGE"];
        }

        // Call Google Gemini API
        const response = await fetch(
            `https://generativelanguage.googleapis.com/v1beta/models/${modelId}:generateContent?key=${apiKey}`,
            {
                method: 'POST',
                headers: {
        } else {
            generationConfig.response_modalities = ["IMAGE"];
        }

        // Call Google Gemini API
        const response = await fetch(
            `https://generativelanguage.googleapis.com/v1beta/models/${modelId}:generateContent?key=${apiKey}`,
            {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
            }
        );

        let data;
        try {
            data = await response.json();
        } catch (e) {
            console.error('Failed to parse Google API response as JSON:', await response.text());
            return {
                statusCode: 500,
                headers,

        let data;
        try {
            data = await response.json();
        } catch (e) {
            console.error('Failed to parse Google API response as JSON:', await response.text());
            return {
                statusCode: 500,
                headers,
                body: JSON.stringify({ error: 'Invalid response from Google API' }),
            };

--- ./archive/old-ui/public/js/app.js ---
   ---------------------------------------------------------------- */
async function logInteraction(actionType, details = {}) {
    if (!state.userName) return;
    
    try {
        await fetch('/.netlify/functions/log-session', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                userName: state.userName,
                action: actionType,
    const itemsNeedingColor = state.wardrobe.filter(item => !item.colorData);
    
    if (itemsNeedingColor.length > 0) {
        showLoading(true, "Analyzing colors...");
        Promise.all(itemsNeedingColor.map(async (item) => {
            item.colorData = await extractDominantColor(item.b64);
            return item;
        })).then(() => {
            showLoading(false);
            state.wardrobe.sort((a, b) => {
                const aColor = a.colorData || { h: 0, l: 0 };
    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) || 
                  (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
    
    try {
        // Fetch the image as a blob to ensure proper download on mobile
        const response = await fetch(src);
        const blob = await response.blob();
        
        // For iOS, use Share API if available, otherwise open in new tab
        if (isIOS && navigator.share) {
            const file = new File([blob], `full_stylist_${Date.now()}.png`, { type: 'image/png' });
                  (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
    
    try {
        // Fetch the image as a blob to ensure proper download on mobile
        const response = await fetch(src);
        const blob = await response.blob();
        
        // For iOS, use Share API if available, otherwise open in new tab
        if (isIOS && navigator.share) {
            const file = new File([blob], `full_stylist_${Date.now()}.png`, { type: 'image/png' });
            if (navigator.canShare && navigator.canShare({ files: [file] })) {
        
        // For iOS, use Share API if available, otherwise open in new tab
        if (isIOS && navigator.share) {
            const file = new File([blob], `full_stylist_${Date.now()}.png`, { type: 'image/png' });
            if (navigator.canShare && navigator.canShare({ files: [file] })) {
                await navigator.share({
                    files: [file],
                    title: 'Full Stylist Image',
                    text: 'Download image'
                });
                return;
   ONBOARDING LOGIC
   ---------------------------------------------------------------- */
async function processFile(file, previewId, stateKey) {
    if (!file) return;
    
    let b64 = await toBase64(file);
    // Resize large mobile photos to ensure stability
    b64 = await resizeImage(b64, 1280);
    
    if(stateKey === 'selfieBase64') state.rawSelfie = b64;
    if(stateKey === 'bodyBase64') state.rawBody = b64;
async function processFile(file, previewId, stateKey) {
    if (!file) return;
    
    let b64 = await toBase64(file);
    // Resize large mobile photos to ensure stability
    b64 = await resizeImage(b64, 1280);
    
    if(stateKey === 'selfieBase64') state.rawSelfie = b64;
    if(stateKey === 'bodyBase64') state.rawBody = b64;
    
    const img = document.getElementById(previewId);
    }
}

async function handleFile(input, previewId, stateKey) {
    if (input.files && input.files[0]) {
        await processFile(input.files[0], previewId, stateKey);
    }
}

function goToStep(step) {
    document.querySelectorAll('.step-card').forEach(el => el.classList.add('hidden'));
    MODIFICATIONS: ${hair}, ${makeup}.
    CRITICAL: Maintain the EXACT framing, zoom level, and head angle of Image 0.
    STYLE: Photorealistic, 8k, soft lighting, light grey/white background.`;

    try {
        const headB64 = await callGemini(headPrompt, [state.rawSelfie]);
        state.previewHeadshotB64 = headB64;
        state.previewHeadshotUrl = `data:image/png;base64,${headB64}`;
        document.getElementById('generated-headshot-preview').src = state.previewHeadshotUrl;
        goToStep(2);
    } catch(e) {
    REFINEMENT: Apply these changes: ${desc}.
    CRITICAL: Maintain the exact framing, zoom, and head angle of Image 0.
    STYLE: Photorealistic, 8k, soft lighting, light grey/white background.`;

    try {
        const headB64 = await callGemini(prompt, [state.previewHeadshotB64]);
        state.previewHeadshotB64 = headB64;
        state.previewHeadshotUrl = `data:image/png;base64,${headB64}`;
        document.getElementById('generated-headshot-preview').src = state.previewHeadshotUrl;
        document.getElementById('refine-headshot-desc').value = "";
    } catch (e) {
    if(!validateModelAccess()) return;
    
    showLoading(true, "Generating...", "loading-body-upload");

    try {
        const bodyB64 = await runBodyGeneration(state.previewHeadshotB64, state.rawBody);
        state.previewBodyB64 = bodyB64;
        state.previewBodyUrl = `data:image/png;base64,${bodyB64}`;
        document.getElementById('generated-body-preview').src = state.previewBodyUrl;
        goToStep(4);
    } catch(e) {
    3. Output a Full Body Vertical Portrait.
    `;

    try {
        const modelOverride = state.selectedModel === 'standard-plus' ? 'gemini-3-pro-image-preview' : null;
        const bodyB64 = await callGemini(prompt, [state.previewBodyB64], modelOverride);
        state.previewBodyB64 = bodyB64;
        state.previewBodyUrl = `data:image/png;base64,${bodyB64}`;
        document.getElementById('generated-body-preview').src = state.previewBodyUrl;
        document.getElementById('refine-body-desc').value = "";
    } catch (e) {
    3. INTEGRATION: Seamlessly blend Head (Img 0) onto Body (Img 1) matching lighting and skin tone.
    4. FRAMING: Maintain the exact framing of Image 1 (Full Body Vertical 3:4 or 9:16).
    5. NEGATIVE CONSTRAINT: Significantly decrease the size of the head and the length of the neck. Do not create a bobblehead effect. The neck must be proportional to the shoulders.
    `;
    const modelOverride = state.selectedModel === 'standard-plus' ? 'gemini-3-pro-image-preview' : null;
    return await callGemini(prompt, [headB64, referenceBodyB64], modelOverride);
}

/* ----------------------------------------------------------------
   DASHBOARD LOGIC
   ---------------------------------------------------------------- */
        SUBJECT: The person in Image 0.
        ${isRefining ? `REFINE: Apply these additional changes: ${h}, ${m}` : `CLOTHING: Wearing a simple white ribbed singlet (wife beater). MODIFICATIONS: ${h}, ${m}.`}
        CRITICAL: Maintain the EXACT framing and composition of Image 0.
        Style: Photorealistic, light background.`;

        const headB64 = await callGemini(headPrompt, [baseB64]);
        
        state.salonPreviewB64 = headB64;
        state.previewHeadshotUrl = `data:image/png;base64,${headB64}`;
        
        document.getElementById('stage-image').src = state.previewHeadshotUrl;
        if (!bodyReference) {
            alert("Body reference not found. Please restart the app.");
            showLoading(false);
            return;
        }
        const bodyB64 = await runBodyGeneration(state.salonPreviewB64, bodyReference);
        
        // Update master reference with new generated body
        state.masterBodyB64 = bodyB64;
        
        saveNewLook(state.salonPreviewB64, bodyB64);
/* ----------------------------------------------------------------
   STYLIST & OUTFIT GENERATION
   ---------------------------------------------------------------- */
async function removeBackground(imageB64) {
    try {
        const response = await fetch('/.netlify/functions/remove-background', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ imageData: imageB64 })
        });
        
        
        if (!response.ok) {
            throw new Error('Background removal failed');
        }
        
        const data = await response.json();
        return data.imageData;
    } catch (e) {
        console.error('Background removal error:', e);
        return imageB64; // Return original if removal fails
    }
    }
}

async function autoTagItem(imageB64) {
    try {
        const response = await fetch('/.netlify/functions/auto-tag-item', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ imageData: imageB64 })
        });
        
        
        if (!response.ok) {
            throw new Error('Auto-tagging failed');
        }
        
        const data = await response.json();
        return data;
    } catch (e) {
        console.error('Auto-tagging error:', e);
        return {
            category: "All",
- High quality, commercial product photography aesthetic
- Remove any background clutter or distractions
- Ensure the item looks professional and ready for e-commerce`;

        // Use cheapest model explicitly
        const productShotB64 = await callGemini(prompt, [imageB64], 'gemini-2.5-flash-image');
        return productShotB64;
    } catch (e) {
        console.error('Product shot generation error:', e);
        // Return original image if generation fails - item will still be created
        // Don't throw, just return original so processing can continue
        showLoading(true, `Processing ${filesArray.length} items...`);
    }
    
    for (const file of filesArray) {
        try {
            let b64 = await toBase64(file);
            // Resize wardrobe items too
            b64 = await resizeImage(b64, 1024);
            
            let processedB64 = b64;
            let originalB64 = b64;
    
    for (const file of filesArray) {
        try {
            let b64 = await toBase64(file);
            // Resize wardrobe items too
            b64 = await resizeImage(b64, 1024);
            
            let processedB64 = b64;
            let originalB64 = b64;
            
            // Generate product shot using Gemini (always done for all uploads)
            b64 = await resizeImage(b64, 1024);
            
            let processedB64 = b64;
            let originalB64 = b64;
            
            // Generate product shot using Gemini (always done for all uploads)
            try {
                // Show progress for product shot generation if multiple files
                if (filesArray.length > 1) {
                    const currentIndex = filesArray.indexOf(file) + 1;
                    showLoading(true, `Generating product shot ${currentIndex}/${filesArray.length}...`);
                // Show progress for product shot generation if multiple files
                if (filesArray.length > 1) {
                    const currentIndex = filesArray.indexOf(file) + 1;
                    showLoading(true, `Generating product shot ${currentIndex}/${filesArray.length}...`);
                }
                processedB64 = await generateProductShot(b64);
                // generateProductShot returns original if it fails, so processedB64 is always valid
            } catch (e) {
                console.error(`Product shot generation failed for ${file.name}, using original:`, e);
                // Continue with original image if product shot generation fails
                // Item will still be created with original image
                // Item will still be created with original image
            }
            
            // Optional background removal (if still needed after product shot)
            if (autoRemoveBg) {
                processedB64 = await removeBackground(processedB64);
            }
            
            // Auto-tagging
            let tags = { category: "All", primaryColor: "Unknown", style: "casual", estimatedSize: null, itemType: file.name.split('.')[0] || "New Item" };
            if (autoTag) {
            
            // Auto-tagging
            let tags = { category: "All", primaryColor: "Unknown", style: "casual", estimatedSize: null, itemType: file.name.split('.')[0] || "New Item" };
            if (autoTag) {
                try {
                    tags = await autoTagItem(processedB64);
                } catch (e) {
                    console.error(`Auto-tagging failed for ${file.name}:`, e);
                    // Continue with default tags - item will still be created
                }
            }
    // For now, errors are logged to console
}

async function handleWardrobeUpload(input) {
    if(input.files) {
        await processWardrobeFiles(input.files);
        // Clear input so same file can be uploaded again if needed
        input.value = '';
    }
}


    // MANNEQUIN WORKFLOW logic
    const threshold = (state.selectedModel === 'gemini-2.5-flash-image' || state.selectedModel === 'standard-plus') ? 2 : Infinity;
    
    if (!isPro && activeClothes.length > threshold) {
        await triggerMannequinWorkflow(activeClothes, additionalDesc);
        return;
    }

    // Normal generation logic...
    await runOutfitGeneration(baseB64, activeClothes, additionalDesc, activeHeadshotB64);
        await triggerMannequinWorkflow(activeClothes, additionalDesc);
        return;
    }

    // Normal generation logic...
    await runOutfitGeneration(baseB64, activeClothes, additionalDesc, activeHeadshotB64);
}

async function triggerMannequinWorkflow(activeClothes, additionalDesc) {
    // Track wardrobe items used for saving outfits
    state.lastUsedWardrobeItems = activeClothes.map(c => c.id);
    `;

    const images = activeClothes.map(c => c.b64);

    try {
        const mannequinB64 = await callGemini(prompt, images);
        state.currentMannequinB64 = mannequinB64;
        
        document.getElementById('mannequin-preview').src = `data:image/jpeg;base64,${mannequinB64}`;
        document.getElementById('mannequin-overlay').classList.remove('hidden');
    } catch (e) {
    - Ensure head-to-body proportions are accurate (8-heads-tall rule).
    - OUTPUT: Full Body Vertical Portrait.
    `;

    try {
        const finalB64 = await callGemini(prompt, [baseB64, state.currentMannequinB64, activeHeadshotB64]);
        applyGenerationResult(finalB64);
    } catch (e) {
        const errorMsg = e.message || 'Unknown error occurred';
        alert(`Outfit application failed: ${errorMsg}\n\nPlease try again or check your internet connection.`);
        console.error('Mannequin approval error:', e);
    4. Ensure head-to-body proportions are accurate (8-heads-tall rule). No long necks or large heads.
    5. Background: Pure white infinite studio.
    `;
    
    try {
        const b64 = await callGemini(prompt, images);
        applyGenerationResult(b64);
    } catch(e) {
        const errorMsg = e.message || 'Unknown error occurred';
        alert(`Outfit generation failed: ${errorMsg}\n\nPlease try again or check your internet connection.`);
        console.error('Outfit generation error:', e);
    showLoading(true, "Saving outfit...");
    
    const b64 = state.currentSessionBaseB64;
    const usedItems = state.wardrobe.filter(i => state.lastUsedWardrobeItems.includes(i.id));
    
    // Generate outfit name using Gemini
    let outfitName = "";
    try {
        const itemDetails = usedItems.length > 0 
            ? usedItems.map(i => `${i.title} (${i.category}, ${i.primaryColor || 'various'}, ${i.style || 'casual'})`).join(', ')
            : "Generated outfit";
- Make it memorable and descriptive
- Avoid generic names like "Outfit 1"

Return ONLY the name, no quotes, no punctuation, no explanation.`;
        
        const nameResult = await callGemini(namingPrompt, [], 'gemini-2.5-flash-image', 'TEXT');
        outfitName = nameResult.trim().replace(/^["']|["']$/g, '');
        if (!outfitName || outfitName.length < 2) {
            throw new Error('Invalid name');
        }
    } catch (e) {
}

/* ----------------------------------------------------------------
   API FUNCTION
   ---------------------------------------------------------------- */
async function callGemini(promptText, b64Images, modelOverride = null, responseType = 'IMAGE') {
    let targetModel = modelOverride || state.selectedModel;
    
    // Handle Standard Plus hybrid mapping
    if (targetModel === 'standard-plus' && !modelOverride) {
        targetModel = 'gemini-2.5-flash-image';
    if (targetModel === 'standard-plus' && !modelOverride) {
        targetModel = 'gemini-2.5-flash-image';
    }

    try {
        const response = await fetch('/.netlify/functions/generate', {
            method: 'POST',
            headers: { 
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
        });

        if (!response.ok) {
            let errorMsg = `Server error: ${response.status}`;
            try {
                const errorData = await response.json();
                errorMsg = errorData.error || errorMsg;
            } catch (e) {
                // Not JSON
            }
            throw new Error(errorMsg);
                // Not JSON
            }
            throw new Error(errorMsg);
        }

        const data = await response.json();
        
        if (data.error) {
            throw new Error(data.error);
        }
        
    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) || 
                  (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
    
    try {
        // Fetch the image as a blob to ensure proper download on mobile
        const response = await fetch(src);
        const blob = await response.blob();
        
        // For iOS, use Share API if available, otherwise open in new tab
        if (isIOS && navigator.share) {
            const file = new File([blob], `full_stylist_${Date.now()}.png`, { type: 'image/png' });
                  (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
    
    try {
        // Fetch the image as a blob to ensure proper download on mobile
        const response = await fetch(src);
        const blob = await response.blob();
        
        // For iOS, use Share API if available, otherwise open in new tab
        if (isIOS && navigator.share) {
            const file = new File([blob], `full_stylist_${Date.now()}.png`, { type: 'image/png' });
            if (navigator.canShare && navigator.canShare({ files: [file] })) {
        
        // For iOS, use Share API if available, otherwise open in new tab
        if (isIOS && navigator.share) {
            const file = new File([blob], `full_stylist_${Date.now()}.png`, { type: 'image/png' });
            if (navigator.canShare && navigator.canShare({ files: [file] })) {
                await navigator.share({
                    files: [file],
                    title: 'Full Stylist Image',
                    text: 'Download image'
                });
                return;
    }
}

/**
 * Calculates estimated cost based on selected model and number of images.
 * Uses rough approximations for standard Gemini pricing.
 */
function getEstimatedCost(numImages, isBodyShot = false) {
    const pricing = {
        'gemini-3-pro-image-preview': { base: 0.002, perImage: 0.001 },
        'gemini-2.5-flash-image': { base: 0.0001, perImage: 0.00005 }
    `;
    
    modal.classList.add('active');
    
    try {
        const advice = await getStyleAdvice(context, selectedItems);
        body.innerHTML = `
            <div style="padding: 20px;">
                <div style="background: var(--surface-light); padding: 20px; border-radius: 12px; margin-bottom: 20px;">
                    <h3 style="margin-top: 0; color: var(--primary);">Style Advice</h3>
                    <p style="color: var(--text-main); line-height: 1.6; white-space: pre-wrap;">${advice.advice}</p>
        closeStyleMe();
    }
}

async function getStyleAdvice(context, selectedItems) {
    const response = await fetch('/.netlify/functions/style-advice', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            context: context,
            selectedItems: selectedItems.map(i => ({ id: i.id, title: i.title, category: i.category, style: i.style })),
    
    if (!response.ok) {
        throw new Error('Failed to get style advice');
    }
    
    return await response.json();
}

function openWeatherSettings() {
    const modal = document.getElementById('weather-settings-modal');
    const body = document.getElementById('weather-settings-body');

    const images = selectedItems.map(c => c.b64);

    try {
        // Use cheapest model explicitly
        const b64 = await callGemini(prompt, images, 'gemini-2.5-flash-image');
        
        // Generate an appropriate name for the outfit
        const itemDetails = selectedItems.map(i => `${i.title} (${i.category}, ${i.primaryColor || 'various'}, ${i.style || 'casual'})`).join(', ');
        const namingPrompt = `You are a creative fashion stylist. Generate a short, stylish, and personality-driven name (2-4 words) for a fashion outfit consisting of these items: ${itemDetails}.

- Avoid generic names like "Outfit 1"

Return ONLY the name, no quotes, no punctuation, no explanation.`;
        let outfitName = "";
        try {
            const nameResult = await callGemini(namingPrompt, [], 'gemini-2.5-flash-image', 'TEXT');
            outfitName = nameResult.trim().replace(/^["']|["']$/g, ''); // Remove quotes if present
            if (!outfitName || outfitName.length < 2) {
                throw new Error('Invalid name');
            }
        } catch (e) {
    - Ensure lighting and skin tones match perfectly.
    - Output: Full Body Vertical Portrait.
    `;

    try {
        const b64 = await callGemini(prompt, [bodyReference, outfit.mannequinB64, headB64]);
        outfit.humanB64 = b64;
        outfit.humanUrl = `data:image/png;base64,${b64}`;
        outfit.lastWorn = new Date().toISOString(); // Track when worn
        
        // Open on Stylist page

--- ./netlify/functions/auto-tag-item.js ---
    "itemType": "specific item type (e.g. t-shirt, jeans, sneakers, watch)"
}

Return ONLY valid JSON, no other text.`;

        const response = await fetch(
            `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image:generateContent?key=${apiKey}`,
            {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    }
                })
            }
        );

        const data = await response.json();
        
        if (!response.ok || data.error) {
            throw new Error(data.error?.message || 'API error');
        }


--- ./netlify/functions/ai-job-runner.js ---
const { createPerformanceTracker, createTimingTracker, downloadImageFromStorage } = require("./utils");
const { processAutoTag } = require("./processes/auto_tag");
const { processProductShot } = require("./processes/product_shot");
const { processHeadshotGenerate } = require("./processes/headshot_generate");
const { processBodyShotGenerate } = require("./processes/body_shot_generate");
const { processOutfitRender } = require("./processes/outfit_render");
const { processOutfitMannequin } = require("./processes/outfit_mannequin");
const { processOutfitSuggest } = require("./processes/outfit_suggest");
const { processReferenceMatch } = require("./processes/reference_match");

/**
    }
    const token = authHeader.replace("Bearer ", "");
    const {
      data: { user },
      error: authError
    } = await supabaseAdmin.auth.getUser(token);
    if (authError || !user) {
      return {
        statusCode: 401,
        headers,
        body: JSON.stringify({ error: "Invalid token" })
        headers,
        body: JSON.stringify({ error: "job_id is required" })
      };
    }
    // Retrieve the job record and verify ownership
    const { data: job, error: jobError } = await supabaseAdmin
      .from("ai_jobs")
      .select("*")
      .eq("id", job_id)
      .eq("owner_user_id", user.id)
      .single();
        headers,
        body: JSON.stringify({ error: "Job already running" })
      };
    }
    // Update job status to running and queue asynchronous processing
    await supabaseAdmin
      .from("ai_jobs")
      .update({ status: "running", updated_at: new Date().toISOString() })
      .eq("id", job_id);
    processJobAsync(job, user.id).catch((err) => {
      console.error(`[AIJobRunner] Async processing error for ${job_id}:`, err);
    // Update job status to running and queue asynchronous processing
    await supabaseAdmin
      .from("ai_jobs")
      .update({ status: "running", updated_at: new Date().toISOString() })
      .eq("id", job_id);
    processJobAsync(job, user.id).catch((err) => {
      console.error(`[AIJobRunner] Async processing error for ${job_id}:`, err);
    });
    return {
      statusCode: 202,
      headers,
 * asynchronously and does not block the HTTP response.
 *
 * @param {object} job - The job record from the database
 * @param {string} userId - ID of the job owner
 */
async function processJobAsync(job, userId) {
  const job_id = job.id;
  
  // Create performance tracker at the start of the request
  const perfTracker = createPerformanceTracker();
  console.log(`[AIJobRunner] Created performance tracker: ${perfTracker.requestId} for job ${job_id} (${job.job_type})`);
  let error = null;
  try {
    const input = job.input;
    switch (job.job_type) {
      case "batch":
        result = await processBatchJob(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
    switch (job.job_type) {
      case "batch":
        result = await processBatchJob(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        throw new Error(`Unknown job type: ${job.job_type}`);
    }
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        throw new Error(`Unknown job type: ${job.job_type}`);
    }
  } catch (err) {
  if (error) {
    updateData.error = error;
  } else {
    updateData.result = result;
  }
  await supabaseAdmin.from("ai_jobs").update(updateData).eq("id", job_id);
}

/**
 * Processes a batch job that runs multiple tasks on the same image in parallel.
 * Downloads the image once and passes it to all tasks to avoid redundant downloads.
  
  console.log(`[BatchJob] Starting batch processing for imageId: ${imageId}, tasks: ${tasks.join(', ')}`);
  
  // Download the image once to a buffer (returns { base64, mimeType } object)
  console.log(`[BatchJob] Downloading image once for shared use...`);
  const imageData = await downloadImageFromStorage(supabase, imageId, timingTracker);
  console.log(`[BatchJob] Image downloaded successfully, length: ${imageData.base64.length}, mimeType: ${imageData.mimeType}`);
  
  // Prepare inputs for both tasks
  const productShotInput = tasks.includes('product_shot') ? {
    image_id: imageId,
    });
    taskPromises.push(autoTagPromise);
  }
  
  // Both promises are now created and executing in parallel
  // Only NOW do we await - Promise.all waits for BOTH to complete
  console.log(`[BatchJob] Both promises created. Awaiting ${taskPromises.length} promises with Promise.all() (both running in parallel)...`);
  const results = await Promise.all(taskPromises);
  
  // Capture end time after Promise.all() completes
  const batchEnd = performance.now();
  }
  
  // Both promises are now created and executing in parallel
  // Only NOW do we await - Promise.all waits for BOTH to complete
  console.log(`[BatchJob] Both promises created. Awaiting ${taskPromises.length} promises with Promise.all() (both running in parallel)...`);
  const results = await Promise.all(taskPromises);
  
  // Capture end time after Promise.all() completes
  const batchEnd = performance.now();
  const batchDuration = ((batchEnd - batchStart) / 1000).toFixed(2);
  

--- ./netlify/functions/utils.js ---
"use strict";

// Utility functions shared by multiple Netlify functions. These helpers
// encapsulate the common logic for downloading and uploading images to
// Supabase storage as well as calling the Gemini API. They are extracted
// into a separate module to avoid duplication and keep the individual
// function handlers focused on their specific job logic.

const sharp = require('sharp');
// STATELESS: Use native fetch if available (Node 18+), otherwise lazy-load node-fetch per call
async function getFetch() {
  if (typeof fetch !== 'undefined') {
    return fetch; // Native fetch (Node 18+)
  }
  if (!fetchFn) {
    const nodeFetch = await import('node-fetch');
    fetchFn = nodeFetch.default;
  }
  return fetchFn;
}

    clientProperties: supabase ? Object.keys(supabase).filter(k => !k.startsWith('_')).join(', ') : 'N/A',
  });
  
  console.log(`[downloadImageFromStorage] Starting download for imageId: ${imageId}`);
  
  const { data: image, error } = await supabase
    .from("images")
    .select("storage_bucket, storage_key, mime_type")
    .eq("id", imageId)
    .single();
    
  const bucket = image.storage_bucket || "media";
  
  // Generate signed URL for direct CDN/S3 access (bypasses API middleware)
  const signedUrlStart = performance.now();
  console.log(`[downloadImageFromStorage] Generating signed URL for direct download...`);
  const { data: signedUrlData, error: signedUrlError } = await supabase.storage
    .from(bucket)
    .createSignedUrl(image.storage_key, 60); // 60 second expiry
  
  if (signedUrlError || !signedUrlData?.signedUrl) {
    console.error(`[downloadImageFromStorage] Failed to create signed URL:`, signedUrlError);
  // Track storage download time
  const downloadStart = performance.now();
  console.log(`[downloadImageFromStorage] Downloading directly from signed URL (CDN/S3 path)...`);
  
  // Use fetch() to download directly from signed URL (routes through CDN/S3, faster than API)
  const fetchResponse = await fetch(signedUrlData.signedUrl);
  
  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text().catch(() => 'Unknown error');
    console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
    throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
  
  // Use fetch() to download directly from signed URL (routes through CDN/S3, faster than API)
  const fetchResponse = await fetch(signedUrlData.signedUrl);
  
  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text().catch(() => 'Unknown error');
    console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
    throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
  }
  
  const arrayBuffer = await fetchResponse.arrayBuffer();
    const errorText = await fetchResponse.text().catch(() => 'Unknown error');
    console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
    throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
  }
  
  const arrayBuffer = await fetchResponse.arrayBuffer();
  const downloadEnd = performance.now();
  const downloadDuration = downloadEnd - downloadStart;
  
  if (timingTracker) {
    timingTracker.addStorageDownload(downloadDuration);
  const isPng = isPngBase64(base64Data);
  const mimeType = isPng ? "image/png" : "image/jpeg";
  const rawBase64 = base64Data.replace(/^data:image\/\w+;base64,/, "");
  const buffer = Buffer.from(rawBase64, "base64");
  const blob = new Blob([buffer], { type: mimeType });
  const { data: uploadData, error: uploadError } = await supabase.storage
    .from("media")
    .upload(storagePath, blob, {
      cacheControl: "3600",
      upsert: false,
      contentType: mimeType
      contentType: mimeType
    });
  if (uploadError || !uploadData) {
    throw new Error(`Failed to upload: ${uploadError?.message}`);
  }
  const { data: imageRecord, error: imageError } = await supabase
    .from("images")
    .insert({
      owner_user_id: userId,
      storage_bucket: "media",
      storage_key: uploadData.path,
  }
  return { imageId: imageRecord.id, storageKey: uploadData.path };
}

/**
 * Calls the Gemini API for either text or image generation. It accepts a
 * prompt and an array of Base64 encoded images that will be sent as
 * inline_data. The model and response type can be configured. For image
 * generation, the response is returned as a Base64 encoded image string.
 * For text generation, the returned string contains the generated text.
 * 
 * chat sessions. This allows true parallel execution when called from
 * Promise.all() without any serialization or queuing.
 *
 * @param {string} prompt - The prompt to send to the API
 * @param {string[]} images - Array of Base64 encoded images
 * @param {string} model - The name of the Gemini model to use
 * @param {"TEXT"|"IMAGE"} responseType - Desired response type
 * @param {object} perfTracker - Optional performance tracker for timing measurements
 * @param {object} timingTracker - Optional timing tracker for detailed step-by-step timing
 * @returns {Promise<string>} The generated text or Base64 image data
 */
 * @param {"TEXT"|"IMAGE"} responseType - Desired response type
 * @param {object} perfTracker - Optional performance tracker for timing measurements
 * @param {object} timingTracker - Optional timing tracker for detailed step-by-step timing
 * @returns {Promise<string>} The generated text or Base64 image data
 */
async function callGeminiAPI(prompt, images, model = "gemini-2.5-flash-image", responseType = "IMAGE", perfTracker = null, timingTracker = null) {
  // STATELESS: Each call reads the API key fresh - no shared state
  const GEMINI_API_KEY = process.env.GEMINI_API_KEY || "";
  if (!GEMINI_API_KEY) {
    throw new Error("GEMINI_API_KEY missing");
  }
  }
  
  // STATELESS: Each call makes a completely independent HTTP request
  // No shared model instances, chat sessions, or connection pooling that could serialize requests
  // Each request uses a fresh fetch instance to ensure true parallelism
  const fetchFn = await getFetch();
  
  const response = await fetchFn(
    `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`,
    {
      method: "POST",
  // STATELESS: Each call makes a completely independent HTTP request
  // No shared model instances, chat sessions, or connection pooling that could serialize requests
  // Each request uses a fresh fetch instance to ensure true parallelism
  const fetchFn = await getFetch();
  
  const response = await fetchFn(
    `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        ]
      })
    }
  );
  
  const data = await response.json();
  if (!response.ok || data.error) {
    console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
    console.error("[GeminiAPI] Request details:", {
      model,
      responseType,
    }
  );
  
  const data = await response.json();
  if (!response.ok || data.error) {
    console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
    console.error("[GeminiAPI] Request details:", {
      model,
      responseType,
      promptLength: prompt.length,
      imageCount: images.length,
  );
  
  const data = await response.json();
  if (!response.ok || data.error) {
    console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
    console.error("[GeminiAPI] Request details:", {
      model,
      responseType,
      promptLength: prompt.length,
      imageCount: images.length,
      firstImageLength: images[0]?.length || 0,
      promptLength: prompt.length,
      imageCount: images.length,
      firstImageLength: images[0]?.length || 0,
      firstImagePreview: images[0]?.substring(0, 100) || "N/A"
    });
    const errorMessage = data.error?.message || data.error || "Gemini API Error";
    // Preserve the original error message from Gemini
    throw new Error(errorMessage);
  }
  const candidate = data.candidates?.[0];
  if (!candidate) {
      imageCount: images.length,
      firstImageLength: images[0]?.length || 0,
      firstImagePreview: images[0]?.substring(0, 100) || "N/A"
    });
    const errorMessage = data.error?.message || data.error || "Gemini API Error";
    // Preserve the original error message from Gemini
    throw new Error(errorMessage);
  }
  const candidate = data.candidates?.[0];
  if (!candidate) {
    throw new Error("No candidates returned");
  
  // Record API call time in timing tracker
  if (timingTracker) {
    timingTracker.addApiCall(apiCallDuration);
  }
  console.log(`[callGeminiAPI] External API call completed in ${(apiCallDuration / 1000).toFixed(2)}s (${responseType})`);
  
  if (perfTracker) {
    if (responseType === "TEXT") {
      perfTracker.endTextGen();
    } else {
      } else {
        imageBuffer = imageInput;
      }

      // Load and resize image to fit within cell (contain mode - no cropping)
      const resizedImage = await sharp(imageBuffer)
        .resize(cellWidth, cellHeight, {
          fit: 'contain',
          background: BACKGROUND_COLOR
        })
        .toBuffer();
          background: BACKGROUND_COLOR
        })
        .toBuffer();

      // Get actual dimensions of resized image (may be smaller than cell)
      const metadata = await sharp(resizedImage).metadata();
      const actualWidth = metadata.width;
      const actualHeight = metadata.height;

      // Center the image within the cell
      const offsetX = x + Math.floor((cellWidth - actualWidth) / 2);
    }
  }

  // Composite all images onto the canvas
  console.log(`[compositeOutfitGrid] Compositing ${composites.length} images...`);
  const finalImage = await canvas
    .composite(composites)
    .jpeg({ quality: 95 })
    .toBuffer();

  // Convert to base64

  return base64;
}

/**
 * Optimizes a Gemini-generated image by resizing and compressing it.
 * Converts the base64 input to a Buffer, resizes to max width 1024px (maintaining aspect ratio),
 * converts to JPEG with quality 80 and mozjpeg compression, then returns as base64 string.
 * 
 * @param {string} base64String - Base64 encoded image string from Gemini API
 * @returns {Promise<string>} Optimized base64 encoded JPEG image string
/**
 * Optimizes a Gemini-generated image by resizing and compressing it.
 * Converts the base64 input to a Buffer, resizes to max width 1024px (maintaining aspect ratio),
 * converts to JPEG with quality 80 and mozjpeg compression, then returns as base64 string.
 * 
 * @param {string} base64String - Base64 encoded image string from Gemini API
 * @returns {Promise<string>} Optimized base64 encoded JPEG image string
 */
async function optimizeGeminiOutput(base64String) {
  console.log('[optimizeGeminiOutput] Starting optimization...');
  
 * converts to JPEG with quality 80 and mozjpeg compression, then returns as base64 string.
 * 
 * @param {string} base64String - Base64 encoded image string from Gemini API
 * @returns {Promise<string>} Optimized base64 encoded JPEG image string
 */
async function optimizeGeminiOutput(base64String) {
  console.log('[optimizeGeminiOutput] Starting optimization...');
  
  try {
    // Convert base64 to buffer
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, '');
 * 
 * @param {string} base64String - Base64 encoded image string from Gemini API
 * @returns {Promise<string>} Optimized base64 encoded JPEG image string
 */
async function optimizeGeminiOutput(base64String) {
  console.log('[optimizeGeminiOutput] Starting optimization...');
  
  try {
    // Convert base64 to buffer
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, '');
    const inputBuffer = Buffer.from(rawBase64, 'base64');
  try {
    // Convert base64 to buffer
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, '');
    const inputBuffer = Buffer.from(rawBase64, 'base64');
    
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    
    // Get original metadata
    const originalMetadata = await sharp(inputBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
    
    const inputBuffer = Buffer.from(rawBase64, 'base64');
    
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    
    // Get original metadata
    const originalMetadata = await sharp(inputBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
    
    // Optimize with sharp: resize to max width 1024px, convert to JPEG with quality 80 and mozjpeg
    const optimizedBuffer = await sharp(inputBuffer)
      .resize(1024, null, {
    
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    
    // Get original metadata
    const originalMetadata = await sharp(inputBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
    
    // Optimize with sharp: resize to max width 1024px, convert to JPEG with quality 80 and mozjpeg
    const optimizedBuffer = await sharp(inputBuffer)
      .resize(1024, null, {
        withoutEnlargement: true,
    // Get original metadata
    const originalMetadata = await sharp(inputBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
    
    // Optimize with sharp: resize to max width 1024px, convert to JPEG with quality 80 and mozjpeg
    const optimizedBuffer = await sharp(inputBuffer)
      .resize(1024, null, {
        withoutEnlargement: true,
        fit: 'inside'
      })
      .jpeg({
        quality: 80,
        mozjpeg: true
      })
      .toBuffer();
    
    console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    
    // Get optimized metadata
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    
      .toBuffer();
    
    console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    
    // Get optimized metadata
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    
    
    console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    
    // Get optimized metadata
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    
    // Convert back to base64 string
    // Get optimized metadata
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    
    // Convert back to base64 string
    const optimizedBase64 = optimizedBuffer.toString('base64');
    console.log('[optimizeGeminiOutput] Optimization complete');
    
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    
    // Convert back to base64 string
    const optimizedBase64 = optimizedBuffer.toString('base64');
    console.log('[optimizeGeminiOutput] Optimization complete');
    
    return optimizedBase64;
  } catch (error) {
    console.error('[optimizeGeminiOutput] Optimization failed:', error);
    // Return original if optimization fails
    const optimizedBase64 = optimizedBuffer.toString('base64');
    console.log('[optimizeGeminiOutput] Optimization complete');
    
    return optimizedBase64;
  } catch (error) {
    console.error('[optimizeGeminiOutput] Optimization failed:', error);
    // Return original if optimization fails
    console.warn('[optimizeGeminiOutput] Returning original image due to error');
    return base64String;
  }
}
    
    return optimizedBase64;
  } catch (error) {
    console.error('[optimizeGeminiOutput] Optimization failed:', error);
    // Return original if optimization fails
    console.warn('[optimizeGeminiOutput] Returning original image due to error');
    return base64String;
  }
}

module.exports = {
}

module.exports = {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI,
  compositeOutfitGrid,
  optimizeGeminiOutput,
  createPerformanceTracker,
  createTimingTracker
};
module.exports = {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI,
  compositeOutfitGrid,
  optimizeGeminiOutput,
  createPerformanceTracker,
  createTimingTracker
};

--- ./netlify/functions/validate-model-password.js ---
"use strict";

/**
 * Validates password for accessing advanced AI models (e.g., Gemini 3 Pro)
 * This keeps the password secure on the server side
 */

const { supabaseAdmin } = require("./supabaseClient");


--- ./netlify/functions/remove-background.js ---
                    data: imageData
                }
            }
        ];

        const response = await fetch(
            `https://generativelanguage.googleapis.com/v1beta/models/${modelId}:generateContent?key=${apiKey}`,
            {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                })
            }
        );

        if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`);
        }

        const data = await response.json();
        
        if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`);
        }

        const data = await response.json();
        
        // Extract image data
        const part = data.candidates?.[0]?.content?.parts?.[0];
        const resultB64 = part?.inline_data?.data || part?.inlineData?.data;

        // Extract image data
        const part = data.candidates?.[0]?.content?.parts?.[0];
        const resultB64 = part?.inline_data?.data || part?.inlineData?.data;

        if (!resultB64) {
            throw new Error('No image data returned from Gemini');
        }

        return {
            statusCode: 200,
            headers,

--- ./netlify/functions/style-advice.js ---
    "advice": "your styling advice text here",
    "suggestedItems": []
}`;
        }

        const response = await fetch(
            `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image:generateContent?key=${apiKey}`,
            {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    }
                })
            }
        );

        const data = await response.json();
        
        if (!response.ok || data.error) {
            throw new Error(data.error?.message || 'API error');
        }


--- ./netlify/functions/processes/product_shot.js ---
"use strict";

// Handler for generating a product photography shot from a wardrobe item image.
// This function uses the PROMPTS.PRODUCT_SHOT template to instruct Gemini
// to produce a square, professionally lit product photo. The resulting
// image is uploaded to Supabase storage and linked to the wardrobe item.

const { PROMPTS } = require("../prompts");
const {

const { PROMPTS } = require("../prompts");
const {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI
} = require("../utils");

/**
 * Generates a product shot for a given wardrobe item and stores the result
 * back into Supabase. It also ensures the new image appears first in the
    console.log(`[processProductShot] Using pre-downloaded image (skipping storage download, saving ~5s)`);
    imageResult = preDownloadedImageData;
  } else {
    // Download from storage if no pre-downloaded data provided
    console.log(`[processProductShot] Downloading image from storage (image_id: ${image_id})...`);
    imageResult = await downloadImageFromStorage(supabase, image_id, timingTracker);
  }
  
  // Generate a product shot using Gemini - pass full result object to include mime-type
  const productShotB64 = await callGeminiAPI(
    PROMPTS.PRODUCT_SHOT,
    // Download from storage if no pre-downloaded data provided
    console.log(`[processProductShot] Downloading image from storage (image_id: ${image_id})...`);
    imageResult = await downloadImageFromStorage(supabase, image_id, timingTracker);
  }
  
  // Generate a product shot using Gemini - pass full result object to include mime-type
  const productShotB64 = await callGeminiAPI(
    PROMPTS.PRODUCT_SHOT,
    [imageResult],
    "gemini-2.5-flash-image",
    "IMAGE",
    console.log(`[processProductShot] Downloading image from storage (image_id: ${image_id})...`);
    imageResult = await downloadImageFromStorage(supabase, image_id, timingTracker);
  }
  
  // Generate a product shot using Gemini - pass full result object to include mime-type
  const productShotB64 = await callGeminiAPI(
    PROMPTS.PRODUCT_SHOT,
    [imageResult],
    "gemini-2.5-flash-image",
    "IMAGE",
    perfTracker,
    timingTracker
  );
  // Upload the generated image to storage
  const timestamp = Date.now();
  const storagePath = `${userId}/ai/product_shots/${timestamp}.jpg`;
  const { imageId, storageKey } = await uploadImageToStorage(
    supabase,
    userId,
    productShotB64,
    storagePath
  );
    userId,
    productShotB64,
    storagePath
  );
  // Adjust existing images' sort orders to ensure the new shot appears first
  const { data: existingImages } = await supabase
    .from("wardrobe_item_images")
    .select("id, sort_order")
    .eq("wardrobe_item_id", wardrobe_item_id)
    .order("sort_order", { ascending: false });
  for (const img of existingImages || []) {
    .from("wardrobe_item_images")
    .select("id, sort_order")
    .eq("wardrobe_item_id", wardrobe_item_id)
    .order("sort_order", { ascending: false });
  for (const img of existingImages || []) {
    await supabase
      .from("wardrobe_item_images")
      .update({ sort_order: (img.sort_order || 0) + 1 })
      .eq("id", img.id);
  }
  // Insert the new product shot as sort_order=0
      .from("wardrobe_item_images")
      .update({ sort_order: (img.sort_order || 0) + 1 })
      .eq("id", img.id);
  }
  // Insert the new product shot as sort_order=0
  await supabase.from("wardrobe_item_images").insert({
    wardrobe_item_id,
    image_id: imageId,
    type: "product_shot",
    sort_order: 0
  });

--- ./netlify/functions/processes/auto_tag.js ---
"use strict";

// This module defines the logic for processing "auto_tag" jobs. It
// downloads the image associated with the wardrobe item, constructs
// prompts to pass to the Gemini model, parses the AI response, and
// writes the resulting attributes back into the database. Extracting
// this logic into its own file simplifies the main job runner and
// allows for easier testing and maintenance.

const { PROMPTS } = require("../prompts");
// writes the resulting attributes back into the database. Extracting
// this logic into its own file simplifies the main job runner and
// allows for easier testing and maintenance.

const { PROMPTS } = require("../prompts");
const { downloadImageFromStorage, callGeminiAPI } = require("../utils");

/**
 * Process an auto-tag job by analyzing a clothing item image and
 * extracting attributes. The function writes new attributes and
 * updates to the wardrobe item into Supabase.
    // Download from storage if no pre-downloaded data provided
    console.log(`[processAutoTag] Downloading image from storage (image_id: ${image_ids[0]})...`);
    imageB64Promise = downloadImageFromStorage(supabase, image_ids[0], timingTracker);
  }
  
  const [imageResult, catRes, subRes, attrRes] = await Promise.all([
    imageB64Promise,
    supabase.from("wardrobe_categories").select("id, name").order("sort_order"),
    supabase.from("wardrobe_subcategories").select("id, name, category_id").order("sort_order"),
    supabase.from("attribute_definitions").select("id, key, name")
  ]);
  const categories = catRes.data || [];
  const subcategories = subRes.data || [];
  const catList = categories.map((c) => c.name).join(", ");
  const subList = subcategories.map((s) => s.name).join(", ");
  const prompt = PROMPTS.AUTO_TAG(catList, subList);
  // Call the Gemini API with the clothing image to extract JSON attributes
  // Pass the full result object so mime-type is included
  const textResult = await callGeminiAPI(prompt, [imageResult], "gemini-2.5-flash-image", "TEXT", perfTracker, timingTracker);
  let result;
  try {
    // Remove possible code fences around the JSON response
  const catList = categories.map((c) => c.name).join(", ");
  const subList = subcategories.map((s) => s.name).join(", ");
  const prompt = PROMPTS.AUTO_TAG(catList, subList);
  // Call the Gemini API with the clothing image to extract JSON attributes
  // Pass the full result object so mime-type is included
  const textResult = await callGeminiAPI(prompt, [imageResult], "gemini-2.5-flash-image", "TEXT", perfTracker, timingTracker);
  let result;
  try {
    // Remove possible code fences around the JSON response
    const cleaned = textResult
      .replace(/```json\n?/g, "")
  for (const attr of result.attributes || []) {
    const defId = defMap.get(attr.key);
    if (!defId) continue;
    for (const val of attr.values || []) {
      // Look up existing attribute values (caseinsensitive)
      let { data: value } = await supabase
        .from("attribute_values")
        .select("id")
        .eq("definition_id", defId)
        .ilike("value", val.value)
        .single();
        .eq("definition_id", defId)
        .ilike("value", val.value)
        .single();
      // Insert new value if it doesn't exist
      if (!value) {
        const { data: newValue } = await supabase
          .from("attribute_values")
          .insert({ definition_id: defId, value: val.value })
          .select("id")
          .single();
        value = newValue;
      }
    }
  }
  // Insert any new attributes into the entity_attributes table
  if (attributesToInsert.length) {
    await supabase.from("entity_attributes").insert(attributesToInsert);
  }
  // Determine updates to the wardrobe item record based on AI output
  const updates = {};
  if (result.suggested_title) updates.title = result.suggested_title;
  if (result.suggested_notes) updates.description = result.suggested_notes;
      }
    }
  }
  // Apply updates to the wardrobe item record
  if (Object.keys(updates).length > 0) {
    await supabase.from("wardrobe_items").update(updates).eq("id", wardrobe_item_id);
  }
  return { ...result, updates_applied: updates };
}

module.exports = { processAutoTag };

--- ./netlify/functions/processes/body_shot_generate.js ---
"use strict";

// Module for generating a full body studio portrait. This function
// composites the user's headshot onto a full-body reference image using
// Gemini, ensuring realistic proportions and proper studio lighting.

const { PROMPTS } = require("../prompts");
const {
  downloadImageFromStorage,
  uploadImageToStorage,

const { PROMPTS } = require("../prompts");
const {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI
} = require("../utils");

/**
 * Generates a body shot by blending an existing headshot onto a body
 * reference image. If no headshot is provided, it falls back to the
    throw new Error("Missing body_photo_image_id");
  }
  // Determine the headshot to use: explicit override or user settings
  let headId = headshot_image_id;
  if (!headId) {
    const { data: settings } = await supabase
      .from("user_settings")
      .select("headshot_image_id")
      .eq("user_id", userId)
      .single();
    headId = settings?.headshot_image_id;
  }
  if (!headId) {
    throw new Error("No headshot available");
  }
  // Download head and body images concurrently
  const [headResult, bodyResult] = await Promise.all([
    downloadImageFromStorage(supabase, headId, timingTracker),
    downloadImageFromStorage(supabase, body_photo_image_id, timingTracker)
  ]);
  // Generate the composite body shot - pass full result objects to include mime-types
  const studioModelB64 = await callGeminiAPI(
  const [headResult, bodyResult] = await Promise.all([
    downloadImageFromStorage(supabase, headId, timingTracker),
    downloadImageFromStorage(supabase, body_photo_image_id, timingTracker)
  ]);
  // Generate the composite body shot - pass full result objects to include mime-types
  const studioModelB64 = await callGeminiAPI(
    PROMPTS.BODY_COMPOSITE,
    [headResult, bodyResult],
    "gemini-3-pro-image-preview",
    "IMAGE",
    perfTracker,
    timingTracker
  );
  // Upload the new body shot image
  const timestamp = Date.now();
  const storagePath = `${userId}/ai/body_shots/${timestamp}.jpg`;
  const { imageId, storageKey } = await uploadImageToStorage(
    supabase,
    userId,
    studioModelB64,
    storagePath
  );
    userId,
    studioModelB64,
    storagePath
  );
  // Update the user's settings to reference the new body shot
  await supabase
    .from("user_settings")
    .update({ body_shot_image_id: imageId })
    .eq("user_id", userId);
  return { image_id: imageId, storage_key: storageKey };
}

--- ./netlify/functions/processes/outfit_mannequin.js ---

const { PROMPTS } = require("../prompts");
const {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI
} = require("../utils");

/**
 * Generates a mannequin image for the selected wardrobe items. It fetches
 * the top image for each item, invokes Gemini to produce a ghost
  callGeminiAPI
} = require("../utils");

/**
 * Generates a mannequin image for the selected wardrobe items. It fetches
 * the top image for each item, invokes Gemini to produce a ghost
 * mannequin render, and stores the resulting image. The returned
 * mannequin_image_id can be used later for compositing.
 *
 * @param {object} input - Job input including outfit_id, selected items, prompt and settings
 * @param {import('@supabase/supabase-js').SupabaseClient} supabase - Supabase client
  const { outfit_id, selected, prompt, settings } = input;
  if (!outfit_id || !selected?.length) {
    throw new Error("Missing outfit_id or selected items");
  }
  const wardrobeItemIds = selected.map((s) => s.wardrobe_item_id);
  const { data: allLinks, error: linksError } = await supabase
    .from("wardrobe_item_images")
    .select("wardrobe_item_id, type, sort_order, image_id")
    .in("wardrobe_item_id", wardrobeItemIds);
  if (linksError) {
    throw new Error(`Failed to load wardrobe item images: ${linksError.message}`);
  });
  if (!imageIdsToDownload.length) {
    throw new Error("No valid images found for outfit items");
  }
  // Download item images for the mannequin generation
  const itemImageResults = await Promise.all(
    imageIdsToDownload.map((id) => downloadImageFromStorage(supabase, id, timingTracker))
  );
  // Pass full result objects to include mime-types (callGeminiAPI will extract base64)
  const itemImages = itemImageResults;
  // Determine the model to use
  }
  // Download item images for the mannequin generation
  const itemImageResults = await Promise.all(
    imageIdsToDownload.map((id) => downloadImageFromStorage(supabase, id, timingTracker))
  );
  // Pass full result objects to include mime-types (callGeminiAPI will extract base64)
  const itemImages = itemImageResults;
  // Determine the model to use
  const { data: userSettings } = await supabase
    .from("user_settings")
    .select("ai_model_preference")
    imageIdsToDownload.map((id) => downloadImageFromStorage(supabase, id, timingTracker))
  );
  // Pass full result objects to include mime-types (callGeminiAPI will extract base64)
  const itemImages = itemImageResults;
  // Determine the model to use
  const { data: userSettings } = await supabase
    .from("user_settings")
    .select("ai_model_preference")
    .eq("user_id", userId)
    .single();
  const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
  const mannequinPrompt = PROMPTS.OUTFIT_MANNEQUIN(
    itemImages.length,
    prompt || "No additional details"
  );
  // Generate the mannequin image
  const mannequinB64 = await callGeminiAPI(
    mannequinPrompt,
    itemImages,
    preferredModel,
    "IMAGE",
    perfTracker,
    timingTracker
  );
  // Upload the mannequin render
  const timestamp = Date.now();
  const storagePath = `${userId}/ai/outfits/${outfit_id}/mannequin/${timestamp}.jpg`;
  const { imageId, storageKey } = await uploadImageToStorage(
    supabase,
    userId,
    mannequinB64,
    storagePath
  );

--- ./netlify/functions/processes/outfit_render.js ---
const sharp = require('sharp');
const { PROMPTS } = require("../prompts");
const {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI,
  optimizeGeminiOutput
} = require("../utils");

/**
 * Generates a description for an outfit based on its items
const { PROMPTS } = require("../prompts");
const {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI,
  optimizeGeminiOutput
} = require("../utils");

/**
 * Generates a description for an outfit based on its items
 * Runs in parallel with image generation for fast user feedback
- Provide exactly 3 style tags
- Keep it concise and actionable

Respond with ONLY the JSON object, no additional text.`;

    // Call Gemini with text-only model (much faster than image generation)
    const response = await callGeminiAPI(
      prompt,
      [], // No images needed for description
      'gemini-2.5-flash', // Fast text model
      'TEXT',
- Keep it concise and actionable

Respond with ONLY the JSON object, no additional text.`;

    // Call Gemini with text-only model (much faster than image generation)
    const response = await callGeminiAPI(
      prompt,
      [], // No images needed for description
      'gemini-2.5-flash', // Fast text model
      'TEXT',
      perfTracker,

    // Parse the JSON response
    const description = parseDescriptionResponse(response);
    
    // Save to database immediately
    const { error: updateError } = await supabase
      .from('outfits')
      .update({
        description: description.description,
        occasions: description.occasions,
        style_tags: description.styleTags,
async function fetchOutfitItemDetails(outfitId, supabase, userId) {
  console.log(`[OutfitDescription] Fetching item details for outfit ${outfitId}`);
  
  try {
    // Use the existing function to get outfit items with wardrobe details
    const { data, error } = await supabase
  .rpc('get_outfit_items_with_details', {
    p_outfit_id: outfitId,
    p_viewer_id: userId,
  });


  const useStackedImage = !!stacked_image_id;
  console.log(`[OutfitRender] Processing outfit ${outfit_id}, using ${useStackedImage ? 'pre-stacked' : 'individual'} images`);

  // Retrieve user settings for default head/body shots, model preference, and headshot inclusion setting
  const { data: userSettings } = await supabase
    .from("user_settings")
    .select("headshot_image_id, body_shot_image_id, ai_model_preference, include_headshot_in_generation")
    .eq("user_id", userId)
    .single();

  // START PARALLEL OPERATIONS
  // 1. Description (fast: 1-3s)  fire-and-forget until end
  // 2. Outfit image(s)  stacked or legacy
  // 3. Body (+ optional headshot)  required for AI
  const descriptionPromise = (async () => {
    const itemDetails = await fetchOutfitItemDetails(outfit_id, supabase, userId);
    if (itemDetails.length > 0) {
      return await generateOutfitDescription(outfit_id, itemDetails, supabase, perfTracker);
    }
    return null;
  })();
  // 2. Outfit image(s)  stacked or legacy
  // 3. Body (+ optional headshot)  required for AI
  const descriptionPromise = (async () => {
    const itemDetails = await fetchOutfitItemDetails(outfit_id, supabase, userId);
    if (itemDetails.length > 0) {
      return await generateOutfitDescription(outfit_id, itemDetails, supabase, perfTracker);
    }
    return null;
  })();

  const outfitImagePromise = (async () => {
  })();

  const outfitImagePromise = (async () => {
    if (useStackedImage) {
      console.log(`[OutfitRender] Downloading pre-stacked image from storage: ${stacked_image_id}`);
      const { data: stackedBlob, error: downloadError } = await supabase
        .storage
        .from('media')
        .download(stacked_image_id);
      if (downloadError) {
        console.error(`[OutfitRender] Storage download error:`, downloadError);
      }
      if (!stackedBlob) {
        throw new Error('Downloaded blob is null or undefined');
      }
      console.log(`[OutfitRender] Downloaded blob size: ${stackedBlob.size} bytes, type: ${stackedBlob.type}`);
      const buffer = await stackedBlob.arrayBuffer();
      console.log(`[OutfitRender] Converted to ArrayBuffer, length: ${buffer.byteLength}`);
      const stackedItemsB64 = Buffer.from(buffer).toString('base64');
      console.log(`[OutfitRender] Converted to base64, length: ${stackedItemsB64.length} chars`);
      const itemCount = settings?.items_count || selected?.length || 0;
      console.log(`[OutfitRender] Pre-stacked image contains ${itemCount} items`);
      return { stackedItemsB64, itemCount };
    }
    // Legacy mode: fetch individual items
    console.log(`[OutfitRender] Legacy mode: fetching ${selected.length} individual items`);
    const wardrobeItemIds = selected.map((s) => s.wardrobe_item_id);
    const { data: allLinks } = await supabase
      .from("wardrobe_item_images")
      .select("wardrobe_item_id, type, sort_order, image_id")
      .in("wardrobe_item_id", wardrobeItemIds);
    const linksByItem = new Map();
    (allLinks || []).forEach((link) => {
    });
    if (!imageIdsToDownload.length) {
      throw new Error("No valid images found for outfit items");
    }
    console.log(`[OutfitRender] Legacy mode: downloading ${imageIdsToDownload.length} images: ${imageIdsToDownload.join(', ')}`);
    const itemImageResults = await Promise.all(
      imageIdsToDownload.map(id => {
        console.log(`[OutfitRender] Downloading item image: ${id}`);
        return downloadImageFromStorage(supabase, id, timingTracker);
      })
    );
    console.log(`[OutfitRender] Downloading body image${includeHeadshot ? ' and headshot' : ''}`);
    const downloadPromises = [downloadImageFromStorage(supabase, bodyId, timingTracker)];
    if (includeHeadshot && headId) {
      downloadPromises.push(downloadImageFromStorage(supabase, headId, timingTracker));
    }
    const downloadedImageResults = await Promise.all(downloadPromises);
    const bodyResult = downloadedImageResults[0];
    const headResult = includeHeadshot && downloadedImageResults[1] ? downloadedImageResults[1] : null;
    if (includeHeadshot && headResult) {
      console.log(`[OutfitRender] Downloaded head (${headResult.base64.length} chars) and body (${bodyResult.base64.length} chars)`);
    } else {
      console.log(`[OutfitRender] Downloaded body (${bodyResult.base64.length} chars), headshot excluded`);
    }
    return { bodyResult, headResult };
  })();

  const [{ stackedItemsB64, itemCount }, { bodyResult, headResult }] = await Promise.all([
    outfitImagePromise,
    bodyImagePromise
  ]);

  // Prepare all inputs for Gemini
  const [{ stackedItemsB64, itemCount }, { bodyResult, headResult }] = await Promise.all([
    outfitImagePromise,
    bodyImagePromise
  ]);

  // Prepare all inputs for Gemini
  let allInputs = [bodyResult];
  if (includeHeadshot && headResult) {
    allInputs.push(headResult);
  }
  
  const renderPrompt = useStackedImage 
    ? PROMPTS.OUTFIT_FINAL_STACKED(prompt || 'Style this outfit naturally', itemCount, includeHeadshot)
    : PROMPTS.OUTFIT_FINAL(prompt || 'Style this outfit naturally', itemCount, includeHeadshot);

  console.log(`[OutfitRender] Generating outfit with model: ${preferredModel}`);
  console.log(`[OutfitRender] Calling Gemini API...`);

  // Generate the outfit image
  const finalImageB64 = await callGeminiAPI(
    renderPrompt,
    allInputs,

  console.log(`[OutfitRender] Generating outfit with model: ${preferredModel}`);
  console.log(`[OutfitRender] Calling Gemini API...`);

  // Generate the outfit image
  const finalImageB64 = await callGeminiAPI(
    renderPrompt,
    allInputs,
    preferredModel,
    "IMAGE",
    perfTracker,
  console.log(`[OutfitRender] AI generation complete, result length: ${finalImageB64.length} chars`);

  // Optimize the generated image (with timing for latency debugging)
  console.log(`[OutfitRender] Optimizing generated image...`);
  const optStart = Date.now();
  const optimizedImageB64 = await optimizeGeminiOutput(finalImageB64);
  const optMs = Date.now() - optStart;
  console.log(`[Perf] Optimization took: ${optMs} ms`);
  console.log(`[OutfitRender] Image optimization complete`);

  // Upload the optimized final composite (with timing for latency debugging)

  // Upload the optimized final composite (with timing for latency debugging)
  const timestamp = Date.now();
  const storagePath = `${userId}/ai/outfits/${outfit_id}/${timestamp}.jpg`;
  const uploadStart = Date.now();
  const { imageId, storageKey } = await uploadImageToStorage(
    supabase,
    userId,
    optimizedImageB64,
    storagePath
  );
  const uploadMs = Date.now() - uploadStart;
  console.log(`[Perf] Upload to Supabase took: ${uploadMs} ms`);
  console.log(`[OutfitRender] Uploaded final image: ${storageKey}`);

  // Record the render and update the outfit cover image
  await supabase.from("outfit_renders").insert({
    outfit_id,
    image_id: imageId,
    prompt: prompt || null,
    settings: { 
      ...(settings || {}), 
      used_stacked_image: useStackedImage
    },
    status: "succeeded"
  });

  await supabase
    .from("outfits")
    .update({ cover_image_id: imageId })
    .eq("id", outfit_id);

  console.log(`[OutfitRender] Outfit render complete`);

  console.log(`[OutfitRender] Outfit render complete`);

  // Wait for description to complete (it should be done by now)
  try {
    await descriptionPromise;
    console.log(`[OutfitRender] Description generation completed`);
  } catch (error) {
    console.error(`[OutfitRender] Description generation failed, but continuing:`, error);
  }


--- ./netlify/functions/processes/headshot_generate.js ---

const { PROMPTS } = require("../prompts");
const {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI
} = require("../utils");

/**
 * Generates a headshot for the given selfie. Optional hair and makeup
 * styles can override the defaults. The generated image is stored and
  if (!selfie_image_id) {
    throw new Error("Missing selfie_image_id");
  }
  // Download the selfie used as input
  console.log(`[processHeadshotGenerate] Downloading selfie image: ${selfie_image_id}`);
  const selfieResult = await downloadImageFromStorage(supabase, selfie_image_id, timingTracker);
  console.log(`[processHeadshotGenerate] Downloaded selfie, base64 length: ${selfieResult.base64.length}`);
  
  // Validate base64
  if (!selfieResult.base64 || selfieResult.base64.length === 0) {
    throw new Error("Downloaded image is empty");
  }
  
  const hair = hair_style || "Keep original hair";
  const makeup = makeup_style || "Natural look";
  const prompt = PROMPTS.HEADSHOT(hair, makeup);
  console.log(`[processHeadshotGenerate] Calling Gemini API with prompt length: ${prompt.length}`);
  // Generate the headshot via Gemini - pass full result object to include mime-type
  const headshotB64 = await callGeminiAPI(
    prompt,
    [selfieResult],
    "gemini-2.5-flash-image",
  
  const hair = hair_style || "Keep original hair";
  const makeup = makeup_style || "Natural look";
  const prompt = PROMPTS.HEADSHOT(hair, makeup);
  console.log(`[processHeadshotGenerate] Calling Gemini API with prompt length: ${prompt.length}`);
  // Generate the headshot via Gemini - pass full result object to include mime-type
  const headshotB64 = await callGeminiAPI(
    prompt,
    [selfieResult],
    "gemini-2.5-flash-image",
    "IMAGE",
  const hair = hair_style || "Keep original hair";
  const makeup = makeup_style || "Natural look";
  const prompt = PROMPTS.HEADSHOT(hair, makeup);
  console.log(`[processHeadshotGenerate] Calling Gemini API with prompt length: ${prompt.length}`);
  // Generate the headshot via Gemini - pass full result object to include mime-type
  const headshotB64 = await callGeminiAPI(
    prompt,
    [selfieResult],
    "gemini-2.5-flash-image",
    "IMAGE",
    perfTracker,
    "gemini-2.5-flash-image",
    "IMAGE",
    perfTracker,
    timingTracker
  );
  console.log(`[processHeadshotGenerate] Gemini API returned, headshot base64 length: ${headshotB64?.length || 0}`);
  // Upload and store the headshot
  const timestamp = Date.now();
  const storagePath = `${userId}/ai/headshots/${timestamp}.jpg`;
  const { imageId, storageKey } = await uploadImageToStorage(
    supabase,
  );
  console.log(`[processHeadshotGenerate] Gemini API returned, headshot base64 length: ${headshotB64?.length || 0}`);
  // Upload and store the headshot
  const timestamp = Date.now();
  const storagePath = `${userId}/ai/headshots/${timestamp}.jpg`;
  const { imageId, storageKey } = await uploadImageToStorage(
    supabase,
    userId,
    headshotB64,
    storagePath
  );
    userId,
    headshotB64,
    storagePath
  );
  // Update the user's settings to reference the new headshot
  await supabase
    .from("user_settings")
    .update({ headshot_image_id: imageId })
    .eq("user_id", userId);
  return { image_id: imageId, storage_key: storageKey };
}

--- ./.netlify/functions-serve/utils/netlify/functions/utils.js ---
async function getFetch() {
  if (typeof fetch !== "undefined") {
    return fetch;
  }
  if (!fetchFn) {
    const nodeFetch = await Promise.resolve().then(() => __toESM(require_lib2()));
    fetchFn = nodeFetch.default;
  }
  return fetchFn;
}
function createTimingTracker() {
    supabaseHostname,
    hasSupabaseClient: !!supabase,
    clientProperties: supabase ? Object.keys(supabase).filter((k) => !k.startsWith("_")).join(", ") : "N/A"
  });
  console.log(`[downloadImageFromStorage] Starting download for imageId: ${imageId}`);
  const { data: image, error } = await supabase.from("images").select("storage_bucket, storage_key, mime_type").eq("id", imageId).single();
  if (error || !image) {
    console.error(`[downloadImageFromStorage] Image not found: ${imageId}`, error);
    throw new Error(`Image not found: ${imageId}`);
  }
  console.log(`[downloadImageFromStorage] Found image record: bucket=${image.storage_bucket}, key=${image.storage_key}`);
  }
  console.log(`[downloadImageFromStorage] Found image record: bucket=${image.storage_bucket}, key=${image.storage_key}`);
  const bucket = image.storage_bucket || "media";
  const signedUrlStart = performance.now();
  console.log(`[downloadImageFromStorage] Generating signed URL for direct download...`);
  const { data: signedUrlData, error: signedUrlError } = await supabase.storage.from(bucket).createSignedUrl(image.storage_key, 60);
  if (signedUrlError || !signedUrlData?.signedUrl) {
    console.error(`[downloadImageFromStorage] Failed to create signed URL:`, signedUrlError);
    throw new Error(`Failed to create signed URL: ${signedUrlError?.message || "Unknown error"}`);
  }
  const signedUrlEnd = performance.now();
  const signedUrlEnd = performance.now();
  const signedUrlDuration = signedUrlEnd - signedUrlStart;
  console.log(`[downloadImageFromStorage] Signed URL generated in ${(signedUrlDuration / 1e3).toFixed(2)}s: ${signedUrlData.signedUrl.substring(0, 80)}...`);
  const downloadStart = performance.now();
  console.log(`[downloadImageFromStorage] Downloading directly from signed URL (CDN/S3 path)...`);
  const fetchResponse = await fetch(signedUrlData.signedUrl);
  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text().catch(() => "Unknown error");
    console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
    throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
  }
  console.log(`[downloadImageFromStorage] Signed URL generated in ${(signedUrlDuration / 1e3).toFixed(2)}s: ${signedUrlData.signedUrl.substring(0, 80)}...`);
  const downloadStart = performance.now();
  console.log(`[downloadImageFromStorage] Downloading directly from signed URL (CDN/S3 path)...`);
  const fetchResponse = await fetch(signedUrlData.signedUrl);
  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text().catch(() => "Unknown error");
    console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
    throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
  }
  const arrayBuffer = await fetchResponse.arrayBuffer();
  const downloadEnd = performance.now();
  if (!fetchResponse.ok) {
    const errorText = await fetchResponse.text().catch(() => "Unknown error");
    console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
    throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
  }
  const arrayBuffer = await fetchResponse.arrayBuffer();
  const downloadEnd = performance.now();
  const downloadDuration = downloadEnd - downloadStart;
  if (timingTracker) {
    timingTracker.addStorageDownload(downloadDuration);
  }
  const isPng = isPngBase64(base64Data);
  const mimeType = isPng ? "image/png" : "image/jpeg";
  const rawBase64 = base64Data.replace(/^data:image\/\w+;base64,/, "");
  const buffer = Buffer.from(rawBase64, "base64");
  const blob = new Blob([buffer], { type: mimeType });
  const { data: uploadData, error: uploadError } = await supabase.storage.from("media").upload(storagePath, blob, {
    cacheControl: "3600",
    upsert: false,
    contentType: mimeType
  });
  if (uploadError || !uploadData) {
    contentType: mimeType
  });
  if (uploadError || !uploadData) {
    throw new Error(`Failed to upload: ${uploadError?.message}`);
  }
  const { data: imageRecord, error: imageError } = await supabase.from("images").insert({
    owner_user_id: userId,
    storage_bucket: "media",
    storage_key: uploadData.path,
    mime_type: mimeType,
    source: "ai_generated"
  if (imageError || !imageRecord) {
    throw new Error(`Failed to create DB record: ${imageError?.message}`);
  }
  return { imageId: imageRecord.id, storageKey: uploadData.path };
}
async function callGeminiAPI(prompt, images, model = "gemini-2.5-flash-image", responseType = "IMAGE", perfTracker = null, timingTracker = null) {
  const GEMINI_API_KEY = process.env.GEMINI_API_KEY || "";
  if (!GEMINI_API_KEY) {
    throw new Error("GEMINI_API_KEY missing");
  }
  const imageCount = Array.isArray(images) ? images.length : images ? 1 : 0;
    temperature: responseType === "TEXT" ? 0.3 : 0.4
  };
  if (responseType === "IMAGE") {
    generationConfig.response_modalities = ["IMAGE"];
  }
  const fetchFn2 = await getFetch();
  const response = await fetchFn2(
    `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
  };
  if (responseType === "IMAGE") {
    generationConfig.response_modalities = ["IMAGE"];
  }
  const fetchFn2 = await getFetch();
  const response = await fetchFn2(
    `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
          { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_ONLY_HIGH" }
        ]
      })
    }
  );
  const data = await response.json();
  if (!response.ok || data.error) {
    console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
    console.error("[GeminiAPI] Request details:", {
      model,
      responseType,
      })
    }
  );
  const data = await response.json();
  if (!response.ok || data.error) {
    console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
    console.error("[GeminiAPI] Request details:", {
      model,
      responseType,
      promptLength: prompt.length,
      imageCount: images.length,
    }
  );
  const data = await response.json();
  if (!response.ok || data.error) {
    console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
    console.error("[GeminiAPI] Request details:", {
      model,
      responseType,
      promptLength: prompt.length,
      imageCount: images.length,
      firstImageLength: images[0]?.length || 0,
      promptLength: prompt.length,
      imageCount: images.length,
      firstImageLength: images[0]?.length || 0,
      firstImagePreview: images[0]?.substring(0, 100) || "N/A"
    });
    const errorMessage = data.error?.message || data.error || "Gemini API Error";
    throw new Error(errorMessage);
  }
  const candidate = data.candidates?.[0];
  if (!candidate) {
    throw new Error("No candidates returned");
  const apiCallEnd = performance.now();
  const apiCallDuration = apiCallEnd - apiCallStart;
  if (timingTracker) {
    timingTracker.addApiCall(apiCallDuration);
  }
  console.log(`[callGeminiAPI] External API call completed in ${(apiCallDuration / 1e3).toFixed(2)}s (${responseType})`);
  if (perfTracker) {
    if (responseType === "TEXT") {
      perfTracker.endTextGen();
    } else {
      perfTracker.endImageGen();
        const rawBase64 = imageInput.replace(/^data:image\/\w+;base64,/, "");
        imageBuffer = Buffer.from(rawBase64, "base64");
      } else {
        imageBuffer = imageInput;
      }
      const resizedImage = await sharp(imageBuffer).resize(cellWidth, cellHeight, {
        fit: "contain",
        background: BACKGROUND_COLOR
      }).toBuffer();
      const metadata = await sharp(resizedImage).metadata();
      const actualWidth = metadata.width;
      }
      const resizedImage = await sharp(imageBuffer).resize(cellWidth, cellHeight, {
        fit: "contain",
        background: BACKGROUND_COLOR
      }).toBuffer();
      const metadata = await sharp(resizedImage).metadata();
      const actualWidth = metadata.width;
      const actualHeight = metadata.height;
      const offsetX = x + Math.floor((cellWidth - actualWidth) / 2);
      const offsetY = y + Math.floor((cellHeight - actualHeight) / 2);
      composites.push({
      console.error(`[compositeOutfitGrid] Error processing image ${i + 1}:`, error);
      throw new Error(`Failed to process image ${i + 1}: ${error.message}`);
    }
  }
  console.log(`[compositeOutfitGrid] Compositing ${composites.length} images...`);
  const finalImage = await canvas.composite(composites).jpeg({ quality: 95 }).toBuffer();
  const base64 = finalImage.toString("base64");
  console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
  return base64;
}
async function optimizeGeminiOutput(base64String) {
  const finalImage = await canvas.composite(composites).jpeg({ quality: 95 }).toBuffer();
  const base64 = finalImage.toString("base64");
  console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
  return base64;
}
async function optimizeGeminiOutput(base64String) {
  console.log("[optimizeGeminiOutput] Starting optimization...");
  try {
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
    const inputBuffer = Buffer.from(rawBase64, "base64");
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
  const base64 = finalImage.toString("base64");
  console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
  return base64;
}
async function optimizeGeminiOutput(base64String) {
  console.log("[optimizeGeminiOutput] Starting optimization...");
  try {
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
    const inputBuffer = Buffer.from(rawBase64, "base64");
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const originalMetadata = await sharp(inputBuffer).metadata();
async function optimizeGeminiOutput(base64String) {
  console.log("[optimizeGeminiOutput] Starting optimization...");
  try {
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
    const inputBuffer = Buffer.from(rawBase64, "base64");
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const originalMetadata = await sharp(inputBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
    const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
      withoutEnlargement: true,
      fit: "inside"
  console.log("[optimizeGeminiOutput] Starting optimization...");
  try {
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
    const inputBuffer = Buffer.from(rawBase64, "base64");
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const originalMetadata = await sharp(inputBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
    const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
      withoutEnlargement: true,
      fit: "inside"
    }).jpeg({
  try {
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
    const inputBuffer = Buffer.from(rawBase64, "base64");
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const originalMetadata = await sharp(inputBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
    const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
      withoutEnlargement: true,
      fit: "inside"
    }).jpeg({
      quality: 80,
    const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
    const inputBuffer = Buffer.from(rawBase64, "base64");
    console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const originalMetadata = await sharp(inputBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
    const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
      withoutEnlargement: true,
      fit: "inside"
    }).jpeg({
      quality: 80,
      mozjpeg: true
      fit: "inside"
    }).jpeg({
      quality: 80,
      mozjpeg: true
    }).toBuffer();
    console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    const optimizedBase64 = optimizedBuffer.toString("base64");
    }).jpeg({
      quality: 80,
      mozjpeg: true
    }).toBuffer();
    console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    const optimizedBase64 = optimizedBuffer.toString("base64");
    console.log("[optimizeGeminiOutput] Optimization complete");
      quality: 80,
      mozjpeg: true
    }).toBuffer();
    console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    const optimizedBase64 = optimizedBuffer.toString("base64");
    console.log("[optimizeGeminiOutput] Optimization complete");
    return optimizedBase64;
    }).toBuffer();
    console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    const optimizedBase64 = optimizedBuffer.toString("base64");
    console.log("[optimizeGeminiOutput] Optimization complete");
    return optimizedBase64;
  } catch (error) {
    console.error("[optimizeGeminiOutput] Optimization failed:", error);
    const optimizedMetadata = await sharp(optimizedBuffer).metadata();
    console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
    const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    const optimizedBase64 = optimizedBuffer.toString("base64");
    console.log("[optimizeGeminiOutput] Optimization complete");
    return optimizedBase64;
  } catch (error) {
    console.error("[optimizeGeminiOutput] Optimization failed:", error);
    console.warn("[optimizeGeminiOutput] Returning original image due to error");
    return base64String;
    console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
    const optimizedBase64 = optimizedBuffer.toString("base64");
    console.log("[optimizeGeminiOutput] Optimization complete");
    return optimizedBase64;
  } catch (error) {
    console.error("[optimizeGeminiOutput] Optimization failed:", error);
    console.warn("[optimizeGeminiOutput] Returning original image due to error");
    return base64String;
  }
}
module.exports = {
    const optimizedBase64 = optimizedBuffer.toString("base64");
    console.log("[optimizeGeminiOutput] Optimization complete");
    return optimizedBase64;
  } catch (error) {
    console.error("[optimizeGeminiOutput] Optimization failed:", error);
    console.warn("[optimizeGeminiOutput] Returning original image due to error");
    return base64String;
  }
}
module.exports = {
  downloadImageFromStorage,
  }
}
module.exports = {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI,
  compositeOutfitGrid,
  optimizeGeminiOutput,
  createPerformanceTracker,
  createTimingTracker
};
module.exports = {
  downloadImageFromStorage,
  uploadImageToStorage,
  callGeminiAPI,
  compositeOutfitGrid,
  optimizeGeminiOutput,
  createPerformanceTracker,
  createTimingTracker
};
//# sourceMappingURL=utils.js.map

--- ./.netlify/functions-serve/style-advice/netlify/functions/style-advice.js ---
{
    "advice": "your styling advice text here",
    "suggestedItems": []
}`;
    }
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image:generateContent?key=${apiKey}`,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
            temperature: 0.7
          }
        })
      }
    );
    const data = await response.json();
    if (!response.ok || data.error) {
      throw new Error(data.error?.message || "API error");
    }
    const textResult = data.candidates[0]?.content?.parts[0]?.text;
    if (!textResult) {

--- ./.netlify/functions-serve/auto-tag-item/netlify/functions/auto-tag-item.js ---
    "estimatedSize": "if detectable: XS, S, M, L, XL, or null if not detectable",
    "itemType": "specific item type (e.g. t-shirt, jeans, sneakers, watch)"
}

Return ONLY valid JSON, no other text.`;
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image:generateContent?key=${apiKey}`,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
            temperature: 0.3
          }
        })
      }
    );
    const data = await response.json();
    if (!response.ok || data.error) {
      throw new Error(data.error?.message || "API error");
    }
    const textResult = data.candidates[0]?.content?.parts[0]?.text;
    if (!textResult) {

--- ./.netlify/functions-serve/ai-job-runner/netlify/functions/ai-job-runner.js ---
    async function getFetch() {
      if (typeof fetch !== "undefined") {
        return fetch;
      }
      if (!fetchFn) {
        const nodeFetch = await Promise.resolve().then(() => __toESM(require_lib2()));
        fetchFn = nodeFetch.default;
      }
      return fetchFn;
    }
    function createTimingTracker2() {
        supabaseHostname,
        hasSupabaseClient: !!supabase,
        clientProperties: supabase ? Object.keys(supabase).filter((k) => !k.startsWith("_")).join(", ") : "N/A"
      });
      console.log(`[downloadImageFromStorage] Starting download for imageId: ${imageId}`);
      const { data: image, error } = await supabase.from("images").select("storage_bucket, storage_key, mime_type").eq("id", imageId).single();
      if (error || !image) {
        console.error(`[downloadImageFromStorage] Image not found: ${imageId}`, error);
        throw new Error(`Image not found: ${imageId}`);
      }
      console.log(`[downloadImageFromStorage] Found image record: bucket=${image.storage_bucket}, key=${image.storage_key}`);
      }
      console.log(`[downloadImageFromStorage] Found image record: bucket=${image.storage_bucket}, key=${image.storage_key}`);
      const bucket = image.storage_bucket || "media";
      const signedUrlStart = performance.now();
      console.log(`[downloadImageFromStorage] Generating signed URL for direct download...`);
      const { data: signedUrlData, error: signedUrlError } = await supabase.storage.from(bucket).createSignedUrl(image.storage_key, 60);
      if (signedUrlError || !signedUrlData?.signedUrl) {
        console.error(`[downloadImageFromStorage] Failed to create signed URL:`, signedUrlError);
        throw new Error(`Failed to create signed URL: ${signedUrlError?.message || "Unknown error"}`);
      }
      const signedUrlEnd = performance.now();
      const signedUrlEnd = performance.now();
      const signedUrlDuration = signedUrlEnd - signedUrlStart;
      console.log(`[downloadImageFromStorage] Signed URL generated in ${(signedUrlDuration / 1e3).toFixed(2)}s: ${signedUrlData.signedUrl.substring(0, 80)}...`);
      const downloadStart = performance.now();
      console.log(`[downloadImageFromStorage] Downloading directly from signed URL (CDN/S3 path)...`);
      const fetchResponse = await fetch(signedUrlData.signedUrl);
      if (!fetchResponse.ok) {
        const errorText = await fetchResponse.text().catch(() => "Unknown error");
        console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
        throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
      }
      console.log(`[downloadImageFromStorage] Signed URL generated in ${(signedUrlDuration / 1e3).toFixed(2)}s: ${signedUrlData.signedUrl.substring(0, 80)}...`);
      const downloadStart = performance.now();
      console.log(`[downloadImageFromStorage] Downloading directly from signed URL (CDN/S3 path)...`);
      const fetchResponse = await fetch(signedUrlData.signedUrl);
      if (!fetchResponse.ok) {
        const errorText = await fetchResponse.text().catch(() => "Unknown error");
        console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
        throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
      }
      const arrayBuffer = await fetchResponse.arrayBuffer();
      const downloadEnd = performance.now();
      if (!fetchResponse.ok) {
        const errorText = await fetchResponse.text().catch(() => "Unknown error");
        console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
        throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
      }
      const arrayBuffer = await fetchResponse.arrayBuffer();
      const downloadEnd = performance.now();
      const downloadDuration = downloadEnd - downloadStart;
      if (timingTracker) {
        timingTracker.addStorageDownload(downloadDuration);
      }
      const isPng = isPngBase64(base64Data);
      const mimeType = isPng ? "image/png" : "image/jpeg";
      const rawBase64 = base64Data.replace(/^data:image\/\w+;base64,/, "");
      const buffer = Buffer.from(rawBase64, "base64");
      const blob = new Blob([buffer], { type: mimeType });
      const { data: uploadData, error: uploadError } = await supabase.storage.from("media").upload(storagePath, blob, {
        cacheControl: "3600",
        upsert: false,
        contentType: mimeType
      });
      if (uploadError || !uploadData) {
        contentType: mimeType
      });
      if (uploadError || !uploadData) {
        throw new Error(`Failed to upload: ${uploadError?.message}`);
      }
      const { data: imageRecord, error: imageError } = await supabase.from("images").insert({
        owner_user_id: userId,
        storage_bucket: "media",
        storage_key: uploadData.path,
        mime_type: mimeType,
        source: "ai_generated"
      if (imageError || !imageRecord) {
        throw new Error(`Failed to create DB record: ${imageError?.message}`);
      }
      return { imageId: imageRecord.id, storageKey: uploadData.path };
    }
    async function callGeminiAPI(prompt, images, model = "gemini-2.5-flash-image", responseType = "IMAGE", perfTracker = null, timingTracker = null) {
      const GEMINI_API_KEY = process.env.GEMINI_API_KEY || "";
      if (!GEMINI_API_KEY) {
        throw new Error("GEMINI_API_KEY missing");
      }
      const imageCount = Array.isArray(images) ? images.length : images ? 1 : 0;
        temperature: responseType === "TEXT" ? 0.3 : 0.4
      };
      if (responseType === "IMAGE") {
        generationConfig.response_modalities = ["IMAGE"];
      }
      const fetchFn2 = await getFetch();
      const response = await fetchFn2(
        `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
      };
      if (responseType === "IMAGE") {
        generationConfig.response_modalities = ["IMAGE"];
      }
      const fetchFn2 = await getFetch();
      const response = await fetchFn2(
        `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
              { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_ONLY_HIGH" }
            ]
          })
        }
      );
      const data = await response.json();
      if (!response.ok || data.error) {
        console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
        console.error("[GeminiAPI] Request details:", {
          model,
          responseType,
          })
        }
      );
      const data = await response.json();
      if (!response.ok || data.error) {
        console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
        console.error("[GeminiAPI] Request details:", {
          model,
          responseType,
          promptLength: prompt.length,
          imageCount: images.length,
        }
      );
      const data = await response.json();
      if (!response.ok || data.error) {
        console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
        console.error("[GeminiAPI] Request details:", {
          model,
          responseType,
          promptLength: prompt.length,
          imageCount: images.length,
          firstImageLength: images[0]?.length || 0,
          promptLength: prompt.length,
          imageCount: images.length,
          firstImageLength: images[0]?.length || 0,
          firstImagePreview: images[0]?.substring(0, 100) || "N/A"
        });
        const errorMessage = data.error?.message || data.error || "Gemini API Error";
        throw new Error(errorMessage);
      }
      const candidate = data.candidates?.[0];
      if (!candidate) {
        throw new Error("No candidates returned");
      const apiCallEnd = performance.now();
      const apiCallDuration = apiCallEnd - apiCallStart;
      if (timingTracker) {
        timingTracker.addApiCall(apiCallDuration);
      }
      console.log(`[callGeminiAPI] External API call completed in ${(apiCallDuration / 1e3).toFixed(2)}s (${responseType})`);
      if (perfTracker) {
        if (responseType === "TEXT") {
          perfTracker.endTextGen();
        } else {
          perfTracker.endImageGen();
            const rawBase64 = imageInput.replace(/^data:image\/\w+;base64,/, "");
            imageBuffer = Buffer.from(rawBase64, "base64");
          } else {
            imageBuffer = imageInput;
          }
          const resizedImage = await sharp(imageBuffer).resize(cellWidth, cellHeight, {
            fit: "contain",
            background: BACKGROUND_COLOR
          }).toBuffer();
          const metadata = await sharp(resizedImage).metadata();
          const actualWidth = metadata.width;
          }
          const resizedImage = await sharp(imageBuffer).resize(cellWidth, cellHeight, {
            fit: "contain",
            background: BACKGROUND_COLOR
          }).toBuffer();
          const metadata = await sharp(resizedImage).metadata();
          const actualWidth = metadata.width;
          const actualHeight = metadata.height;
          const offsetX = x + Math.floor((cellWidth - actualWidth) / 2);
          const offsetY = y + Math.floor((cellHeight - actualHeight) / 2);
          composites.push({
          console.error(`[compositeOutfitGrid] Error processing image ${i + 1}:`, error);
          throw new Error(`Failed to process image ${i + 1}: ${error.message}`);
        }
      }
      console.log(`[compositeOutfitGrid] Compositing ${composites.length} images...`);
      const finalImage = await canvas.composite(composites).jpeg({ quality: 95 }).toBuffer();
      const base64 = finalImage.toString("base64");
      console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
      return base64;
    }
    async function optimizeGeminiOutput(base64String) {
      const finalImage = await canvas.composite(composites).jpeg({ quality: 95 }).toBuffer();
      const base64 = finalImage.toString("base64");
      console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
      return base64;
    }
    async function optimizeGeminiOutput(base64String) {
      console.log("[optimizeGeminiOutput] Starting optimization...");
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
      const base64 = finalImage.toString("base64");
      console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
      return base64;
    }
    async function optimizeGeminiOutput(base64String) {
      console.log("[optimizeGeminiOutput] Starting optimization...");
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
    async function optimizeGeminiOutput(base64String) {
      console.log("[optimizeGeminiOutput] Starting optimization...");
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
        const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
          withoutEnlargement: true,
          fit: "inside"
      console.log("[optimizeGeminiOutput] Starting optimization...");
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
        const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
          withoutEnlargement: true,
          fit: "inside"
        }).jpeg({
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
        const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
          withoutEnlargement: true,
          fit: "inside"
        }).jpeg({
          quality: 80,
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
        const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
          withoutEnlargement: true,
          fit: "inside"
        }).jpeg({
          quality: 80,
          mozjpeg: true
          fit: "inside"
        }).jpeg({
          quality: 80,
          mozjpeg: true
        }).toBuffer();
        console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        }).jpeg({
          quality: 80,
          mozjpeg: true
        }).toBuffer();
        console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
          quality: 80,
          mozjpeg: true
        }).toBuffer();
        console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
        }).toBuffer();
        console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
      } catch (error) {
        console.error("[optimizeGeminiOutput] Optimization failed:", error);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
      } catch (error) {
        console.error("[optimizeGeminiOutput] Optimization failed:", error);
        console.warn("[optimizeGeminiOutput] Returning original image due to error");
        return base64String;
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
      } catch (error) {
        console.error("[optimizeGeminiOutput] Optimization failed:", error);
        console.warn("[optimizeGeminiOutput] Returning original image due to error");
        return base64String;
      }
    }
    module2.exports = {
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
      } catch (error) {
        console.error("[optimizeGeminiOutput] Optimization failed:", error);
        console.warn("[optimizeGeminiOutput] Returning original image due to error");
        return base64String;
      }
    }
    module2.exports = {
      downloadImageFromStorage: downloadImageFromStorage2,
      }
    }
    module2.exports = {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI,
      compositeOutfitGrid,
      optimizeGeminiOutput,
      createPerformanceTracker: createPerformanceTracker2,
      createTimingTracker: createTimingTracker2
    };
    module2.exports = {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI,
      compositeOutfitGrid,
      optimizeGeminiOutput,
      createPerformanceTracker: createPerformanceTracker2,
      createTimingTracker: createTimingTracker2
    };
  }
});
// netlify/functions/processes/auto_tag.js
var require_auto_tag = __commonJS({
  "netlify/functions/processes/auto_tag.js"(exports2, module2) {
    "use strict";
    var { PROMPTS } = require_prompts();
    var { downloadImageFromStorage: downloadImageFromStorage2, callGeminiAPI } = require_utils2();
    async function processAutoTag2(input, supabase, perfTracker = null, timingTracker = null, preDownloadedImageData = null) {
      const { wardrobe_item_id, image_ids } = input;
      if (!wardrobe_item_id || !image_ids?.length) {
        throw new Error("Missing ID or images");
      }
        imageB64Promise = Promise.resolve(preDownloadedImageData);
      } else {
        console.log(`[processAutoTag] Downloading image from storage (image_id: ${image_ids[0]})...`);
        imageB64Promise = downloadImageFromStorage2(supabase, image_ids[0], timingTracker);
      }
      const [imageResult, catRes, subRes, attrRes] = await Promise.all([
        imageB64Promise,
        supabase.from("wardrobe_categories").select("id, name").order("sort_order"),
        supabase.from("wardrobe_subcategories").select("id, name, category_id").order("sort_order"),
        supabase.from("attribute_definitions").select("id, key, name")
      ]);
      const categories = catRes.data || [];
      const subcategories = subRes.data || [];
      const catList = categories.map((c) => c.name).join(", ");
      const subList = subcategories.map((s) => s.name).join(", ");
      const prompt = PROMPTS.AUTO_TAG(catList, subList);
      const textResult = await callGeminiAPI(prompt, [imageResult], "gemini-2.5-flash-image", "TEXT", perfTracker, timingTracker);
      let result;
      try {
        const cleaned = textResult.replace(/```json\n?/g, "").replace(/```\n?/g, "").trim();
        result = JSON.parse(cleaned);
      } catch (e) {
      const attributesToInsert = [];
      for (const attr of result.attributes || []) {
        const defId = defMap.get(attr.key);
        if (!defId) continue;
        for (const val of attr.values || []) {
          let { data: value } = await supabase.from("attribute_values").select("id").eq("definition_id", defId).ilike("value", val.value).single();
          if (!value) {
            const { data: newValue } = await supabase.from("attribute_values").insert({ definition_id: defId, value: val.value }).select("id").single();
            value = newValue;
          }
          if (value?.id) {
        const defId = defMap.get(attr.key);
        if (!defId) continue;
        for (const val of attr.values || []) {
          let { data: value } = await supabase.from("attribute_values").select("id").eq("definition_id", defId).ilike("value", val.value).single();
          if (!value) {
            const { data: newValue } = await supabase.from("attribute_values").insert({ definition_id: defId, value: val.value }).select("id").single();
            value = newValue;
          }
          if (value?.id) {
            attributesToInsert.push({
              entity_type: "wardrobe_item",
            });
          }
        }
      }
      if (attributesToInsert.length) {
        await supabase.from("entity_attributes").insert(attributesToInsert);
      }
      const updates = {};
      if (result.suggested_title) updates.title = result.suggested_title;
      if (result.suggested_notes) updates.description = result.suggested_notes;
      const colorAttr = result.attributes?.find((a) => a.key === "color");
            updates.subcategory_id = null;
          }
        }
      }
      if (Object.keys(updates).length > 0) {
        await supabase.from("wardrobe_items").update(updates).eq("id", wardrobe_item_id);
      }
      return { ...result, updates_applied: updates };
    }
    module2.exports = { processAutoTag: processAutoTag2 };
  }
    "use strict";
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI
    } = require_utils2();
    async function processProductShot2(input, supabase, userId, perfTracker = null, timingTracker = null, preDownloadedImageData = null) {
      const { image_id, wardrobe_item_id } = input;
      if (!image_id || !wardrobe_item_id) {
        throw new Error("Missing ID or wardrobe_item_id");
      if (preDownloadedImageData && preDownloadedImageData.base64) {
        console.log(`[processProductShot] Using pre-downloaded image (skipping storage download, saving ~5s)`);
        imageResult = preDownloadedImageData;
      } else {
        console.log(`[processProductShot] Downloading image from storage (image_id: ${image_id})...`);
        imageResult = await downloadImageFromStorage2(supabase, image_id, timingTracker);
      }
      const productShotB64 = await callGeminiAPI(
        PROMPTS.PRODUCT_SHOT,
        [imageResult],
        "gemini-2.5-flash-image",
        imageResult = preDownloadedImageData;
      } else {
        console.log(`[processProductShot] Downloading image from storage (image_id: ${image_id})...`);
        imageResult = await downloadImageFromStorage2(supabase, image_id, timingTracker);
      }
      const productShotB64 = await callGeminiAPI(
        PROMPTS.PRODUCT_SHOT,
        [imageResult],
        "gemini-2.5-flash-image",
        "IMAGE",
        perfTracker,
        perfTracker,
        timingTracker
      );
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/product_shots/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        productShotB64,
        storagePath
      );
        supabase,
        userId,
        productShotB64,
        storagePath
      );
      const { data: existingImages } = await supabase.from("wardrobe_item_images").select("id, sort_order").eq("wardrobe_item_id", wardrobe_item_id).order("sort_order", { ascending: false });
      for (const img of existingImages || []) {
        await supabase.from("wardrobe_item_images").update({ sort_order: (img.sort_order || 0) + 1 }).eq("id", img.id);
      }
      await supabase.from("wardrobe_item_images").insert({
        wardrobe_item_id,
        productShotB64,
        storagePath
      );
      const { data: existingImages } = await supabase.from("wardrobe_item_images").select("id, sort_order").eq("wardrobe_item_id", wardrobe_item_id).order("sort_order", { ascending: false });
      for (const img of existingImages || []) {
        await supabase.from("wardrobe_item_images").update({ sort_order: (img.sort_order || 0) + 1 }).eq("id", img.id);
      }
      await supabase.from("wardrobe_item_images").insert({
        wardrobe_item_id,
        image_id: imageId,
        type: "product_shot",
      );
      const { data: existingImages } = await supabase.from("wardrobe_item_images").select("id, sort_order").eq("wardrobe_item_id", wardrobe_item_id).order("sort_order", { ascending: false });
      for (const img of existingImages || []) {
        await supabase.from("wardrobe_item_images").update({ sort_order: (img.sort_order || 0) + 1 }).eq("id", img.id);
      }
      await supabase.from("wardrobe_item_images").insert({
        wardrobe_item_id,
        image_id: imageId,
        type: "product_shot",
        sort_order: 0
      });
    "use strict";
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI
    } = require_utils2();
    async function processHeadshotGenerate2(input, supabase, userId, perfTracker = null, timingTracker = null) {
      console.log(`[processHeadshotGenerate] Starting for userId: ${userId}`, input);
      const { selfie_image_id, hair_style, makeup_style } = input;
      if (!selfie_image_id) {
      const { selfie_image_id, hair_style, makeup_style } = input;
      if (!selfie_image_id) {
        throw new Error("Missing selfie_image_id");
      }
      console.log(`[processHeadshotGenerate] Downloading selfie image: ${selfie_image_id}`);
      const selfieResult = await downloadImageFromStorage2(supabase, selfie_image_id, timingTracker);
      console.log(`[processHeadshotGenerate] Downloaded selfie, base64 length: ${selfieResult.base64.length}`);
      if (!selfieResult.base64 || selfieResult.base64.length === 0) {
        throw new Error("Downloaded image is empty");
      }
      const base64Regex = /^[A-Za-z0-9+/]*={0,2}$/;
        throw new Error("Invalid base64 image format");
      }
      const hair = hair_style || "Keep original hair";
      const makeup = makeup_style || "Natural look";
      const prompt = PROMPTS.HEADSHOT(hair, makeup);
      console.log(`[processHeadshotGenerate] Calling Gemini API with prompt length: ${prompt.length}`);
      const headshotB64 = await callGeminiAPI(
        prompt,
        [selfieResult],
        "gemini-2.5-flash-image",
        "IMAGE",
      }
      const hair = hair_style || "Keep original hair";
      const makeup = makeup_style || "Natural look";
      const prompt = PROMPTS.HEADSHOT(hair, makeup);
      console.log(`[processHeadshotGenerate] Calling Gemini API with prompt length: ${prompt.length}`);
      const headshotB64 = await callGeminiAPI(
        prompt,
        [selfieResult],
        "gemini-2.5-flash-image",
        "IMAGE",
        perfTracker,
        "gemini-2.5-flash-image",
        "IMAGE",
        perfTracker,
        timingTracker
      );
      console.log(`[processHeadshotGenerate] Gemini API returned, headshot base64 length: ${headshotB64?.length || 0}`);
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/headshots/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        timingTracker
      );
      console.log(`[processHeadshotGenerate] Gemini API returned, headshot base64 length: ${headshotB64?.length || 0}`);
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/headshots/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        headshotB64,
        storagePath
      );
        supabase,
        userId,
        headshotB64,
        storagePath
      );
      await supabase.from("user_settings").update({ headshot_image_id: imageId }).eq("user_id", userId);
      return { image_id: imageId, storage_key: storageKey };
    }
    module2.exports = { processHeadshotGenerate: processHeadshotGenerate2 };
  }
});
    "use strict";
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI
    } = require_utils2();
    async function processBodyShotGenerate2(input, supabase, userId, perfTracker = null, timingTracker = null) {
      const { body_photo_image_id, headshot_image_id } = input;
      if (!body_photo_image_id) {
        throw new Error("Missing body_photo_image_id");
      if (!body_photo_image_id) {
        throw new Error("Missing body_photo_image_id");
      }
      let headId = headshot_image_id;
      if (!headId) {
        const { data: settings } = await supabase.from("user_settings").select("headshot_image_id").eq("user_id", userId).single();
        headId = settings?.headshot_image_id;
      }
      if (!headId) {
        throw new Error("No headshot available");
      }
        headId = settings?.headshot_image_id;
      }
      if (!headId) {
        throw new Error("No headshot available");
      }
      const [headResult, bodyResult] = await Promise.all([
        downloadImageFromStorage2(supabase, headId, timingTracker),
        downloadImageFromStorage2(supabase, body_photo_image_id, timingTracker)
      ]);
      const studioModelB64 = await callGeminiAPI(
        PROMPTS.BODY_COMPOSITE,
      }
      const [headResult, bodyResult] = await Promise.all([
        downloadImageFromStorage2(supabase, headId, timingTracker),
        downloadImageFromStorage2(supabase, body_photo_image_id, timingTracker)
      ]);
      const studioModelB64 = await callGeminiAPI(
        PROMPTS.BODY_COMPOSITE,
        [headResult, bodyResult],
        "gemini-3-pro-image-preview",
        "IMAGE",
        perfTracker,
        perfTracker,
        timingTracker
      );
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/body_shots/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        studioModelB64,
        storagePath
      );
        supabase,
        userId,
        studioModelB64,
        storagePath
      );
      await supabase.from("user_settings").update({ body_shot_image_id: imageId }).eq("user_id", userId);
      return { image_id: imageId, storage_key: storageKey };
    }
    module2.exports = { processBodyShotGenerate: processBodyShotGenerate2 };
  }
});
    }
    module2.exports = { processBodyShotGenerate: processBodyShotGenerate2 };
  }
});

// netlify/functions/processes/outfit_render.js
var require_outfit_render = __commonJS({
  "netlify/functions/processes/outfit_render.js"(exports2, module2) {
    "use strict";
    var sharp = require("sharp");
    var { PROMPTS } = require_prompts();
    module2.exports = { processBodyShotGenerate: processBodyShotGenerate2 };
  }
});

// netlify/functions/processes/outfit_render.js
var require_outfit_render = __commonJS({
  "netlify/functions/processes/outfit_render.js"(exports2, module2) {
    "use strict";
    var sharp = require("sharp");
    var { PROMPTS } = require_prompts();
    var {
  }
});

// netlify/functions/processes/outfit_render.js
var require_outfit_render = __commonJS({
  "netlify/functions/processes/outfit_render.js"(exports2, module2) {
    "use strict";
    var sharp = require("sharp");
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
    var sharp = require("sharp");
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI,
      optimizeGeminiOutput
    } = require_utils2();
    async function generateOutfitDescription(outfitId, itemDetails, supabase, perfTracker = null) {
      console.log(`[OutfitDescription] Starting description generation for outfit ${outfitId}`);
      const startTime = Date.now();
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI,
      optimizeGeminiOutput
    } = require_utils2();
    async function generateOutfitDescription(outfitId, itemDetails, supabase, perfTracker = null) {
      console.log(`[OutfitDescription] Starting description generation for outfit ${outfitId}`);
      const startTime = Date.now();
      try {
- Style tags should describe the overall vibe (e.g., "minimalist", "preppy", "streetwear")
- Provide exactly 3 style tags
- Keep it concise and actionable

Respond with ONLY the JSON object, no additional text.`;
        const response = await callGeminiAPI(
          prompt,
          [],
          // No images needed for description
          "gemini-2.5-flash",
          // Fast text model
          "TEXT",
          perfTracker,
          null
        );
        const description = parseDescriptionResponse(response);
        const { error: updateError } = await supabase.from("outfits").update({
          description: description.description,
          occasions: description.occasions,
          style_tags: description.styleTags,
          season: description.season,
          description_generated_at: (/* @__PURE__ */ new Date()).toISOString()
      }
    }
    async function fetchOutfitItemDetails(outfitId, supabase, userId) {
      console.log(`[OutfitDescription] Fetching item details for outfit ${outfitId}`);
      try {
        const { data, error } = await supabase.rpc("get_outfit_items_with_details", {
          p_outfit_id: outfitId,
          p_viewer_id: userId
        });
        if (error) {
          console.error(`[OutfitDescription] Error fetching items:`, error);
      if (!stacked_image_id && (!selected || selected.length === 0)) {
        throw new Error("Missing stacked_image_id or selected items");
      }
      const useStackedImage = !!stacked_image_id;
      console.log(`[OutfitRender] Processing outfit ${outfit_id}, using ${useStackedImage ? "pre-stacked" : "individual"} images`);
      const { data: userSettings } = await supabase.from("user_settings").select("headshot_image_id, body_shot_image_id, ai_model_preference, include_headshot_in_generation").eq("user_id", userId).single();
      const bodyId = userSettings?.body_shot_image_id;
      const includeHeadshot = userSettings?.include_headshot_in_generation ?? false;
      const headId = includeHeadshot ? headshot_image_id || userSettings?.headshot_image_id : null;
      if (!bodyId) {
        throw new Error("Missing body shot");
      if (includeHeadshot && !headId) {
        throw new Error("Missing headshot (required when include_headshot_in_generation is enabled)");
      }
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      const descriptionPromise = (async () => {
        const itemDetails = await fetchOutfitItemDetails(outfit_id, supabase, userId);
        if (itemDetails.length > 0) {
          return await generateOutfitDescription(outfit_id, itemDetails, supabase, perfTracker);
        }
        return null;
      })();
      }
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      const descriptionPromise = (async () => {
        const itemDetails = await fetchOutfitItemDetails(outfit_id, supabase, userId);
        if (itemDetails.length > 0) {
          return await generateOutfitDescription(outfit_id, itemDetails, supabase, perfTracker);
        }
        return null;
      })();
      const outfitImagePromise = (async () => {
        if (useStackedImage) {
        return null;
      })();
      const outfitImagePromise = (async () => {
        if (useStackedImage) {
          console.log(`[OutfitRender] Downloading pre-stacked image from storage: ${stacked_image_id}`);
          const { data: stackedBlob, error: downloadError } = await supabase.storage.from("media").download(stacked_image_id);
          if (downloadError) {
            console.error(`[OutfitRender] Storage download error:`, downloadError);
            throw new Error(`Failed to download stacked image: ${downloadError.message}`);
          }
          if (!stackedBlob) {
          }
          if (!stackedBlob) {
            throw new Error("Downloaded blob is null or undefined");
          }
          console.log(`[OutfitRender] Downloaded blob size: ${stackedBlob.size} bytes, type: ${stackedBlob.type}`);
          const buffer = await stackedBlob.arrayBuffer();
          console.log(`[OutfitRender] Converted to ArrayBuffer, length: ${buffer.byteLength}`);
          const stackedItemsB643 = Buffer.from(buffer).toString("base64");
          console.log(`[OutfitRender] Converted to base64, length: ${stackedItemsB643.length} chars`);
          const itemCount3 = settings?.items_count || selected?.length || 0;
          console.log(`[OutfitRender] Pre-stacked image contains ${itemCount3} items`);
          console.log(`[OutfitRender] Pre-stacked image contains ${itemCount3} items`);
          return { stackedItemsB64: stackedItemsB643, itemCount: itemCount3 };
        }
        console.log(`[OutfitRender] Legacy mode: fetching ${selected.length} individual items`);
        const wardrobeItemIds = selected.map((s) => s.wardrobe_item_id);
        const { data: allLinks } = await supabase.from("wardrobe_item_images").select("wardrobe_item_id, type, sort_order, image_id").in("wardrobe_item_id", wardrobeItemIds);
        const linksByItem = /* @__PURE__ */ new Map();
        (allLinks || []).forEach((link) => {
          if (!linksByItem.has(link.wardrobe_item_id)) {
            linksByItem.set(link.wardrobe_item_id, []);
          }
        });
        if (!imageIdsToDownload.length) {
          throw new Error("No valid images found for outfit items");
        }
        console.log(`[OutfitRender] Legacy mode: downloading ${imageIdsToDownload.length} images: ${imageIdsToDownload.join(", ")}`);
        const itemImageResults = await Promise.all(
          imageIdsToDownload.map((id) => {
            console.log(`[OutfitRender] Downloading item image: ${id}`);
            return downloadImageFromStorage2(supabase, id, timingTracker);
          })
        );
        console.log(`[OutfitRender] Downloading body image${includeHeadshot ? " and headshot" : ""}`);
        const downloadPromises = [downloadImageFromStorage2(supabase, bodyId, timingTracker)];
        if (includeHeadshot && headId) {
          downloadPromises.push(downloadImageFromStorage2(supabase, headId, timingTracker));
        }
        const downloadedImageResults = await Promise.all(downloadPromises);
        const bodyResult2 = downloadedImageResults[0];
        const headResult2 = includeHeadshot && downloadedImageResults[1] ? downloadedImageResults[1] : null;
        if (includeHeadshot && headResult2) {
          console.log(`[OutfitRender] Downloaded head (${headResult2.base64.length} chars) and body (${bodyResult2.base64.length} chars)`);
        } else {
        } else {
          console.log(`[OutfitRender] Downloaded body (${bodyResult2.base64.length} chars), headshot excluded`);
        }
        return { bodyResult: bodyResult2, headResult: headResult2 };
      })();
      const [{ stackedItemsB64, itemCount }, { bodyResult, headResult }] = await Promise.all([
        outfitImagePromise,
        bodyImagePromise
      ]);
      let allInputs = [bodyResult];
      if (includeHeadshot && headResult) {
        allInputs.push({ base64: stackedItemsB64, mimeType: "image/jpeg" });
      }
      console.log(`[OutfitRender] Total images being sent to AI: ${allInputs.length}`);
      const renderPrompt = useStackedImage ? PROMPTS.OUTFIT_FINAL_STACKED(prompt || "Style this outfit naturally", itemCount, includeHeadshot) : PROMPTS.OUTFIT_FINAL(prompt || "Style this outfit naturally", itemCount, includeHeadshot);
      console.log(`[OutfitRender] Generating outfit with model: ${preferredModel}`);
      console.log(`[OutfitRender] Calling Gemini API...`);
      const finalImageB64 = await callGeminiAPI(
        renderPrompt,
        allInputs,
        preferredModel,
        "IMAGE",
      }
      console.log(`[OutfitRender] Total images being sent to AI: ${allInputs.length}`);
      const renderPrompt = useStackedImage ? PROMPTS.OUTFIT_FINAL_STACKED(prompt || "Style this outfit naturally", itemCount, includeHeadshot) : PROMPTS.OUTFIT_FINAL(prompt || "Style this outfit naturally", itemCount, includeHeadshot);
      console.log(`[OutfitRender] Generating outfit with model: ${preferredModel}`);
      console.log(`[OutfitRender] Calling Gemini API...`);
      const finalImageB64 = await callGeminiAPI(
        renderPrompt,
        allInputs,
        preferredModel,
        "IMAGE",
        perfTracker,
        timingTracker
      );
      console.log(`[OutfitRender] AI generation complete, result length: ${finalImageB64.length} chars`);
      console.log(`[OutfitRender] Optimizing generated image...`);
      const optStart = Date.now();
      const optimizedImageB64 = await optimizeGeminiOutput(finalImageB64);
      const optMs = Date.now() - optStart;
      console.log(`[Perf] Optimization took: ${optMs} ms`);
      console.log(`[OutfitRender] Image optimization complete`);
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/outfits/${outfit_id}/${timestamp}.jpg`;
      console.log(`[Perf] Optimization took: ${optMs} ms`);
      console.log(`[OutfitRender] Image optimization complete`);
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/outfits/${outfit_id}/${timestamp}.jpg`;
      const uploadStart = Date.now();
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        optimizedImageB64,
        storagePath
      );
        storagePath
      );
      const uploadMs = Date.now() - uploadStart;
      console.log(`[Perf] Upload to Supabase took: ${uploadMs} ms`);
      console.log(`[OutfitRender] Uploaded final image: ${storageKey}`);
      await supabase.from("outfit_renders").insert({
        outfit_id,
        image_id: imageId,
        prompt: prompt || null,
        settings: {
          ...settings || {},
          items_count: itemCount,
          used_stacked_image: useStackedImage
        },
        status: "succeeded"
      });
      await supabase.from("outfits").update({ cover_image_id: imageId }).eq("id", outfit_id);
      console.log(`[OutfitRender] Outfit render complete`);
      try {
        await descriptionPromise;
        console.log(`[OutfitRender] Description generation completed`);
      } catch (error) {
        status: "succeeded"
      });
      await supabase.from("outfits").update({ cover_image_id: imageId }).eq("id", outfit_id);
      console.log(`[OutfitRender] Outfit render complete`);
      try {
        await descriptionPromise;
        console.log(`[OutfitRender] Description generation completed`);
      } catch (error) {
        console.error(`[OutfitRender] Description generation failed, but continuing:`, error);
      }
      return {
    "use strict";
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI
    } = require_utils2();
    async function processOutfitMannequin2(input, supabase, userId, perfTracker = null, timingTracker = null) {
      const { outfit_id, selected, prompt, settings } = input;
      if (!outfit_id || !selected?.length) {
        throw new Error("Missing outfit_id or selected items");
      const { outfit_id, selected, prompt, settings } = input;
      if (!outfit_id || !selected?.length) {
        throw new Error("Missing outfit_id or selected items");
      }
      const wardrobeItemIds = selected.map((s) => s.wardrobe_item_id);
      const { data: allLinks, error: linksError } = await supabase.from("wardrobe_item_images").select("wardrobe_item_id, type, sort_order, image_id").in("wardrobe_item_id", wardrobeItemIds);
      if (linksError) {
        throw new Error(`Failed to load wardrobe item images: ${linksError.message}`);
      }
      const linksByItem = /* @__PURE__ */ new Map();
      (allLinks || []).forEach((link) => {
        }
      });
      if (!imageIdsToDownload.length) {
        throw new Error("No valid images found for outfit items");
      }
      const itemImageResults = await Promise.all(
        imageIdsToDownload.map((id) => downloadImageFromStorage2(supabase, id, timingTracker))
      );
      const itemImages = itemImageResults;
      const { data: userSettings } = await supabase.from("user_settings").select("ai_model_preference").eq("user_id", userId).single();
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      }
      const itemImageResults = await Promise.all(
        imageIdsToDownload.map((id) => downloadImageFromStorage2(supabase, id, timingTracker))
      );
      const itemImages = itemImageResults;
      const { data: userSettings } = await supabase.from("user_settings").select("ai_model_preference").eq("user_id", userId).single();
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      const mannequinPrompt = PROMPTS.OUTFIT_MANNEQUIN(
        itemImages.length,
        prompt || "No additional details"
      );
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      const mannequinPrompt = PROMPTS.OUTFIT_MANNEQUIN(
        itemImages.length,
        prompt || "No additional details"
      );
      const mannequinB64 = await callGeminiAPI(
        mannequinPrompt,
        itemImages,
        preferredModel,
        "IMAGE",
        perfTracker,
        perfTracker,
        timingTracker
      );
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/outfits/${outfit_id}/mannequin/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        mannequinB64,
        storagePath
      );
var { createPerformanceTracker, createTimingTracker, downloadImageFromStorage } = require_utils2();
var { processAutoTag } = require_auto_tag();
var { processProductShot } = require_product_shot();
var { processHeadshotGenerate } = require_headshot_generate();
var { processBodyShotGenerate } = require_body_shot_generate();
var { processOutfitRender } = require_outfit_render();
var { processOutfitMannequin } = require_outfit_mannequin();
var { processOutfitSuggest } = require_outfit_suggest();
var { processReferenceMatch } = require_reference_match();
exports.handler = async (event, context) => {
  context.callbackWaitsForEmptyEventLoop = false;
    }
    const token = authHeader.replace("Bearer ", "");
    const {
      data: { user },
      error: authError
    } = await supabaseAdmin.auth.getUser(token);
    if (authError || !user) {
      return {
        statusCode: 401,
        headers,
        body: JSON.stringify({ error: "Invalid token" })
        statusCode: 400,
        headers,
        body: JSON.stringify({ error: "job_id is required" })
      };
    }
    const { data: job, error: jobError } = await supabaseAdmin.from("ai_jobs").select("*").eq("id", job_id).eq("owner_user_id", user.id).single();
    if (jobError || !job) {
      return {
        statusCode: 404,
        headers,
        body: JSON.stringify({ error: "Job not found" })
        statusCode: 409,
        headers,
        body: JSON.stringify({ error: "Job already running" })
      };
    }
    await supabaseAdmin.from("ai_jobs").update({ status: "running", updated_at: (/* @__PURE__ */ new Date()).toISOString() }).eq("id", job_id);
    processJobAsync(job, user.id).catch((err) => {
      console.error(`[AIJobRunner] Async processing error for ${job_id}:`, err);
    });
    return {
      statusCode: 202,
        headers,
        body: JSON.stringify({ error: "Job already running" })
      };
    }
    await supabaseAdmin.from("ai_jobs").update({ status: "running", updated_at: (/* @__PURE__ */ new Date()).toISOString() }).eq("id", job_id);
    processJobAsync(job, user.id).catch((err) => {
      console.error(`[AIJobRunner] Async processing error for ${job_id}:`, err);
    });
    return {
      statusCode: 202,
      headers,
      headers,
      body: JSON.stringify({ error: err.message || "Internal server error" })
    };
  }
};
async function processJobAsync(job, userId) {
  const job_id = job.id;
  const perfTracker = createPerformanceTracker();
  console.log(`[AIJobRunner] Created performance tracker: ${perfTracker.requestId} for job ${job_id} (${job.job_type})`);
  const timingTracker = createTimingTracker();
  timingTracker.startJob();
  let error = null;
  try {
    const input = job.input;
    switch (job.job_type) {
      case "batch":
        result = await processBatchJob(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
    switch (job.job_type) {
      case "batch":
        result = await processBatchJob(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        throw new Error(`Unknown job type: ${job.job_type}`);
    }
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        throw new Error(`Unknown job type: ${job.job_type}`);
    }
  } catch (err) {
  if (error) {
    updateData.error = error;
  } else {
    updateData.result = result;
  }
  await supabaseAdmin.from("ai_jobs").update(updateData).eq("id", job_id);
}
async function processBatchJob(input, supabase, userId, perfTracker, timingTracker) {
  const { imageId, tasks, wardrobe_item_id, image_ids } = input;
  if (!imageId || !tasks || !Array.isArray(tasks) || tasks.length === 0) {
    throw new Error("Batch job requires imageId and tasks array");
  if (!wardrobe_item_id) {
    throw new Error("Batch job requires wardrobe_item_id");
  }
  console.log(`[BatchJob] Starting batch processing for imageId: ${imageId}, tasks: ${tasks.join(", ")}`);
  console.log(`[BatchJob] Downloading image once for shared use...`);
  const imageData = await downloadImageFromStorage(supabase, imageId, timingTracker);
  console.log(`[BatchJob] Image downloaded successfully, length: ${imageData.base64.length}, mimeType: ${imageData.mimeType}`);
  const productShotInput = tasks.includes("product_shot") ? {
    image_id: imageId,
    wardrobe_item_id
  } : null;
      return { task: "auto_tag", result: null, error: err.message };
    });
    taskPromises.push(autoTagPromise);
  }
  console.log(`[BatchJob] Both promises created. Awaiting ${taskPromises.length} promises with Promise.all() (both running in parallel)...`);
  const results = await Promise.all(taskPromises);
  const batchEnd = performance.now();
  const batchDuration = ((batchEnd - batchStart) / 1e3).toFixed(2);
  if (timingTracker && typeof timingTracker.setBatchAIGenerationTime === "function") {
    timingTracker.setBatchAIGenerationTime(parseFloat(batchDuration) * 1e3);
  }

--- ./.netlify/functions-serve/ai-job-runner-background/netlify/functions/ai-job-runner-background.js ---
    async function getFetch() {
      if (typeof fetch !== "undefined") {
        return fetch;
      }
      if (!fetchFn) {
        const nodeFetch = await Promise.resolve().then(() => __toESM(require_lib2()));
        fetchFn = nodeFetch.default;
      }
      return fetchFn;
    }
    function createTimingTracker2() {
        supabaseHostname,
        hasSupabaseClient: !!supabase,
        clientProperties: supabase ? Object.keys(supabase).filter((k) => !k.startsWith("_")).join(", ") : "N/A"
      });
      console.log(`[downloadImageFromStorage] Starting download for imageId: ${imageId}`);
      const { data: image, error } = await supabase.from("images").select("storage_bucket, storage_key, mime_type").eq("id", imageId).single();
      if (error || !image) {
        console.error(`[downloadImageFromStorage] Image not found: ${imageId}`, error);
        throw new Error(`Image not found: ${imageId}`);
      }
      console.log(`[downloadImageFromStorage] Found image record: bucket=${image.storage_bucket}, key=${image.storage_key}`);
      }
      console.log(`[downloadImageFromStorage] Found image record: bucket=${image.storage_bucket}, key=${image.storage_key}`);
      const bucket = image.storage_bucket || "media";
      const signedUrlStart = performance.now();
      console.log(`[downloadImageFromStorage] Generating signed URL for direct download...`);
      const { data: signedUrlData, error: signedUrlError } = await supabase.storage.from(bucket).createSignedUrl(image.storage_key, 60);
      if (signedUrlError || !signedUrlData?.signedUrl) {
        console.error(`[downloadImageFromStorage] Failed to create signed URL:`, signedUrlError);
        throw new Error(`Failed to create signed URL: ${signedUrlError?.message || "Unknown error"}`);
      }
      const signedUrlEnd = performance.now();
      const signedUrlEnd = performance.now();
      const signedUrlDuration = signedUrlEnd - signedUrlStart;
      console.log(`[downloadImageFromStorage] Signed URL generated in ${(signedUrlDuration / 1e3).toFixed(2)}s: ${signedUrlData.signedUrl.substring(0, 80)}...`);
      const downloadStart = performance.now();
      console.log(`[downloadImageFromStorage] Downloading directly from signed URL (CDN/S3 path)...`);
      const fetchResponse = await fetch(signedUrlData.signedUrl);
      if (!fetchResponse.ok) {
        const errorText = await fetchResponse.text().catch(() => "Unknown error");
        console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
        throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
      }
      console.log(`[downloadImageFromStorage] Signed URL generated in ${(signedUrlDuration / 1e3).toFixed(2)}s: ${signedUrlData.signedUrl.substring(0, 80)}...`);
      const downloadStart = performance.now();
      console.log(`[downloadImageFromStorage] Downloading directly from signed URL (CDN/S3 path)...`);
      const fetchResponse = await fetch(signedUrlData.signedUrl);
      if (!fetchResponse.ok) {
        const errorText = await fetchResponse.text().catch(() => "Unknown error");
        console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
        throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
      }
      const arrayBuffer = await fetchResponse.arrayBuffer();
      const downloadEnd = performance.now();
      if (!fetchResponse.ok) {
        const errorText = await fetchResponse.text().catch(() => "Unknown error");
        console.error(`[downloadImageFromStorage] Fetch failed: ${fetchResponse.status} ${fetchResponse.statusText}`, errorText);
        throw new Error(`Failed to download image from signed URL: ${fetchResponse.status} ${fetchResponse.statusText}`);
      }
      const arrayBuffer = await fetchResponse.arrayBuffer();
      const downloadEnd = performance.now();
      const downloadDuration = downloadEnd - downloadStart;
      if (timingTracker) {
        timingTracker.addStorageDownload(downloadDuration);
      }
      const isPng = isPngBase64(base64Data);
      const mimeType = isPng ? "image/png" : "image/jpeg";
      const rawBase64 = base64Data.replace(/^data:image\/\w+;base64,/, "");
      const buffer = Buffer.from(rawBase64, "base64");
      const blob = new Blob([buffer], { type: mimeType });
      const { data: uploadData, error: uploadError } = await supabase.storage.from("media").upload(storagePath, blob, {
        cacheControl: "3600",
        upsert: false,
        contentType: mimeType
      });
      if (uploadError || !uploadData) {
        contentType: mimeType
      });
      if (uploadError || !uploadData) {
        throw new Error(`Failed to upload: ${uploadError?.message}`);
      }
      const { data: imageRecord, error: imageError } = await supabase.from("images").insert({
        owner_user_id: userId,
        storage_bucket: "media",
        storage_key: uploadData.path,
        mime_type: mimeType,
        source: "ai_generated"
      if (imageError || !imageRecord) {
        throw new Error(`Failed to create DB record: ${imageError?.message}`);
      }
      return { imageId: imageRecord.id, storageKey: uploadData.path };
    }
    async function callGeminiAPI(prompt, images, model = "gemini-2.5-flash-image", responseType = "IMAGE", perfTracker = null, timingTracker = null) {
      const GEMINI_API_KEY = process.env.GEMINI_API_KEY || "";
      if (!GEMINI_API_KEY) {
        throw new Error("GEMINI_API_KEY missing");
      }
      const imageCount = Array.isArray(images) ? images.length : images ? 1 : 0;
        temperature: responseType === "TEXT" ? 0.3 : 0.4
      };
      if (responseType === "IMAGE") {
        generationConfig.response_modalities = ["IMAGE"];
      }
      const fetchFn2 = await getFetch();
      const response = await fetchFn2(
        `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
      };
      if (responseType === "IMAGE") {
        generationConfig.response_modalities = ["IMAGE"];
      }
      const fetchFn2 = await getFetch();
      const response = await fetchFn2(
        `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${GEMINI_API_KEY}`,
        {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
              { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_ONLY_HIGH" }
            ]
          })
        }
      );
      const data = await response.json();
      if (!response.ok || data.error) {
        console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
        console.error("[GeminiAPI] Request details:", {
          model,
          responseType,
          })
        }
      );
      const data = await response.json();
      if (!response.ok || data.error) {
        console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
        console.error("[GeminiAPI] Request details:", {
          model,
          responseType,
          promptLength: prompt.length,
          imageCount: images.length,
        }
      );
      const data = await response.json();
      if (!response.ok || data.error) {
        console.error("[GeminiAPI] Error response:", JSON.stringify(data.error || data, null, 2));
        console.error("[GeminiAPI] Request details:", {
          model,
          responseType,
          promptLength: prompt.length,
          imageCount: images.length,
          firstImageLength: images[0]?.length || 0,
          promptLength: prompt.length,
          imageCount: images.length,
          firstImageLength: images[0]?.length || 0,
          firstImagePreview: images[0]?.substring(0, 100) || "N/A"
        });
        const errorMessage = data.error?.message || data.error || "Gemini API Error";
        throw new Error(errorMessage);
      }
      const candidate = data.candidates?.[0];
      if (!candidate) {
        throw new Error("No candidates returned");
      const apiCallEnd = performance.now();
      const apiCallDuration = apiCallEnd - apiCallStart;
      if (timingTracker) {
        timingTracker.addApiCall(apiCallDuration);
      }
      console.log(`[callGeminiAPI] External API call completed in ${(apiCallDuration / 1e3).toFixed(2)}s (${responseType})`);
      if (perfTracker) {
        if (responseType === "TEXT") {
          perfTracker.endTextGen();
        } else {
          perfTracker.endImageGen();
            const rawBase64 = imageInput.replace(/^data:image\/\w+;base64,/, "");
            imageBuffer = Buffer.from(rawBase64, "base64");
          } else {
            imageBuffer = imageInput;
          }
          const resizedImage = await sharp(imageBuffer).resize(cellWidth, cellHeight, {
            fit: "contain",
            background: BACKGROUND_COLOR
          }).toBuffer();
          const metadata = await sharp(resizedImage).metadata();
          const actualWidth = metadata.width;
          }
          const resizedImage = await sharp(imageBuffer).resize(cellWidth, cellHeight, {
            fit: "contain",
            background: BACKGROUND_COLOR
          }).toBuffer();
          const metadata = await sharp(resizedImage).metadata();
          const actualWidth = metadata.width;
          const actualHeight = metadata.height;
          const offsetX = x + Math.floor((cellWidth - actualWidth) / 2);
          const offsetY = y + Math.floor((cellHeight - actualHeight) / 2);
          composites.push({
          console.error(`[compositeOutfitGrid] Error processing image ${i + 1}:`, error);
          throw new Error(`Failed to process image ${i + 1}: ${error.message}`);
        }
      }
      console.log(`[compositeOutfitGrid] Compositing ${composites.length} images...`);
      const finalImage = await canvas.composite(composites).jpeg({ quality: 95 }).toBuffer();
      const base64 = finalImage.toString("base64");
      console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
      return base64;
    }
    async function optimizeGeminiOutput(base64String) {
      const finalImage = await canvas.composite(composites).jpeg({ quality: 95 }).toBuffer();
      const base64 = finalImage.toString("base64");
      console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
      return base64;
    }
    async function optimizeGeminiOutput(base64String) {
      console.log("[optimizeGeminiOutput] Starting optimization...");
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
      const base64 = finalImage.toString("base64");
      console.log(`[compositeOutfitGrid] Composite complete, base64 length: ${base64.length}`);
      return base64;
    }
    async function optimizeGeminiOutput(base64String) {
      console.log("[optimizeGeminiOutput] Starting optimization...");
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
    async function optimizeGeminiOutput(base64String) {
      console.log("[optimizeGeminiOutput] Starting optimization...");
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
        const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
          withoutEnlargement: true,
          fit: "inside"
      console.log("[optimizeGeminiOutput] Starting optimization...");
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
        const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
          withoutEnlargement: true,
          fit: "inside"
        }).jpeg({
      try {
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
        const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
          withoutEnlargement: true,
          fit: "inside"
        }).jpeg({
          quality: 80,
        const rawBase64 = base64String.replace(/^data:image\/\w+;base64,/, "");
        const inputBuffer = Buffer.from(rawBase64, "base64");
        console.log(`[optimizeGeminiOutput] Input size: ${inputBuffer.length} bytes (${(inputBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const originalMetadata = await sharp(inputBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Original dimensions: ${originalMetadata.width}x${originalMetadata.height}`);
        const optimizedBuffer = await sharp(inputBuffer).resize(1024, null, {
          withoutEnlargement: true,
          fit: "inside"
        }).jpeg({
          quality: 80,
          mozjpeg: true
          fit: "inside"
        }).jpeg({
          quality: 80,
          mozjpeg: true
        }).toBuffer();
        console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        }).jpeg({
          quality: 80,
          mozjpeg: true
        }).toBuffer();
        console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
          quality: 80,
          mozjpeg: true
        }).toBuffer();
        console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
        }).toBuffer();
        console.log(`[optimizeGeminiOutput] Optimized size: ${optimizedBuffer.length} bytes (${(optimizedBuffer.length / (1024 * 1024)).toFixed(2)} MB)`);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
      } catch (error) {
        console.error("[optimizeGeminiOutput] Optimization failed:", error);
        const optimizedMetadata = await sharp(optimizedBuffer).metadata();
        console.log(`[optimizeGeminiOutput] Optimized dimensions: ${optimizedMetadata.width}x${optimizedMetadata.height}`);
        const sizeReduction = ((1 - optimizedBuffer.length / inputBuffer.length) * 100).toFixed(1);
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
      } catch (error) {
        console.error("[optimizeGeminiOutput] Optimization failed:", error);
        console.warn("[optimizeGeminiOutput] Returning original image due to error");
        return base64String;
        console.log(`[optimizeGeminiOutput] Size reduction: ${sizeReduction}%`);
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
      } catch (error) {
        console.error("[optimizeGeminiOutput] Optimization failed:", error);
        console.warn("[optimizeGeminiOutput] Returning original image due to error");
        return base64String;
      }
    }
    module2.exports = {
        const optimizedBase64 = optimizedBuffer.toString("base64");
        console.log("[optimizeGeminiOutput] Optimization complete");
        return optimizedBase64;
      } catch (error) {
        console.error("[optimizeGeminiOutput] Optimization failed:", error);
        console.warn("[optimizeGeminiOutput] Returning original image due to error");
        return base64String;
      }
    }
    module2.exports = {
      downloadImageFromStorage: downloadImageFromStorage2,
      }
    }
    module2.exports = {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI,
      compositeOutfitGrid,
      optimizeGeminiOutput,
      createPerformanceTracker: createPerformanceTracker2,
      createTimingTracker: createTimingTracker2
    };
    module2.exports = {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI,
      compositeOutfitGrid,
      optimizeGeminiOutput,
      createPerformanceTracker: createPerformanceTracker2,
      createTimingTracker: createTimingTracker2
    };
  }
});
// netlify/functions/processes/auto_tag.js
var require_auto_tag = __commonJS({
  "netlify/functions/processes/auto_tag.js"(exports2, module2) {
    "use strict";
    var { PROMPTS } = require_prompts();
    var { downloadImageFromStorage: downloadImageFromStorage2, callGeminiAPI } = require_utils2();
    async function processAutoTag2(input, supabase, perfTracker = null, timingTracker = null, preDownloadedImageData = null) {
      const { wardrobe_item_id, image_ids } = input;
      if (!wardrobe_item_id || !image_ids?.length) {
        throw new Error("Missing ID or images");
      }
        imageB64Promise = Promise.resolve(preDownloadedImageData);
      } else {
        console.log(`[processAutoTag] Downloading image from storage (image_id: ${image_ids[0]})...`);
        imageB64Promise = downloadImageFromStorage2(supabase, image_ids[0], timingTracker);
      }
      const [imageResult, catRes, subRes, attrRes] = await Promise.all([
        imageB64Promise,
        supabase.from("wardrobe_categories").select("id, name").order("sort_order"),
        supabase.from("wardrobe_subcategories").select("id, name, category_id").order("sort_order"),
        supabase.from("attribute_definitions").select("id, key, name")
      ]);
      const categories = catRes.data || [];
      const subcategories = subRes.data || [];
      const catList = categories.map((c) => c.name).join(", ");
      const subList = subcategories.map((s) => s.name).join(", ");
      const prompt = PROMPTS.AUTO_TAG(catList, subList);
      const textResult = await callGeminiAPI(prompt, [imageResult], "gemini-2.5-flash-image", "TEXT", perfTracker, timingTracker);
      let result;
      try {
        const cleaned = textResult.replace(/```json\n?/g, "").replace(/```\n?/g, "").trim();
        result = JSON.parse(cleaned);
      } catch (e) {
      const attributesToInsert = [];
      for (const attr of result.attributes || []) {
        const defId = defMap.get(attr.key);
        if (!defId) continue;
        for (const val of attr.values || []) {
          let { data: value } = await supabase.from("attribute_values").select("id").eq("definition_id", defId).ilike("value", val.value).single();
          if (!value) {
            const { data: newValue } = await supabase.from("attribute_values").insert({ definition_id: defId, value: val.value }).select("id").single();
            value = newValue;
          }
          if (value?.id) {
        const defId = defMap.get(attr.key);
        if (!defId) continue;
        for (const val of attr.values || []) {
          let { data: value } = await supabase.from("attribute_values").select("id").eq("definition_id", defId).ilike("value", val.value).single();
          if (!value) {
            const { data: newValue } = await supabase.from("attribute_values").insert({ definition_id: defId, value: val.value }).select("id").single();
            value = newValue;
          }
          if (value?.id) {
            attributesToInsert.push({
              entity_type: "wardrobe_item",
            });
          }
        }
      }
      if (attributesToInsert.length) {
        await supabase.from("entity_attributes").insert(attributesToInsert);
      }
      const updates = {};
      if (result.suggested_title) updates.title = result.suggested_title;
      if (result.suggested_notes) updates.description = result.suggested_notes;
      const colorAttr = result.attributes?.find((a) => a.key === "color");
            updates.subcategory_id = null;
          }
        }
      }
      if (Object.keys(updates).length > 0) {
        await supabase.from("wardrobe_items").update(updates).eq("id", wardrobe_item_id);
      }
      return { ...result, updates_applied: updates };
    }
    module2.exports = { processAutoTag: processAutoTag2 };
  }
    "use strict";
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI
    } = require_utils2();
    async function processProductShot2(input, supabase, userId, perfTracker = null, timingTracker = null, preDownloadedImageData = null) {
      const { image_id, wardrobe_item_id } = input;
      if (!image_id || !wardrobe_item_id) {
        throw new Error("Missing ID or wardrobe_item_id");
      if (preDownloadedImageData && preDownloadedImageData.base64) {
        console.log(`[processProductShot] Using pre-downloaded image (skipping storage download, saving ~5s)`);
        imageResult = preDownloadedImageData;
      } else {
        console.log(`[processProductShot] Downloading image from storage (image_id: ${image_id})...`);
        imageResult = await downloadImageFromStorage2(supabase, image_id, timingTracker);
      }
      const productShotB64 = await callGeminiAPI(
        PROMPTS.PRODUCT_SHOT,
        [imageResult],
        "gemini-2.5-flash-image",
        imageResult = preDownloadedImageData;
      } else {
        console.log(`[processProductShot] Downloading image from storage (image_id: ${image_id})...`);
        imageResult = await downloadImageFromStorage2(supabase, image_id, timingTracker);
      }
      const productShotB64 = await callGeminiAPI(
        PROMPTS.PRODUCT_SHOT,
        [imageResult],
        "gemini-2.5-flash-image",
        "IMAGE",
        perfTracker,
        perfTracker,
        timingTracker
      );
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/product_shots/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        productShotB64,
        storagePath
      );
        supabase,
        userId,
        productShotB64,
        storagePath
      );
      const { data: existingImages } = await supabase.from("wardrobe_item_images").select("id, sort_order").eq("wardrobe_item_id", wardrobe_item_id).order("sort_order", { ascending: false });
      for (const img of existingImages || []) {
        await supabase.from("wardrobe_item_images").update({ sort_order: (img.sort_order || 0) + 1 }).eq("id", img.id);
      }
      await supabase.from("wardrobe_item_images").insert({
        wardrobe_item_id,
        productShotB64,
        storagePath
      );
      const { data: existingImages } = await supabase.from("wardrobe_item_images").select("id, sort_order").eq("wardrobe_item_id", wardrobe_item_id).order("sort_order", { ascending: false });
      for (const img of existingImages || []) {
        await supabase.from("wardrobe_item_images").update({ sort_order: (img.sort_order || 0) + 1 }).eq("id", img.id);
      }
      await supabase.from("wardrobe_item_images").insert({
        wardrobe_item_id,
        image_id: imageId,
        type: "product_shot",
      );
      const { data: existingImages } = await supabase.from("wardrobe_item_images").select("id, sort_order").eq("wardrobe_item_id", wardrobe_item_id).order("sort_order", { ascending: false });
      for (const img of existingImages || []) {
        await supabase.from("wardrobe_item_images").update({ sort_order: (img.sort_order || 0) + 1 }).eq("id", img.id);
      }
      await supabase.from("wardrobe_item_images").insert({
        wardrobe_item_id,
        image_id: imageId,
        type: "product_shot",
        sort_order: 0
      });
    "use strict";
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI
    } = require_utils2();
    async function processHeadshotGenerate2(input, supabase, userId, perfTracker = null, timingTracker = null) {
      console.log(`[processHeadshotGenerate] Starting for userId: ${userId}`, input);
      const { selfie_image_id, hair_style, makeup_style } = input;
      if (!selfie_image_id) {
      const { selfie_image_id, hair_style, makeup_style } = input;
      if (!selfie_image_id) {
        throw new Error("Missing selfie_image_id");
      }
      console.log(`[processHeadshotGenerate] Downloading selfie image: ${selfie_image_id}`);
      const selfieResult = await downloadImageFromStorage2(supabase, selfie_image_id, timingTracker);
      console.log(`[processHeadshotGenerate] Downloaded selfie, base64 length: ${selfieResult.base64.length}`);
      if (!selfieResult.base64 || selfieResult.base64.length === 0) {
        throw new Error("Downloaded image is empty");
      }
      const base64Regex = /^[A-Za-z0-9+/]*={0,2}$/;
        throw new Error("Invalid base64 image format");
      }
      const hair = hair_style || "Keep original hair";
      const makeup = makeup_style || "Natural look";
      const prompt = PROMPTS.HEADSHOT(hair, makeup);
      console.log(`[processHeadshotGenerate] Calling Gemini API with prompt length: ${prompt.length}`);
      const headshotB64 = await callGeminiAPI(
        prompt,
        [selfieResult],
        "gemini-2.5-flash-image",
        "IMAGE",
      }
      const hair = hair_style || "Keep original hair";
      const makeup = makeup_style || "Natural look";
      const prompt = PROMPTS.HEADSHOT(hair, makeup);
      console.log(`[processHeadshotGenerate] Calling Gemini API with prompt length: ${prompt.length}`);
      const headshotB64 = await callGeminiAPI(
        prompt,
        [selfieResult],
        "gemini-2.5-flash-image",
        "IMAGE",
        perfTracker,
        "gemini-2.5-flash-image",
        "IMAGE",
        perfTracker,
        timingTracker
      );
      console.log(`[processHeadshotGenerate] Gemini API returned, headshot base64 length: ${headshotB64?.length || 0}`);
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/headshots/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        timingTracker
      );
      console.log(`[processHeadshotGenerate] Gemini API returned, headshot base64 length: ${headshotB64?.length || 0}`);
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/headshots/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        headshotB64,
        storagePath
      );
        supabase,
        userId,
        headshotB64,
        storagePath
      );
      await supabase.from("user_settings").update({ headshot_image_id: imageId }).eq("user_id", userId);
      return { image_id: imageId, storage_key: storageKey };
    }
    module2.exports = { processHeadshotGenerate: processHeadshotGenerate2 };
  }
});
    "use strict";
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI
    } = require_utils2();
    async function processBodyShotGenerate2(input, supabase, userId, perfTracker = null, timingTracker = null) {
      const { body_photo_image_id, headshot_image_id } = input;
      if (!body_photo_image_id) {
        throw new Error("Missing body_photo_image_id");
      if (!body_photo_image_id) {
        throw new Error("Missing body_photo_image_id");
      }
      let headId = headshot_image_id;
      if (!headId) {
        const { data: settings } = await supabase.from("user_settings").select("headshot_image_id").eq("user_id", userId).single();
        headId = settings?.headshot_image_id;
      }
      if (!headId) {
        throw new Error("No headshot available");
      }
        headId = settings?.headshot_image_id;
      }
      if (!headId) {
        throw new Error("No headshot available");
      }
      const [headResult, bodyResult] = await Promise.all([
        downloadImageFromStorage2(supabase, headId, timingTracker),
        downloadImageFromStorage2(supabase, body_photo_image_id, timingTracker)
      ]);
      const studioModelB64 = await callGeminiAPI(
        PROMPTS.BODY_COMPOSITE,
      }
      const [headResult, bodyResult] = await Promise.all([
        downloadImageFromStorage2(supabase, headId, timingTracker),
        downloadImageFromStorage2(supabase, body_photo_image_id, timingTracker)
      ]);
      const studioModelB64 = await callGeminiAPI(
        PROMPTS.BODY_COMPOSITE,
        [headResult, bodyResult],
        "gemini-3-pro-image-preview",
        "IMAGE",
        perfTracker,
        perfTracker,
        timingTracker
      );
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/body_shots/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        studioModelB64,
        storagePath
      );
        supabase,
        userId,
        studioModelB64,
        storagePath
      );
      await supabase.from("user_settings").update({ body_shot_image_id: imageId }).eq("user_id", userId);
      return { image_id: imageId, storage_key: storageKey };
    }
    module2.exports = { processBodyShotGenerate: processBodyShotGenerate2 };
  }
});
    }
    module2.exports = { processBodyShotGenerate: processBodyShotGenerate2 };
  }
});

// netlify/functions/processes/outfit_render.js
var require_outfit_render = __commonJS({
  "netlify/functions/processes/outfit_render.js"(exports2, module2) {
    "use strict";
    var sharp = require("sharp");
    var { PROMPTS } = require_prompts();
    module2.exports = { processBodyShotGenerate: processBodyShotGenerate2 };
  }
});

// netlify/functions/processes/outfit_render.js
var require_outfit_render = __commonJS({
  "netlify/functions/processes/outfit_render.js"(exports2, module2) {
    "use strict";
    var sharp = require("sharp");
    var { PROMPTS } = require_prompts();
    var {
  }
});

// netlify/functions/processes/outfit_render.js
var require_outfit_render = __commonJS({
  "netlify/functions/processes/outfit_render.js"(exports2, module2) {
    "use strict";
    var sharp = require("sharp");
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
    var sharp = require("sharp");
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI,
      optimizeGeminiOutput
    } = require_utils2();
    async function generateOutfitDescription(outfitId, itemDetails, supabase, perfTracker = null) {
      console.log(`[OutfitDescription] Starting description generation for outfit ${outfitId}`);
      const startTime = Date.now();
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI,
      optimizeGeminiOutput
    } = require_utils2();
    async function generateOutfitDescription(outfitId, itemDetails, supabase, perfTracker = null) {
      console.log(`[OutfitDescription] Starting description generation for outfit ${outfitId}`);
      const startTime = Date.now();
      try {
- Style tags should describe the overall vibe (e.g., "minimalist", "preppy", "streetwear")
- Provide exactly 3 style tags
- Keep it concise and actionable

Respond with ONLY the JSON object, no additional text.`;
        const response = await callGeminiAPI(
          prompt,
          [],
          // No images needed for description
          "gemini-2.5-flash",
          // Fast text model
          "TEXT",
          perfTracker,
          null
        );
        const description = parseDescriptionResponse(response);
        const { error: updateError } = await supabase.from("outfits").update({
          description: description.description,
          occasions: description.occasions,
          style_tags: description.styleTags,
          season: description.season,
          description_generated_at: (/* @__PURE__ */ new Date()).toISOString()
      }
    }
    async function fetchOutfitItemDetails(outfitId, supabase, userId) {
      console.log(`[OutfitDescription] Fetching item details for outfit ${outfitId}`);
      try {
        const { data, error } = await supabase.rpc("get_outfit_items_with_details", {
          p_outfit_id: outfitId,
          p_viewer_id: userId
        });
        if (error) {
          console.error(`[OutfitDescription] Error fetching items:`, error);
      if (!stacked_image_id && (!selected || selected.length === 0)) {
        throw new Error("Missing stacked_image_id or selected items");
      }
      const useStackedImage = !!stacked_image_id;
      console.log(`[OutfitRender] Processing outfit ${outfit_id}, using ${useStackedImage ? "pre-stacked" : "individual"} images`);
      const { data: userSettings } = await supabase.from("user_settings").select("headshot_image_id, body_shot_image_id, ai_model_preference, include_headshot_in_generation").eq("user_id", userId).single();
      const bodyId = userSettings?.body_shot_image_id;
      const includeHeadshot = userSettings?.include_headshot_in_generation ?? false;
      const headId = includeHeadshot ? headshot_image_id || userSettings?.headshot_image_id : null;
      if (!bodyId) {
        throw new Error("Missing body shot");
      if (includeHeadshot && !headId) {
        throw new Error("Missing headshot (required when include_headshot_in_generation is enabled)");
      }
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      const descriptionPromise = (async () => {
        const itemDetails = await fetchOutfitItemDetails(outfit_id, supabase, userId);
        if (itemDetails.length > 0) {
          return await generateOutfitDescription(outfit_id, itemDetails, supabase, perfTracker);
        }
        return null;
      })();
      }
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      const descriptionPromise = (async () => {
        const itemDetails = await fetchOutfitItemDetails(outfit_id, supabase, userId);
        if (itemDetails.length > 0) {
          return await generateOutfitDescription(outfit_id, itemDetails, supabase, perfTracker);
        }
        return null;
      })();
      const outfitImagePromise = (async () => {
        if (useStackedImage) {
        return null;
      })();
      const outfitImagePromise = (async () => {
        if (useStackedImage) {
          console.log(`[OutfitRender] Downloading pre-stacked image from storage: ${stacked_image_id}`);
          const { data: stackedBlob, error: downloadError } = await supabase.storage.from("media").download(stacked_image_id);
          if (downloadError) {
            console.error(`[OutfitRender] Storage download error:`, downloadError);
            throw new Error(`Failed to download stacked image: ${downloadError.message}`);
          }
          if (!stackedBlob) {
          }
          if (!stackedBlob) {
            throw new Error("Downloaded blob is null or undefined");
          }
          console.log(`[OutfitRender] Downloaded blob size: ${stackedBlob.size} bytes, type: ${stackedBlob.type}`);
          const buffer = await stackedBlob.arrayBuffer();
          console.log(`[OutfitRender] Converted to ArrayBuffer, length: ${buffer.byteLength}`);
          const stackedItemsB643 = Buffer.from(buffer).toString("base64");
          console.log(`[OutfitRender] Converted to base64, length: ${stackedItemsB643.length} chars`);
          const itemCount3 = settings?.items_count || selected?.length || 0;
          console.log(`[OutfitRender] Pre-stacked image contains ${itemCount3} items`);
          console.log(`[OutfitRender] Pre-stacked image contains ${itemCount3} items`);
          return { stackedItemsB64: stackedItemsB643, itemCount: itemCount3 };
        }
        console.log(`[OutfitRender] Legacy mode: fetching ${selected.length} individual items`);
        const wardrobeItemIds = selected.map((s) => s.wardrobe_item_id);
        const { data: allLinks } = await supabase.from("wardrobe_item_images").select("wardrobe_item_id, type, sort_order, image_id").in("wardrobe_item_id", wardrobeItemIds);
        const linksByItem = /* @__PURE__ */ new Map();
        (allLinks || []).forEach((link) => {
          if (!linksByItem.has(link.wardrobe_item_id)) {
            linksByItem.set(link.wardrobe_item_id, []);
          }
        });
        if (!imageIdsToDownload.length) {
          throw new Error("No valid images found for outfit items");
        }
        console.log(`[OutfitRender] Legacy mode: downloading ${imageIdsToDownload.length} images: ${imageIdsToDownload.join(", ")}`);
        const itemImageResults = await Promise.all(
          imageIdsToDownload.map((id) => {
            console.log(`[OutfitRender] Downloading item image: ${id}`);
            return downloadImageFromStorage2(supabase, id, timingTracker);
          })
        );
        console.log(`[OutfitRender] Downloading body image${includeHeadshot ? " and headshot" : ""}`);
        const downloadPromises = [downloadImageFromStorage2(supabase, bodyId, timingTracker)];
        if (includeHeadshot && headId) {
          downloadPromises.push(downloadImageFromStorage2(supabase, headId, timingTracker));
        }
        const downloadedImageResults = await Promise.all(downloadPromises);
        const bodyResult2 = downloadedImageResults[0];
        const headResult2 = includeHeadshot && downloadedImageResults[1] ? downloadedImageResults[1] : null;
        if (includeHeadshot && headResult2) {
          console.log(`[OutfitRender] Downloaded head (${headResult2.base64.length} chars) and body (${bodyResult2.base64.length} chars)`);
        } else {
        } else {
          console.log(`[OutfitRender] Downloaded body (${bodyResult2.base64.length} chars), headshot excluded`);
        }
        return { bodyResult: bodyResult2, headResult: headResult2 };
      })();
      const [{ stackedItemsB64, itemCount }, { bodyResult, headResult }] = await Promise.all([
        outfitImagePromise,
        bodyImagePromise
      ]);
      let allInputs = [bodyResult];
      if (includeHeadshot && headResult) {
        allInputs.push({ base64: stackedItemsB64, mimeType: "image/jpeg" });
      }
      console.log(`[OutfitRender] Total images being sent to AI: ${allInputs.length}`);
      const renderPrompt = useStackedImage ? PROMPTS.OUTFIT_FINAL_STACKED(prompt || "Style this outfit naturally", itemCount, includeHeadshot) : PROMPTS.OUTFIT_FINAL(prompt || "Style this outfit naturally", itemCount, includeHeadshot);
      console.log(`[OutfitRender] Generating outfit with model: ${preferredModel}`);
      console.log(`[OutfitRender] Calling Gemini API...`);
      const finalImageB64 = await callGeminiAPI(
        renderPrompt,
        allInputs,
        preferredModel,
        "IMAGE",
      }
      console.log(`[OutfitRender] Total images being sent to AI: ${allInputs.length}`);
      const renderPrompt = useStackedImage ? PROMPTS.OUTFIT_FINAL_STACKED(prompt || "Style this outfit naturally", itemCount, includeHeadshot) : PROMPTS.OUTFIT_FINAL(prompt || "Style this outfit naturally", itemCount, includeHeadshot);
      console.log(`[OutfitRender] Generating outfit with model: ${preferredModel}`);
      console.log(`[OutfitRender] Calling Gemini API...`);
      const finalImageB64 = await callGeminiAPI(
        renderPrompt,
        allInputs,
        preferredModel,
        "IMAGE",
        perfTracker,
        timingTracker
      );
      console.log(`[OutfitRender] AI generation complete, result length: ${finalImageB64.length} chars`);
      console.log(`[OutfitRender] Optimizing generated image...`);
      const optStart = Date.now();
      const optimizedImageB64 = await optimizeGeminiOutput(finalImageB64);
      const optMs = Date.now() - optStart;
      console.log(`[Perf] Optimization took: ${optMs} ms`);
      console.log(`[OutfitRender] Image optimization complete`);
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/outfits/${outfit_id}/${timestamp}.jpg`;
      console.log(`[Perf] Optimization took: ${optMs} ms`);
      console.log(`[OutfitRender] Image optimization complete`);
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/outfits/${outfit_id}/${timestamp}.jpg`;
      const uploadStart = Date.now();
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        optimizedImageB64,
        storagePath
      );
        storagePath
      );
      const uploadMs = Date.now() - uploadStart;
      console.log(`[Perf] Upload to Supabase took: ${uploadMs} ms`);
      console.log(`[OutfitRender] Uploaded final image: ${storageKey}`);
      await supabase.from("outfit_renders").insert({
        outfit_id,
        image_id: imageId,
        prompt: prompt || null,
        settings: {
          ...settings || {},
          items_count: itemCount,
          used_stacked_image: useStackedImage
        },
        status: "succeeded"
      });
      await supabase.from("outfits").update({ cover_image_id: imageId }).eq("id", outfit_id);
      console.log(`[OutfitRender] Outfit render complete`);
      try {
        await descriptionPromise;
        console.log(`[OutfitRender] Description generation completed`);
      } catch (error) {
        status: "succeeded"
      });
      await supabase.from("outfits").update({ cover_image_id: imageId }).eq("id", outfit_id);
      console.log(`[OutfitRender] Outfit render complete`);
      try {
        await descriptionPromise;
        console.log(`[OutfitRender] Description generation completed`);
      } catch (error) {
        console.error(`[OutfitRender] Description generation failed, but continuing:`, error);
      }
      return {
    "use strict";
    var { PROMPTS } = require_prompts();
    var {
      downloadImageFromStorage: downloadImageFromStorage2,
      uploadImageToStorage,
      callGeminiAPI
    } = require_utils2();
    async function processOutfitMannequin2(input, supabase, userId, perfTracker = null, timingTracker = null) {
      const { outfit_id, selected, prompt, settings } = input;
      if (!outfit_id || !selected?.length) {
        throw new Error("Missing outfit_id or selected items");
      const { outfit_id, selected, prompt, settings } = input;
      if (!outfit_id || !selected?.length) {
        throw new Error("Missing outfit_id or selected items");
      }
      const wardrobeItemIds = selected.map((s) => s.wardrobe_item_id);
      const { data: allLinks, error: linksError } = await supabase.from("wardrobe_item_images").select("wardrobe_item_id, type, sort_order, image_id").in("wardrobe_item_id", wardrobeItemIds);
      if (linksError) {
        throw new Error(`Failed to load wardrobe item images: ${linksError.message}`);
      }
      const linksByItem = /* @__PURE__ */ new Map();
      (allLinks || []).forEach((link) => {
        }
      });
      if (!imageIdsToDownload.length) {
        throw new Error("No valid images found for outfit items");
      }
      const itemImageResults = await Promise.all(
        imageIdsToDownload.map((id) => downloadImageFromStorage2(supabase, id, timingTracker))
      );
      const itemImages = itemImageResults;
      const { data: userSettings } = await supabase.from("user_settings").select("ai_model_preference").eq("user_id", userId).single();
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      }
      const itemImageResults = await Promise.all(
        imageIdsToDownload.map((id) => downloadImageFromStorage2(supabase, id, timingTracker))
      );
      const itemImages = itemImageResults;
      const { data: userSettings } = await supabase.from("user_settings").select("ai_model_preference").eq("user_id", userId).single();
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      const mannequinPrompt = PROMPTS.OUTFIT_MANNEQUIN(
        itemImages.length,
        prompt || "No additional details"
      );
      const preferredModel = userSettings?.ai_model_preference || "gemini-2.5-flash-image";
      const mannequinPrompt = PROMPTS.OUTFIT_MANNEQUIN(
        itemImages.length,
        prompt || "No additional details"
      );
      const mannequinB64 = await callGeminiAPI(
        mannequinPrompt,
        itemImages,
        preferredModel,
        "IMAGE",
        perfTracker,
        perfTracker,
        timingTracker
      );
      const timestamp = Date.now();
      const storagePath = `${userId}/ai/outfits/${outfit_id}/mannequin/${timestamp}.jpg`;
      const { imageId, storageKey } = await uploadImageToStorage(
        supabase,
        userId,
        mannequinB64,
        storagePath
      );
var { createPerformanceTracker, createTimingTracker, downloadImageFromStorage } = require_utils2();
var { processAutoTag } = require_auto_tag();
var { processProductShot } = require_product_shot();
var { processHeadshotGenerate } = require_headshot_generate();
var { processBodyShotGenerate } = require_body_shot_generate();
var { processOutfitRender } = require_outfit_render();
var { processOutfitMannequin } = require_outfit_mannequin();
var { processOutfitSuggest } = require_outfit_suggest();
var { processReferenceMatch } = require_reference_match();
exports.handler = async (event, context) => {
  const headers = {
    }
    const token = authHeader.replace("Bearer ", "");
    const {
      data: { user },
      error: authError
    } = await supabaseAdmin.auth.getUser(token);
    if (authError || !user) {
      return {
        statusCode: 401,
        headers,
        body: JSON.stringify({ error: "Invalid token" })
        statusCode: 400,
        headers,
        body: JSON.stringify({ error: "job_id is required" })
      };
    }
    const { data: job, error: jobError } = await supabaseAdmin.from("ai_jobs").select("*").eq("id", job_id).eq("owner_user_id", user.id).single();
    if (jobError || !job) {
      return {
        statusCode: 404,
        headers,
        body: JSON.stringify({ error: "Job not found" })
        statusCode: 409,
        headers,
        body: JSON.stringify({ error: "Job already running" })
      };
    }
    await supabaseAdmin.from("ai_jobs").update({ status: "running", updated_at: (/* @__PURE__ */ new Date()).toISOString() }).eq("id", job_id);
    try {
      await processJobAsync(job, user.id);
    } catch (err) {
      console.error(`[AIJobRunner] Processing error for ${job_id}:`, err);
    }
        body: JSON.stringify({ error: "Job already running" })
      };
    }
    await supabaseAdmin.from("ai_jobs").update({ status: "running", updated_at: (/* @__PURE__ */ new Date()).toISOString() }).eq("id", job_id);
    try {
      await processJobAsync(job, user.id);
    } catch (err) {
      console.error(`[AIJobRunner] Processing error for ${job_id}:`, err);
    }
  } catch (err) {
    console.error("Handler Critical Error:", err);
      headers,
      body: JSON.stringify({ error: err.message || "Internal server error" })
    };
  }
};
async function processJobAsync(job, userId) {
  const job_id = job.id;
  const perfTracker = createPerformanceTracker();
  console.log(`[AIJobRunner] Created performance tracker: ${perfTracker.requestId} for job ${job_id} (${job.job_type})`);
  const timingTracker = createTimingTracker();
  timingTracker.startJob();
  let error = null;
  try {
    const input = job.input;
    switch (job.job_type) {
      case "batch":
        result = await processBatchJob(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
    switch (job.job_type) {
      case "batch":
        result = await processBatchJob(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        break;
      case "auto_tag":
        result = await processAutoTag(input, supabaseAdmin, perfTracker, timingTracker);
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        break;
      case "product_shot":
        result = await processProductShot(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        break;
      case "headshot_generate":
        result = await processHeadshotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        break;
      case "body_shot_generate":
        result = await processBodyShotGenerate(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        break;
      case "outfit_suggest":
        result = await processOutfitSuggest(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        break;
      case "reference_match":
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        result = await processReferenceMatch(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        throw new Error(`Unknown job type: ${job.job_type}`);
    }
        break;
      case "outfit_mannequin":
        result = await processOutfitMannequin(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      case "outfit_render":
        result = await processOutfitRender(input, supabaseAdmin, userId, perfTracker, timingTracker);
        break;
      default:
        throw new Error(`Unknown job type: ${job.job_type}`);
    }
  } catch (err) {
  if (error) {
    updateData.error = error;
  } else {
    updateData.result = result;
  }
  await supabaseAdmin.from("ai_jobs").update(updateData).eq("id", job_id);
}
async function processBatchJob(input, supabase, userId, perfTracker, timingTracker) {
  const { imageId, tasks, wardrobe_item_id, image_ids } = input;
  if (!imageId || !tasks || !Array.isArray(tasks) || tasks.length === 0) {
    throw new Error("Batch job requires imageId and tasks array");
  }
  if (!wardrobe_item_id) {
    throw new Error("Batch job requires wardrobe_item_id");
  }
  console.log(`[BatchJob] Starting batch processing for imageId: ${imageId}, tasks: ${tasks.join(", ")}`);
  const imageData = await downloadImageFromStorage(supabase, imageId, timingTracker);
  console.log(`[BatchJob] Image downloaded successfully, length: ${imageData.base64.length}, mimeType: ${imageData.mimeType}`);
  const productShotInput = tasks.includes("product_shot") ? {
    image_id: imageId,
    wardrobe_item_id
  } : null;
      console.error(`[BatchJob] auto_tag failed:`, err.message);
      return { task: "auto_tag", result: null, error: err.message };
    });
    taskPromises.push(autoTagPromise);
  }
  const results = await Promise.all(taskPromises);
  const batchDuration = ((performance.now() - batchStart) / 1e3).toFixed(2);
  if (timingTracker && typeof timingTracker.setBatchAIGenerationTime === "function") {
    timingTracker.setBatchAIGenerationTime(parseFloat(batchDuration) * 1e3);
  }
  console.log(`[BatchJob] All tasks completed in ${batchDuration}s`);

--- ./.netlify/functions-serve/remove-background/netlify/functions/remove-background.js ---
          mime_type: "image/jpeg",
          data: imageData
        }
      }
    ];
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/${modelId}:generateContent?key=${apiKey}`,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
          ]
        })
      }
    );
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`);
    }
    const data = await response.json();
    const part = data.candidates?.[0]?.content?.parts?.[0];
    const resultB64 = part?.inline_data?.data || part?.inlineData?.data;
    );
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`);
    }
    const data = await response.json();
    const part = data.candidates?.[0]?.content?.parts?.[0];
    const resultB64 = part?.inline_data?.data || part?.inlineData?.data;
    if (!resultB64) {
      throw new Error("No image data returned from Gemini");
    }
    }
    const data = await response.json();
    const part = data.candidates?.[0]?.content?.parts?.[0];
    const resultB64 = part?.inline_data?.data || part?.inlineData?.data;
    if (!resultB64) {
      throw new Error("No image data returned from Gemini");
    }
    return {
      statusCode: 200,
      headers,
      body: JSON.stringify({

--- ./src/utils/canvasTrimmer.js ---
  }

  // Load the image if it's a URL string
  let image;
  if (typeof imageSource === 'string') {
    image = await new Promise((resolve, reject) => {
      const img = new Image();
      img.crossOrigin = 'anonymous';
      img.onload = () => resolve(img);
      img.onerror = () => reject(new Error(`Failed to load image: ${imageSource}`));
      img.src = imageSource;

--- ./src/utils/imageUtils.ts ---

/**
 * Convert URI to Blob for image uploads (handles file:// on iOS)
 */
export async function uriToBlob(uri: string): Promise<Blob> {
  const response = await fetch(uri);
  const blob = await response.blob();
  return blob;
}

/**
/**
 * Convert URI to Blob for image uploads (handles file:// on iOS)
 */
export async function uriToBlob(uri: string): Promise<Blob> {
  const response = await fetch(uri);
  const blob = await response.blob();
  return blob;
}

/**
 * Get image dimensions from URI

--- ./src/utils/clothing-grid.js ---
  console.log(`[generateClothingGrid] Cell dimensions: ${cellWidth}x${cellHeight}`);

  // Load all images asynchronously
  const images = [];
  for (let i = 0; i < imageUrls.length; i++) {
    const img = await new Promise((resolve, reject) => {
      const image = new Image();
      image.crossOrigin = 'anonymous'; // Enable CORS
      image.onload = () => {
        console.log(`[generateClothingGrid] Loaded image ${i + 1}/${imageUrls.length}: ${image.width}x${image.height}`);
        resolve(image);

  // Pre-process: Trim whitespace from all images
  console.log(`[generateClothingGrid] Trimming whitespace from ${images.length} images...`);
  const trimmedCanvases = [];
  for (let i = 0; i < images.length; i++) {
    const trimmedCanvas = await trimImageWhitespace(images[i], 15, false);
    trimmedCanvases.push(trimmedCanvas);
    console.log(`[generateClothingGrid] Trimmed image ${i + 1}/${images.length}: ${trimmedCanvas.width}x${trimmedCanvas.height}`);
  }

  // Create the canvas

--- ./src/utils/image-compression.ts ---
      maxWidthOrHeight: 1536,
      useWebWorker: true,
      fileType: 'image/webp' as const,
    };

    const compressedFile = await imageCompression(file, options);

    console.log('[compressImageFile] Compression complete:', {
      originalSize: file.size,
      compressedSize: compressedFile.size,
      reduction: `${((1 - compressedFile.size / file.size) * 100).toFixed(1)}%`,

--- ./src/utils/imageProcessor.ts ---
  const processedCanvases: { canvas: HTMLCanvasElement; height: number }[] = [];

  for (const file of files) {
    try {
      // First trim the image
      const trimmedBlob = await trimImageWhitespace(file);
      
      // Load the trimmed image
      const img = await new Promise<HTMLImageElement>((resolve, reject) => {
        const image = new Image();
        image.onload = () => resolve(image);
    try {
      // First trim the image
      const trimmedBlob = await trimImageWhitespace(file);
      
      // Load the trimmed image
      const img = await new Promise<HTMLImageElement>((resolve, reject) => {
        const image = new Image();
        image.onload = () => resolve(image);
        image.onerror = () => reject(new Error(`Failed to load trimmed image: ${file.name}`));
        image.src = URL.createObjectURL(trimmedBlob);
      });
  console.log(`[generateOutfitGridCanvas] Cell dimensions: ${cellWidth}x${cellHeight}`);

  // Load all images asynchronously
  const images: HTMLImageElement[] = [];
  for (let i = 0; i < imageUrls.length; i++) {
    const img = await new Promise<HTMLImageElement>((resolve, reject) => {
      const image = new Image();
      image.crossOrigin = 'anonymous'; // Allow CORS if needed
      image.onload = () => {
        console.log(`[generateOutfitGridCanvas] Loaded image ${i + 1}/${imageUrls.length}: ${image.width}x${image.height}`);
        resolve(image);

--- ./src/hooks/useSearch.ts ---
    setLoading(true);

    try {
      // Query all entity types in parallel
      const [usersResult, outfitsResult, lookbooksResult, wardrobeResult] =
        await Promise.all([
          searchUsers(searchQuery),
          searchOutfits(searchQuery),
          searchLookbooks(searchQuery),
          searchWardrobeItems(searchQuery),
        ]);

--- ./src/hooks/useFindSimilar.ts ---

  const loadWardrobeSimilar = useCallback(async () => {
    if (!user) return;

    setLoading(true);
    const { data } = await findSimilarInWardrobe(
      user.id,
      entityType,
      entityId,
      categoryId,
      20
    setLoading(false);
  }, [user, entityType, entityId, categoryId]);

  const loadSellableSimilar = useCallback(async () => {
    setLoading(true);
    const { data } = await findSimilarSellable(entityType, entityId, categoryId, 20);
    if (data) {
      setSellableResults(data);
    }
    setLoading(false);
  }, [entityType, entityId, categoryId]);
    setLoading(false);
  }, [entityType, entityId, categoryId]);

  const loadOnlineSimilar = useCallback(async () => {
    setLoading(true);
    const { data } = await searchOnlineSimilar(entityType, entityId, categoryId);
    if (data) {
      setOnlineResults(data);
      setOnlineSearched(true);
    }
    setLoading(false);
      loadOnlineSimilar();
    }
  }, [onlineSearched, loadOnlineSimilar]);

  const getItemImageUrl = useCallback(async (itemId: string): Promise<string | null> => {
    const { data: images } = await getWardrobeItemImages(itemId);
    if (images && images.length > 0) {
      const img = images[0].image;
      const bucket = img?.storage_bucket || 'media';
      const key = img?.storage_key;
      if (!key) return null;

--- ./src/hooks/useImageStacker.ts ---

    try {
      console.log(`[useImageStacker] Stacking ${files.length} images...`);

      // Get the current user session
      const { data: { session }, error: sessionError } = await supabase.auth.getSession();
      
      if (sessionError) {
        throw new Error(`Failed to get session: ${sessionError.message}`);
      }

      }

      const userId = session.user.id;

      // Process and stack images using the utility function
      const stackedBlob = await processAndStackImages(files);
      console.log(`[useImageStacker] Images stacked successfully`);

      // Generate a unique filename
      const timestamp = Date.now();
      const fileName = `stacked-${timestamp}.jpg`;
      const fileName = `stacked-${timestamp}.jpg`;
      const storagePath = `${userId}/ai/stacked/${fileName}`;

      // Upload to Supabase storage bucket 'media'
      // Use Uint8Array to ensure raw binary upload in React Native
      const arrayBuffer = await stackedBlob.arrayBuffer();
      const uploadData = new Uint8Array(arrayBuffer);

      const { data: uploadDataResult, error: uploadError } = await supabase.storage
        .from('media')
        .upload(storagePath, uploadData, {
      // Upload to Supabase storage bucket 'media'
      // Use Uint8Array to ensure raw binary upload in React Native
      const arrayBuffer = await stackedBlob.arrayBuffer();
      const uploadData = new Uint8Array(arrayBuffer);

      const { data: uploadDataResult, error: uploadError } = await supabase.storage
        .from('media')
        .upload(storagePath, uploadData, {
          cacheControl: '3600',
          upsert: false,
          contentType: 'image/jpeg',

--- ./src/hooks/wardrobe/useWardrobeItemEdit.ts ---
  const [visibilityExpanded, setVisibilityExpanded] = useState(false);
  const pollingIntervalRef = useRef<NodeJS.Timeout | null>(null);

  const loadSubcategories = async (categoryId: string) => {
    if (!categoryId) return;
    const { data } = await getSubcategories(categoryId);
    if (data) {
      setSubcategories(data);
    }
  };


    pollingIntervalRef.current = setInterval(async () => {
      if (!itemId || !userId) return;

      try {
        const { data: refreshedItem } = await getWardrobeItem(itemId);
        const { data: itemAttributes } = await getEntityAttributes(
          'wardrobe_item',
          itemId
        );

    pollingIntervalRef.current = setInterval(async () => {
      if (!itemId || !userId) return;

      try {
        const { data: refreshedItem } = await getWardrobeItem(itemId);
        const { data: itemAttributes } = await getEntityAttributes(
          'wardrobe_item',
          itemId
        );

        if (refreshedItem && itemAttributes) {
            setSelectedSubcategoryId(refreshedItem.subcategory_id || '');
            setCategoriesExpanded(false);
            setSubcategoriesExpanded(false);

            if (refreshedItem.category_id) {
              await loadSubcategories(refreshedItem.category_id);
            }

            if (pollingIntervalRef.current) {
              clearInterval(pollingIntervalRef.current);
              pollingIntervalRef.current = null;
    if (!userId || !itemId) return;

    setLoading(true);

    try {
      const { data: categoriesData } = await getWardrobeCategories();
      if (categoriesData) {
        setCategories(categoriesData);
      }

      const { data: foundItem, error: itemError } = await getWardrobeItem(itemId);
      const { data: categoriesData } = await getWardrobeCategories();
      if (categoriesData) {
        setCategories(categoriesData);
      }

      const { data: foundItem, error: itemError } = await getWardrobeItem(itemId);
      if (itemError) throw itemError;

      if (foundItem) {
        setItem(foundItem);
        setTitle(foundItem?.title || '');

        setCategoriesExpanded(!foundItem?.category_id);
        setSubcategoriesExpanded(!foundItem?.subcategory_id);
        setVisibilityExpanded(false);

        const { data: itemAttributes } = await getEntityAttributes(
          'wardrobe_item',
          itemId
        );

        const titleIsGenerated =
        if (isComplete) {
          setSelectedCategoryId(foundItem?.category_id || '');
          setSelectedSubcategoryId(foundItem?.subcategory_id || '');

          if (foundItem?.category_id) {
            await loadSubcategories(foundItem.category_id);
            setCategoriesExpanded(false);
            if (foundItem?.subcategory_id) {
              setSubcategoriesExpanded(false);
            }
          }

      if (size.trim()) {
        updateData.size = size.trim();
      }

      const { error } = await supabase
        .from('wardrobe_items')
        .update(updateData)
        .eq('id', itemId)
        .eq('owner_user_id', userId);

      Alert.alert('Error', error.message || 'Failed to save item');
    }
  };

  const refreshItem = async () => {
    await initialize();
  };

  useEffect(() => {
    if (itemId && userId) {
      initialize();

--- ./src/hooks/wardrobe/useWardrobe.ts ---

    setLoading(true);
    setError(null);

    try {
      const { data: defaultWardrobeId, error: wardrobeError } = await getDefaultWardrobeId(userId);
      
      if (wardrobeError) {
        throw wardrobeError;
      }


--- ./src/hooks/wardrobe/useAttributeEditor.ts ---
        } else {
          return onUpdateAttribute(attrId, value.trim());
        }
      });

      await Promise.all(updates);
      setEditingAttributeTypeKey(null);
      setEditingAttributeValues({});
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to update attributes');
    }
      Alert.alert('Error', 'Please select an attribute type and enter a value');
      return;
    }

    try {
      await onCreateAttribute(newAttributeKey, newAttributeValue.trim());
      setShowAddAttribute(false);
      setNewAttributeKey('');
      setNewAttributeValue('');
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to add attribute');

--- ./src/hooks/wardrobe/useItemAttributes.ts ---

  const refreshAttributes = async () => {
    if (!itemId) return;

    try {
      const { data: itemAttributes } = await getEntityAttributes(
        entityType,
        itemId
      );
      if (itemAttributes) {
        setAttributes(itemAttributes);

  const updateAttribute = async (attributeId: string, value: string) => {
    if (!itemId) return;

    try {
      const { error } = await updateEntityAttribute(attributeId, value);
      if (error) throw error;
      await refreshAttributes();
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to update attribute');
    }
    if (!itemId) return;

    try {
      const { error } = await updateEntityAttribute(attributeId, value);
      if (error) throw error;
      await refreshAttributes();
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to update attribute');
    }
  };


  const deleteAttribute = async (attributeId: string) => {
    if (!itemId) return;

    try {
      const { error } = await deleteEntityAttribute(attributeId);
      if (error) throw error;
      await refreshAttributes();
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to delete attribute');
    }
    if (!itemId) return;

    try {
      const { error } = await deleteEntityAttribute(attributeId);
      if (error) throw error;
      await refreshAttributes();
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to delete attribute');
    }
  };


  const createAttribute = async (definitionKey: string, value: string) => {
    if (!itemId) return;

    try {
      const { error } = await createEntityAttribute(
        entityType,
        itemId,
        definitionKey,
        value
      );
        itemId,
        definitionKey,
        value
      );
      if (error) throw error;
      await refreshAttributes();
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to create attribute');
    }
  };

        return;
      }

      setLoading(true);
      try {
        const { data: definitions } = await getAttributeDefinitions();
        if (definitions) {
          setAttributeDefinitions(definitions);
        }

        await refreshAttributes();
        const { data: definitions } = await getAttributeDefinitions();
        if (definitions) {
          setAttributeDefinitions(definitions);
        }

        await refreshAttributes();
      } catch (error: any) {
        console.error('Failed to load attributes:', error);
      } finally {
        setLoading(false);
      }

--- ./src/hooks/wardrobe/useCategories.ts ---
  const loadCategories = useCallback(async () => {
    setLoading(true);
    setError(null);

    try {
      const { data, error: categoriesError } = await getWardrobeCategories();
      
      if (categoriesError) {
        throw categoriesError;
      }

      setSubcategories([]);
      return;
    }

    try {
      const { data, error: subcategoriesError } = await getSubcategories(categoryId);
      
      if (subcategoriesError) {
        throw subcategoriesError;
      }


--- ./src/hooks/wardrobe/useWardrobeItemPolling.ts ---
    }, timeout);

    // Start polling
    pollingIntervalRef.current = setInterval(async () => {
      try {
        const { data: job, error } = await getAIJob(jobId);

        if (error) {
          console.error(`${logPrefix} Error fetching job:`, error);
          if (onError) {
            stopPolling();

--- ./src/hooks/wardrobe/useAddWardrobeItem.ts ---
      setAnalysisStep('Adding item to your wardrobe');
    }
  }, [aiJob, generatingAI]);

  const handleTakePhoto = useCallback(async () => {
    const { status } = await ImagePicker.requestCameraPermissionsAsync();
    if (status !== 'granted') {
      Alert.alert('Permission Required', 'Please grant camera permissions');
      return;
    }

      return;
    }

    const mediaTypes = (ImagePicker as any).MediaType?.Images || 'images';

    const result = await ImagePicker.launchCameraAsync({
      mediaTypes,
      allowsEditing: false, // We'll handle cropping in our cropper
      quality: 0.8,
    });

      }
    }
  }, []);

  const handleUploadPhoto = useCallback(async () => {
    const { status } = await ImagePicker.requestMediaLibraryPermissionsAsync();
    if (status !== 'granted') {
      Alert.alert('Permission Required', 'Please grant camera roll permissions');
      return;
    }

      return;
    }

    const mediaTypes = (ImagePicker as any).MediaType?.Images || 'images';

    const result = await ImagePicker.launchImageLibraryAsync({
      mediaTypes,
      allowsMultipleSelection: Platform.OS !== 'web', // Single selection on web to show cropper
      quality: 0.8,
    });

    setLoading(true);
    setAiError(null);

    try {
      // Create item with placeholder title
      const { data, error } = await createWardrobeItem(
        user.id,
        wardrobeId,
        {
          title: 'New Item',
          description: undefined,
          imageId: imageIds[0],
          itemId,
          imageIds,
        });
        
        const { data: batchJob, error: batchError } = await triggerBatchJob(
          user.id,
          imageIds[0],
          itemId,
          imageIds
        );
          pendingItemId: itemId,
        });

        // Trigger job execution
        console.log('[useAddWardrobeItem] Triggering job execution for:', batchJob.id);
        const { error: execError } = await triggerAIJobExecution(batchJob.id);
        
        if (execError) {
          console.warn('[useAddWardrobeItem] Job trigger returned error (may still work):', execError);
          // Continue anyway - job might still be triggered
        } else {

--- ./src/hooks/wardrobe/useWardrobeItemDetailActions.ts ---
  useEffect(() => {
    const checkIfSaved = async () => {
      if (!itemId || !user || !item) return;
      const isOwn = item.owner_user_id === user.id;
      if (isReadOnly && !isOwn) {
        const { data: saved } = await isWardrobeItemSaved(user.id, itemId);
        setIsSaved(saved || false);
      }
    };

    if (item && user) {
  const toggleFavorite = useCallback(async () => {
    if (!itemId || !user || !item) return;

    try {
      const newFavoriteStatus = !item.is_favorite;
      const { error } = await supabase
        .from('wardrobe_items')
        .update({ is_favorite: newFavoriteStatus })
        .eq('id', itemId)
        .eq('owner_user_id', user.id);


    setIsSaving(true);
    const isCurrentlySaved = isSaved;

    if (isCurrentlySaved) {
      const { error } = await unsaveWardrobeItem(user.id, itemId);
      if (!error) {
        setIsSaved(false);
        Alert.alert('Success', 'Item removed from your wardrobe');
      } else {
        Alert.alert('Error', 'Failed to remove item from wardrobe');
        Alert.alert('Success', 'Item removed from your wardrobe');
      } else {
        Alert.alert('Error', 'Failed to remove item from wardrobe');
      }
    } else {
      const { error } = await saveWardrobeItem(user.id, itemId);
      if (!error) {
        setIsSaved(true);
        Alert.alert('Success', 'Item saved to your wardrobe');
      } else {
        Alert.alert('Error', 'Failed to save item to wardrobe');
  const handleDelete = useCallback(async () => {
    if (!isOwnItem || !itemId || !user) return;

    const deleteAction = async () => {
      try {
        const { error } = await supabase
          .from('wardrobe_items')
          .update({ archived_at: new Date().toISOString() })
          .eq('id', itemId)
          .eq('owner_user_id', user.id);


    if (Platform.OS === 'web') {
      if (
        confirm('Are you sure you want to delete this item? This action cannot be undone.')
      ) {
        await deleteAction();
      }
    } else {
      Alert.alert(
        'Delete Item',
        'Are you sure you want to delete this item? This action cannot be undone.',

    try {
      const shareUrl = `${process.env.EXPO_PUBLIC_APP_URL || 'https://fullstylist.app'}/wardrobe/item/${itemId}`;
      const message = `Check out my ${item.title} on Full Stylist!`;

      await Share.share({
        message: `${message}\n${shareUrl}`,
        title: item.title,
      });
    } catch (error: any) {
      console.error('Share error:', error);

--- ./src/hooks/wardrobe/useWardrobeItemData.ts ---
  const [tags, setTags] = useState<Array<{ id: string; name: string }>>([]);

  const refreshImages = useCallback(async () => {
    if (!itemId) return;

    const { data: refreshedImages } = await getWardrobeItemImages(itemId);
    const { data: itemAttributes } = await getEntityAttributes(
      'wardrobe_item',
      itemId
    );


  const refreshImages = useCallback(async () => {
    if (!itemId) return;

    const { data: refreshedImages } = await getWardrobeItemImages(itemId);
    const { data: itemAttributes } = await getEntityAttributes(
      'wardrobe_item',
      itemId
    );

    if (refreshedImages) {
  }, [itemId]);

  const refreshAttributes = useCallback(async () => {
    if (!itemId) return;

    const { data: itemAttributes } = await getEntityAttributes(
      'wardrobe_item',
      itemId
    );
    if (itemAttributes && itemAttributes.length > 0) {
      setAttributes(itemAttributes);
      'wardrobe_item',
      itemId
    );
    if (itemAttributes && itemAttributes.length > 0) {
      setAttributes(itemAttributes);
      const { data: refreshedItem } = await getWardrobeItem(itemId);
      if (refreshedItem) {
        setItem(refreshedItem);
        if (refreshedItem.category_id) {
          const { data: categories } = await getWardrobeCategories();
          const foundCategory = categories?.find(
      setAttributes(itemAttributes);
      const { data: refreshedItem } = await getWardrobeItem(itemId);
      if (refreshedItem) {
        setItem(refreshedItem);
        if (refreshedItem.category_id) {
          const { data: categories } = await getWardrobeCategories();
          const foundCategory = categories?.find(
            (c) => c.id === refreshedItem.category_id
          );
          if (foundCategory) {
            setCategory(foundCategory);

  const loadItemData = useCallback(async () => {
    if (!itemId) return;

    try {
      const { data: foundItem, error: itemError } = await getWardrobeItem(
        itemId
      );

      if (itemError) throw itemError;

      if (itemError) throw itemError;

      if (foundItem) {
        setItem(foundItem);

        const { data: categories } = await getWardrobeCategories();
        const foundCategory = categories?.find(
          (c) => c.id === foundItem?.category_id
        );
        if (foundCategory) {
          setCategory(foundCategory);
        if (foundCategory) {
          setCategory(foundCategory);
        }
      }

      const { data: itemImages } = await getWardrobeItemImages(itemId);

      if (itemImages) {
        setAllImages(itemImages);
        const filtered = itemImages.filter(
          (img) => img.type === 'original' || img.type === 'product_shot'
          (img) => img.type === 'original' || img.type === 'product_shot'
        );
        setDisplayImages(filtered);
      }

      const { data: itemAttributes } = await getEntityAttributes(
        'wardrobe_item',
        itemId
      );
      if (itemAttributes) {
        setAttributes(itemAttributes);
      );
      if (itemAttributes) {
        setAttributes(itemAttributes);
      }

      const { data: tagLinks } = await supabase
        .from('tag_links')
        .select('*, tags(id, name)')
        .eq('entity_type', 'wardrobe_item')
        .eq('entity_id', itemId);


--- ./src/hooks/wardrobe/useWardrobeItemNavigation.ts ---
    try {
      const idsArray = itemIds.split(',');
      const currentIndex = idsArray.indexOf(currentItemId || '');
      setCurrentItemIndex(currentIndex >= 0 ? currentIndex : 0);

      const { data: allItems } = await getWardrobeItemsByIds(idsArray);

      if (!allItems || allItems.length === 0) return;

      const itemsMap = new Map(allItems.map((item) => [item.id, item]));

      if (!allItems || allItems.length === 0) return;

      const itemsMap = new Map(allItems.map((item) => [item.id, item]));

      const visibleItemIds = idsArray.slice(0, 6);
      const { data: imagesMap } = await getWardrobeItemsImages(visibleItemIds);

      const navItems = idsArray
        .map((itemId) => {
          const foundItem = itemsMap.get(itemId);
          if (!foundItem) return null;

--- ./src/hooks/wardrobe/useWardrobeItemDetail.ts ---
      clearTimeout(periodicImageTimeoutRef.current);
    }

    periodicImageRefreshRef.current = setInterval(async () => {
      if (!itemId) return;
      await data.refreshImages();
    }, 3000);

    periodicImageTimeoutRef.current = setTimeout(() => {
      if (periodicImageRefreshRef.current) {
        clearInterval(periodicImageRefreshRef.current);
    if (periodicAttributeTimeoutRef.current) {
      clearTimeout(periodicAttributeTimeoutRef.current);
    }

    periodicAttributeRefreshRef.current = setInterval(async () => {
      await data.refreshAttributes();
    }, 5000);

    periodicAttributeTimeoutRef.current = setTimeout(() => {
      if (periodicAttributeRefreshRef.current) {
        clearInterval(periodicAttributeRefreshRef.current);
  // Product shot polling
  const productShotPolling = useWardrobeItemPolling({
    jobId: productShotJobId,
    onComplete: async () => {
      setIsGeneratingProductShot(false);
      await data.refreshImages();
    },
    onError: () => {
      startPeriodicImageRefresh();
    },
    onTimeout: () => {

  // Auto-tag polling
  const autoTagPolling = useWardrobeItemPolling({
    jobId: autoTagJobId,
    onComplete: async () => {
      await data.refreshAttributes();
    },
    onError: () => {
      startPeriodicAttributeRefresh();
    },
    onTimeout: () => {
  const batchJobPolling = useWardrobeItemPolling({
    jobId: batchJobId,
    onComplete: async () => {
      setIsGeneratingProductShot(false);
      // Refresh both images and attributes since batch job handles both
      await data.refreshImages();
      await data.refreshAttributes();
    },
    onError: () => {
      // Fallback to periodic refresh if batch job fails
      startPeriodicImageRefresh();
    jobId: batchJobId,
    onComplete: async () => {
      setIsGeneratingProductShot(false);
      // Refresh both images and attributes since batch job handles both
      await data.refreshImages();
      await data.refreshAttributes();
    },
    onError: () => {
      // Fallback to periodic refresh if batch job fails
      startPeriodicImageRefresh();
      startPeriodicAttributeRefresh();

    const loadItemData = async () => {
      setLoading(true);

      try {
        await data.loadItemData();

        // Check for batch job first (new approach - combines product_shot and auto_tag)
        const { data: activeBatchJob } = await getActiveBatchJob(itemId, userId);
        
        if (activeBatchJob) {

      try {
        await data.loadItemData();

        // Check for batch job first (new approach - combines product_shot and auto_tag)
        const { data: activeBatchJob } = await getActiveBatchJob(itemId, userId);
        
        if (activeBatchJob) {
          // Batch job is active - use it for both product shot and auto tag
          setIsGeneratingProductShot(true);
          setBatchJobId(activeBatchJob.id);
          setIsGeneratingProductShot(true);
          setBatchJobId(activeBatchJob.id);
          // Don't check for individual jobs if batch job exists
        } else {
          // No active batch job - check for recent batch job
          const { data: recentBatchJob } = await getRecentBatchJob(itemId, userId);
          
          if (recentBatchJob && recentBatchJob.status === 'succeeded') {
            // Recent batch job completed - refresh data
            await data.refreshImages();
            await data.refreshAttributes();
          // No active batch job - check for recent batch job
          const { data: recentBatchJob } = await getRecentBatchJob(itemId, userId);
          
          if (recentBatchJob && recentBatchJob.status === 'succeeded') {
            // Recent batch job completed - refresh data
            await data.refreshImages();
            await data.refreshAttributes();
          } else {
            // No batch job found - fall back to checking individual jobs (legacy support)
            const itemImages = data.allImages;

          const { data: recentBatchJob } = await getRecentBatchJob(itemId, userId);
          
          if (recentBatchJob && recentBatchJob.status === 'succeeded') {
            // Recent batch job completed - refresh data
            await data.refreshImages();
            await data.refreshAttributes();
          } else {
            // No batch job found - fall back to checking individual jobs (legacy support)
            const itemImages = data.allImages;

            if (itemImages && itemImages.length > 0) {
                  (img) => img.type === 'product_shot' && img.image?.created_at
                )
                .map((img) => new Date(img.image.created_at).getTime())
                .reduce((latest, current) => Math.max(latest, current), 0) || null;

              const { data: activeJob } = await getActiveProductShotJob(
                itemId,
                userId
              );

              if (activeJob) {
                  setProductShotJobId(activeJob.id);
                } else {
                  setIsGeneratingProductShot(false);
                }
              } else if (!hasProductShot) {
                const { data: recentJob } = await getRecentProductShotJob(
                  itemId,
                  userId
                );

                if (recentJob && recentJob.status === 'succeeded') {
                  itemId,
                  userId
                );

                if (recentJob && recentJob.status === 'succeeded') {
                  await data.refreshImages();
                } else {
                  setIsGeneratingProductShot(true);
                  startPeriodicImageRefresh();
                }
              }
          const currentItem = data.item;
          if (
            (!currentAttributes || currentAttributes.length === 0 || currentItem?.title === 'New Item') &&
            userId
          ) {
            const { data: activeAutoTagJobs } = await supabase
              .from('ai_jobs')
              .select('*')
              .eq('job_type', 'auto_tag')
              .eq('owner_user_id', userId)
              .in('status', ['queued', 'running'])

--- ./src/hooks/wardrobe/useWardrobeItems.ts ---
    setLoading(true);
    setError(null);

    try {
      // Load owned items
      const { data: ownedItems, error: ownedError } = await getWardrobeItems(wardrobeId, {
        category_id: categoryId,
        search: searchQuery,
      });

      // Load saved items from other users
        category_id: categoryId,
        search: searchQuery,
      });

      // Load saved items from other users
      const { data: savedItems, error: savedError } = await getSavedWardrobeItems(userId, {
        category_id: categoryId,
        search: searchQuery,
      });

      if (ownedError || savedError) {
      setAllItems(combinedItems);

      // Batch load images
      if (combinedItems.length > 0) {
        const itemIds = combinedItems.map(item => item.id);
        const { data: imagesMap } = await getWardrobeItemsImages(itemIds);

        // Build URL cache
        const newCache = new Map<string, string | null>();
        for (const itemId of itemIds) {
          const images = imagesMap.get(itemId);
  }, [wardrobeId, userId, categoryId, searchQuery]);

  // Refresh items (for pull-to-refresh)
  const refresh = useCallback(async () => {
    setRefreshing(true);
    await loadItems();
    setRefreshing(false);
  }, [loadItems]);

  // Auto-load on mount and when dependencies change
  useEffect(() => {

--- ./src/hooks/calendar/useDayEntries.ts ---
    }

    setLoading(true);

    try {
      const { data: dayEntries } = await getCalendarEntriesForDate(userId, date);
      if (dayEntries) {
        setEntries(dayEntries);
      }
    } catch (error) {
      console.error('Error loading day entries:', error);
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadEntries();
  };

  const addEntry = async (data: {
    outfit_id?: string;
    slot_preset_id?: string;
  }) => {
    if (!userId || !date) {
      return { data: null, error: { message: 'User or date not provided' } };
    }

    const result = await createCalendarEntry(userId, date, data);

    if (!result.error) {
      await refresh();
    }

    }

    const result = await createCalendarEntry(userId, date, data);

    if (!result.error) {
      await refresh();
    }

    return result;
  };


    return result;
  };

  const updateEntry = async (entryId: string, data: Partial<CalendarEntry>) => {
    const result = await updateCalendarEntry(entryId, data);

    if (!result.error) {
      await refresh();
    }


  const updateEntry = async (entryId: string, data: Partial<CalendarEntry>) => {
    const result = await updateCalendarEntry(entryId, data);

    if (!result.error) {
      await refresh();
    }

    return result;
  };


    return result;
  };

  const deleteEntry = async (entryId: string) => {
    const result = await deleteCalendarEntry(entryId);

    if (!result.error) {
      setEntries(entries.filter((e) => e.id !== entryId));
    }


      const updatePromises = updates.map((update) =>
        updateCalendarEntry(update.id, { sort_order: update.sort_order })
      );

      const results = await Promise.all(updatePromises);
      const errors = results.filter((r) => r.error);

      if (errors.length > 0) {
        // Rollback on error
        await refresh();
      const results = await Promise.all(updatePromises);
      const errors = results.filter((r) => r.error);

      if (errors.length > 0) {
        // Rollback on error
        await refresh();
      }
    } catch (error) {
      // Rollback on error
      await refresh();
    }
        // Rollback on error
        await refresh();
      }
    } catch (error) {
      // Rollback on error
      await refresh();
    }
  };

  useEffect(() => {
    loadEntries();

--- ./src/hooks/calendar/useSlotPresets.ts ---
    }

    setLoading(true);

    try {
      const { data } = await getSlotPresets(userId);
      if (data) {
        setPresets(data);
      }
    } catch (error) {
      console.error('Error loading slot presets:', error);
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadPresets();
  };

  const createPreset = async (name: string) => {
    if (!userId) {
      return { data: null, error: { message: 'User not provided' } };
  const createPreset = async (name: string) => {
    if (!userId) {
      return { data: null, error: { message: 'User not provided' } };
    }

    const result = await createSlotPreset(userId, name);

    if (!result.error) {
      await refresh();
    }

    }

    const result = await createSlotPreset(userId, name);

    if (!result.error) {
      await refresh();
    }

    return result;
  };


--- ./src/hooks/calendar/useCalendarEntries.ts ---

    setLoading(true);

    try {
      // Load all entries for the date range
      const { data: monthEntries } = await getCalendarEntries(userId, startDate, endDate);

      // Group entries by date
      const entriesMap = new Map<string, CalendarEntry[]>();
      if (monthEntries) {
        monthEntries.forEach((entry) => {

      setEntries(entriesMap);

      // Load outfit images
      if (monthEntries) {
        await loadOutfitImages(monthEntries);
      }
    } catch (error) {
      console.error('Error loading calendar entries:', error);
    } finally {
      setLoading(false);
        )
        .eq('id', outfitId)
        .single()
    );

    const outfitResults = await Promise.all(outfitPromises);

    for (const { data: outfit } of outfitResults) {
      const coverImage = Array.isArray(outfit?.cover_image) ? outfit?.cover_image?.[0] : outfit?.cover_image;
      if (coverImage?.storage_key) {
        const storageBucket = (coverImage as any).storage_bucket || 'media';

    setOutfitImages(imagesMap);
  };

  const refresh = async () => {
    await loadEntries();
  };

  useEffect(() => {
    loadEntries();
  }, [userId, startDate, endDate]);

--- ./src/hooks/calendar/useCalendarDayForm.ts ---
      return;
    }

    setSaving(true);

    const { error } = await addEntry({
      outfit_id: selectedOutfit || undefined,
      slot_preset_id: selectedPreset,
      status: entryStatus,
      notes: editNotes.trim() || undefined,
      sort_order: entries.length,
  const handleUpdateEntry = useCallback(async () => {
    if (!editingEntry) return;

    setSaving(true);

    const { error } = await updateEntry(editingEntry.id, {
      outfit_id: selectedOutfit || null,
      slot_preset_id: selectedPreset || null,
      status: entryStatus,
      notes: editNotes.trim() || null,
    });
  }, []);

  const confirmDelete = useCallback(async () => {
    if (!entryToDelete) return;

    const { error } = await deleteEntry(entryToDelete);

    if (error) {
      Alert.alert('Error', 'Failed to delete entry');
    }

      if (entryIndex === -1) return;

      const newIndex = direction === 'up' ? entryIndex - 1 : entryIndex + 1;
      if (newIndex < 0 || newIndex >= entries.length) return;

      await reorderEntries(entryIndex, newIndex);
    },
    [entries, reorderEntries]
  );

  const handleStatusChange = useCallback(
    [entries, reorderEntries]
  );

  const handleStatusChange = useCallback(
    async (entryId: string, status: 'planned' | 'worn' | 'skipped') => {
      await updateEntry(entryId, { status });
    },
    [updateEntry]
  );

  const handleCreatePreset = useCallback(
      if (!newPresetName.trim()) {
        Alert.alert('Error', 'Please enter a preset name');
        return;
      }

      const { error } = await createPresetFn(newPresetName.trim());

      if (error) {
        Alert.alert('Error', `Failed to create preset: ${error.message || error}`);
      } else {
        setNewPresetName('');

--- ./src/hooks/calendar/useUserOutfits.ts ---
    }

    setLoading(true);

    try {
      const { data: userOutfits } = await getUserOutfits(userId);
      if (userOutfits) {
        setOutfits(userOutfits);

        // Load outfit images
        const imagesMap = new Map<string, string | null>();

        // Load outfit images
        const imagesMap = new Map<string, string | null>();
        for (const outfit of userOutfits) {
          if (outfit.cover_image_id) {
            const { data: coverImage } = await supabase
              .from('images')
              .select('storage_key, storage_bucket')
              .eq('id', outfit.cover_image_id)
              .single();

      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadOutfits();
  };

  useEffect(() => {
    loadOutfits();
  }, [userId]);

--- ./src/hooks/lookbooks/useLookbookDetailActions.ts ---
      }

      try {
        const outfitIds = outfits.map((outfit) => outfit.id);

        const { error } = await saveLookbook(
          user.id,
          {
            id: lookbook.id,
            title: title.trim(),
            description: description.trim() || undefined,

        if (error) {
          Alert.alert('Error', 'Failed to update lookbook');
        } else {
          setShowEditModal(false);
          await onRefresh();
        }
      } catch (error: any) {
        Alert.alert('Error', error.message || 'Failed to update lookbook');
      }
    },
        {
          text: 'Delete',
          style: 'destructive',
          onPress: async () => {
            setDeleting(true);
            const { error } = await deleteLookbook(user.id, lookbook.id);

            if (error) {
              Alert.alert('Error', 'Failed to delete lookbook');
              setDeleting(false);
            } else {
    if (!user || !lookbook) return;

    setPublishing(true);

    try {
      const { error } = await createPost(
        user.id,
        'lookbook',
        lookbook.id,
        undefined,
        lookbook.visibility === 'inherit' ? 'followers' : lookbook.visibility

    setLoadingOutfits(true);
    setShowAddOutfitsModal(true);

    try {
      const { data: allOutfits } = await getUserOutfits(user.id);
      if (allOutfits) {
        const existingOutfitIds = new Set(outfits.map((o) => o.id));
        const available = allOutfits.filter((o: any) => !existingOutfitIds.has(o.id));
        setAvailableOutfits(available);

        const existingOutfitIds = new Set(outfits.map((o) => o.id));
        const available = allOutfits.filter((o: any) => !existingOutfitIds.has(o.id));
        setAvailableOutfits(available);

        const imageUrlMap = new Map<string, string | null>();
        await Promise.all(
          available.map(async (outfit: any) => {
            const url = await getOutfitCoverImageUrl(outfit);
            imageUrlMap.set(outfit.id, url);
          })
        );
        setAvailableOutfits(available);

        const imageUrlMap = new Map<string, string | null>();
        await Promise.all(
          available.map(async (outfit: any) => {
            const url = await getOutfitCoverImageUrl(outfit);
            imageUrlMap.set(outfit.id, url);
          })
        );
        setAddOutfitImageUrls(imageUrlMap);
      }
  }, []);

  const handleAddOutfits = useCallback(
    async (addOutfitsFn: (outfitIds: string[]) => Promise<void>) => {
      if (selectedNewOutfits.size === 0) return;
      await addOutfitsFn(Array.from(selectedNewOutfits));
      setShowAddOutfitsModal(false);
      setSelectedNewOutfits(new Set());
    },
    [selectedNewOutfits]
  );

  const handleRemoveOutfitFromMenu = useCallback(
    async (removeOutfitFn: (outfitId: string) => Promise<void>) => {
      if (!selectedOutfit) return;
      setShowOutfitMenu(false);
      await removeOutfitFn(selectedOutfit.id);
    },
    [selectedOutfit]
  );

  const toggleFavorite = useCallback(
  const toggleFavorite = useCallback(
    async (outfitId: string, currentFavoriteStatus: boolean) => {
      if (!user) return;

      try {
        const { error } = await supabase
          .from('outfits')
          .update({ is_favorite: !currentFavoriteStatus })
          .eq('id', outfitId)
          .eq('owner_user_id', user.id);

    [user, outfits, onOutfitsChange]
  );

  const handleOpenSlideshow = useCallback(async () => {
    if (outfits.length === 0) return;
    await onSlideshowOpen(outfits);
  }, [outfits, onSlideshowOpen]);

  return {
    // Edit modal
    showEditModal,

--- ./src/hooks/lookbooks/useNewLookbook.ts ---

  const loadOutfits = useCallback(async () => {
    if (!user) return;

    setLoading(true);
    const { data: userOutfits } = await getUserOutfits(user.id);
    if (userOutfits) {
      setOutfits(userOutfits);

      // Pre-load all outfit images
      const imageUrlMap = new Map<string, string | null>();
    if (userOutfits) {
      setOutfits(userOutfits);

      // Pre-load all outfit images
      const imageUrlMap = new Map<string, string | null>();
      await Promise.all(
        userOutfits.map(async (outfit: any) => {
          const url = await getOutfitCoverImageUrl(outfit);
          imageUrlMap.set(outfit.id, url);
        })
      );

      // Pre-load all outfit images
      const imageUrlMap = new Map<string, string | null>();
      await Promise.all(
        userOutfits.map(async (outfit: any) => {
          const url = await getOutfitCoverImageUrl(outfit);
          imageUrlMap.set(outfit.id, url);
        })
      );
      setOutfitImageUrls(imageUrlMap);
    }
        filter_definition: type === 'custom_filter' ? filterDefinition : undefined,
      };

      const outfitIds = type === 'custom_manual' ? Array.from(selectedOutfits) : undefined;

      const { data: lookbook, error } = await saveLookbook(user.id, lookbookData, outfitIds);

      if (error) {
        throw error;
      }


--- ./src/hooks/lookbooks/useSystemLookbooks.ts ---

    setLoading(true);

    try {
      // Load all system categories in parallel
      const [favoritesResult, recentResult, topResult] = await Promise.all([
        getSystemLookbookOutfits(userId, 'system_favorites'),
        getSystemLookbookOutfits(userId, 'system_recent'),
        getSystemLookbookOutfits(userId, 'system_top'),
      ]);

        getSystemLookbookOutfits(userId, 'system_recent'),
        getSystemLookbookOutfits(userId, 'system_top'),
      ]);

      // Get all outfits for mapping
      const { data: allOutfits } = await getUserOutfits(userId);
      const outfitMap = allOutfits
        ? new Map(allOutfits.map((o: any) => [o.id, o]))
        : new Map();

      const categories: {
          }
          return true;
        });

      // Load cover images
      const lookbooksWithCovers = await Promise.all(
        lookbooksData.map(async (lookbook) => {
          const coverOutfit = lookbook.outfits[0] || null;
          const coverImageUrl = coverOutfit
            ? await getOutfitCoverImageUrl(coverOutfit)
            : null;
      // Load cover images
      const lookbooksWithCovers = await Promise.all(
        lookbooksData.map(async (lookbook) => {
          const coverOutfit = lookbook.outfits[0] || null;
          const coverImageUrl = coverOutfit
            ? await getOutfitCoverImageUrl(coverOutfit)
            : null;
          return {
            ...lookbook,
            coverImageUrl,
          };
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadSystemLookbooks();
  };

  useEffect(() => {
    loadSystemLookbooks();
  }, [userId]);

--- ./src/hooks/lookbooks/useLookbookDetail.ts ---
        };

        setLookbook(virtualLookbook);

        // Load system outfits
        const { data: systemOutfitsResult } = await getSystemLookbookOutfits(
          userId,
          systemTypeMap[systemType]
        );

        if (systemOutfitsResult) {
          userId,
          systemTypeMap[systemType]
        );

        if (systemOutfitsResult) {
          const { data: allOutfits } = await getUserOutfits(userId);
          if (allOutfits) {
            const outfitMap = new Map(allOutfits.map((o: any) => [o.id, o]));
            const outfitsWithData = systemOutfitsResult
              .map((so) => outfitMap.get(so.outfit_id))
              .filter(Boolean);
            setOutfits(outfitsWithData);
          }
        }
      } else {
        // Regular database lookbook
        const { data, error } = await getLookbook(lookbookId);

        if (!error && data) {
          setLookbook(data.lookbook);

          // Load outfits
        if (!error && data) {
          setLookbook(data.lookbook);

          // Load outfits
          if (data.lookbook.type === 'custom_manual') {
            const { data: allOutfits } = await getUserOutfits(data.lookbook.owner_user_id);

            if (allOutfits) {
              const outfitMap = new Map(allOutfits.map((o: any) => [o.id, o]));
              const lookbookOutfits = data.outfits
                .map((lo: any) => outfitMap.get(lo.outfit_id))
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadLookbook();
  };

  useEffect(() => {
    loadLookbook();
  }, [lookbookId, userId]);

--- ./src/hooks/lookbooks/useLookbookOutfits.ts ---

    setAddingOutfits(true);
    try {
      const updatedOutfitIds = [...outfits.map((o) => o.id), ...outfitIds];

      const { error } = await saveLookbook(
        userId,
        {
          id: lookbook.id,
          title: lookbook.title,
          description: lookbook.description,
      );

      if (error) {
        Alert.alert('Error', 'Failed to add outfits to lookbook');
      } else {
        await onRefresh();
      }
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to add outfits');
    } finally {
      setAddingOutfits(false);
    if (!userId || !lookbook) return;

    try {
      const updatedOutfitIds = outfits.filter((o) => o.id !== outfitId).map((o) => o.id);

      const { error } = await saveLookbook(
        userId,
        {
          id: lookbook.id,
          title: lookbook.title,
          description: lookbook.description,

  const removeOutfitWithConfirm = async (outfitId: string) => {
    if (!userId || !lookbook) return;

    const removeAction = async () => {
      await removeOutfit(outfitId);
    };

    if (Platform.OS === 'web') {
      if (confirm('Remove this outfit from the lookbook?')) {
        await removeAction();
      await removeOutfit(outfitId);
    };

    if (Platform.OS === 'web') {
      if (confirm('Remove this outfit from the lookbook?')) {
        await removeAction();
      }
    } else {
      Alert.alert(
        'Remove Outfit',
        'Remove this outfit from the lookbook?',

--- ./src/hooks/lookbooks/useSlideshow.ts ---

    try {
      // Pre-load all images
      const imageMap = new Map<string, string | null>();
      const loadPromises = outfitsToShow.map(async (outfit) => {
        const url = await getOutfitCoverImageUrl(outfit);
        imageMap.set(outfit.id, url);
      });
      await Promise.all(loadPromises);

      setImages(imageMap);
      const imageMap = new Map<string, string | null>();
      const loadPromises = outfitsToShow.map(async (outfit) => {
        const url = await getOutfitCoverImageUrl(outfit);
        imageMap.set(outfit.id, url);
      });
      await Promise.all(loadPromises);

      setImages(imageMap);
      setOutfits(outfitsToShow);
      setCurrentIndex(0);
      setIsAutoPlaying(true);

--- ./src/hooks/lookbooks/useLookbooks.ts ---
    }

    setLoading(true);

    try {
      const { data } = await getUserLookbooks(userId);
      if (data) {
        const customLookbooks = data.filter((lb) => lb.type.startsWith('custom_'));
        setLookbooks(customLookbooks);

        // Mark all as loading

        // Mark all as loading
        setLoadingIds(new Set(customLookbooks.map((lb) => lb.id)));

        // Load thumbnails for each lookbook
        const { data: allOutfits } = await getUserOutfits(userId);
        const thumbnailMap = new Map<string, string | null>();

        if (allOutfits) {
          const thumbnailPromises = customLookbooks.map(async (lookbook) => {
            if (lookbook.type === 'custom_manual') {
        const thumbnailMap = new Map<string, string | null>();

        if (allOutfits) {
          const thumbnailPromises = customLookbooks.map(async (lookbook) => {
            if (lookbook.type === 'custom_manual') {
              const { data: lookbookData } = await getLookbook(lookbook.id);
              if (lookbookData && lookbookData.outfits.length > 0) {
                const firstOutfit = allOutfits.find(
                  (o: any) => o.id === lookbookData.outfits[0].outfit_id
                );
                if (firstOutfit) {
              if (lookbookData && lookbookData.outfits.length > 0) {
                const firstOutfit = allOutfits.find(
                  (o: any) => o.id === lookbookData.outfits[0].outfit_id
                );
                if (firstOutfit) {
                  const imageUrl = await getOutfitCoverImageUrl(firstOutfit);
                  return { id: lookbook.id, url: imageUrl };
                }
              }
            }
            return null;
              }
            }
            return null;
          });

          const results = await Promise.all(thumbnailPromises);
          results.forEach((result) => {
            if (result) {
              thumbnailMap.set(result.id, result.url);
            }
          });
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadLookbooks();
  };

  useEffect(() => {
    loadLookbooks();
  }, [userId]);

--- ./src/hooks/listings/useNewListing.ts ---

  const loadWardrobe = useCallback(async () => {
    if (!user) return;

    setLoading(true);
    const { data: defaultWardrobeId } = await getDefaultWardrobeId(user.id);
    if (defaultWardrobeId) {
      setWardrobeId(defaultWardrobeId);
      const { data: wardrobeItems } = await getWardrobeItems(defaultWardrobeId, {});
      if (wardrobeItems) {
        setItems(wardrobeItems);

    setLoading(true);
    const { data: defaultWardrobeId } = await getDefaultWardrobeId(user.id);
    if (defaultWardrobeId) {
      setWardrobeId(defaultWardrobeId);
      const { data: wardrobeItems } = await getWardrobeItems(defaultWardrobeId, {});
      if (wardrobeItems) {
        setItems(wardrobeItems);
      }
    }
    setLoading(false);
    }
  }, [user, loadWardrobe]);

  const selectItem = useCallback(async (item: WardrobeItem) => {
    setSelectedItem(item);
    const { data: images } = await getWardrobeItemImages(item.id);
    if (images) {
      // Filter to only original images
      const originalImages = images.filter((img) => img.type === 'original');
      setItemImages(originalImages);
      // Auto-select all original images
    }

    setSaving(true);

    try {
      const { data: listing, error } = await createListing(user.id, selectedItem.id, {
        price: parseFloat(price),
        currency: 'AUD',
        condition: condition,
        imageIds: Array.from(selectedImageIds),
      });

--- ./src/hooks/feedback/useFeedbackThread.ts ---
  const loadThread = async () => {
    if (!threadId) return;

    setLoading(true);

    const { data: threadData } = await getFeedbackThread(threadId);
    if (threadData) {
      setThread(threadData);
    }

    const { data: commentsData } = await getFeedbackThreadComments(threadId);
    const { data: threadData } = await getFeedbackThread(threadId);
    if (threadData) {
      setThread(threadData);
    }

    const { data: commentsData } = await getFeedbackThreadComments(threadId);
    if (commentsData) {
      setComments(commentsData);
    }

    setLoading(false);

    setLoading(false);
  };

  const refresh = async () => {
    await loadThread();
  };

  const submitComment = async (text: string): Promise<boolean> => {
    if (!userId || !threadId || !text.trim()) return false;

    if (!userId || !threadId || !text.trim()) return false;

    setSubmittingComment(true);

    try {
      const { data: comment, error } = await createFeedbackThreadComment(
        userId,
        threadId,
        text.trim()
      );


      if (error) throw error;

      if (comment) {
        setComments([comment, ...comments]);
        await loadThread();
        return true;
      }
      return false;
    } catch (error: any) {
      Alert.alert('Error', `Failed to post comment: ${error.message || error}`);
    newStatus: 'open' | 'in_progress' | 'resolved' | 'closed'
  ) => {
    if (!userId || !thread || thread.user_id !== userId) return;

    try {
      const { data: updatedThread, error } = await updateFeedbackThread(
        userId,
        thread.id,
        { status: newStatus }
      );


--- ./src/hooks/feedback/useFeedbackThreads.ts ---
    }
    if (status !== 'all') {
      filters.status = status;
    }

    const { data } = await getFeedbackThreads(filters);
    if (data) {
      setThreads(data);
    }

    setLoading(false);

    setLoading(false);
  };

  const refresh = async () => {
    await loadThreads();
  };

  useEffect(() => {
    loadThreads();
  }, [category, status]);

--- ./src/hooks/social/useFollowStatus.ts ---

  const checkFollowStatus = async () => {
    if (!currentUserId || !targetUserId) return;

    try {
      const result = await isFollowing(currentUserId, targetUserId);
      setFollowState(result);
    } catch (error) {
      console.error('Error checking follow status:', error);
    }
  };
  const follow = async () => {
    if (!currentUserId || !targetUserId) return;

    setLoading(true);
    try {
      const { error } = await followUser(currentUserId, targetUserId);
      if (!error) {
        setFollowState({ isFollowing: true, status: 'requested' });
        // Re-check to get actual status
        await checkFollowStatus();
      }
    try {
      const { error } = await followUser(currentUserId, targetUserId);
      if (!error) {
        setFollowState({ isFollowing: true, status: 'requested' });
        // Re-check to get actual status
        await checkFollowStatus();
      }
    } catch (error) {
      console.error('Error following user:', error);
    } finally {
      setLoading(false);
  const unfollow = async () => {
    if (!currentUserId || !targetUserId) return;

    setLoading(true);
    try {
      const { error } = await unfollowUser(currentUserId, targetUserId);
      if (!error) {
        setFollowState({ isFollowing: false, status: null });
      }
    } catch (error) {
      console.error('Error unfollowing user:', error);
      setLoading(false);
    }
  };

  const refresh = async () => {
    await checkFollowStatus();
  };

  useEffect(() => {
    checkFollowStatus();
  }, [currentUserId, targetUserId]);

--- ./src/hooks/social/useSocialModals.ts ---

  const openComments = useCallback(async (item: FeedItem) => {
    setSelectedItem(item);
    const post = item.type === 'post' ? item.post! : item.repost!.original_post!;
    if (post) {
      const { data: commentsData } = await getComments('post', post.id);
      if (commentsData) {
        setComments(commentsData);
      }
    }
    setShowComments(true);
          'Are you sure you want to delete this post? This action cannot be undone.'
        );

        if (!confirmed) return;

        const { error } = await deletePost(postId, user.id);

        if (error) {
          alert(`Failed to delete post: ${error.message || error}`);
        } else {
          alert('Post deleted successfully');

        if (error) {
          alert(`Failed to delete post: ${error.message || error}`);
        } else {
          alert('Post deleted successfully');
          await refreshFeed();
        }
        return;
      }

      Alert.alert(
          { text: 'Cancel', style: 'cancel' },
          {
            text: 'Delete',
            style: 'destructive',
            onPress: async () => {
              const { error } = await deletePost(postId, user.id);

              if (error) {
                Alert.alert('Error', `Failed to delete post: ${error.message || error}`);
              } else {
                Alert.alert('Success', 'Post deleted successfully');

              if (error) {
                Alert.alert('Error', `Failed to delete post: ${error.message || error}`);
              } else {
                Alert.alert('Success', 'Post deleted successfully');
                await refreshFeed();
              }
            },
          },
        ]
      );
      setUnfollowingUserId(userId);
      setOpenMenuPostId(null);
      setMenuButtonPosition(null);

      try {
        const { error } = await unfollowUser(user.id, userId);
        if (error) {
          Alert.alert('Error', error.message || 'Failed to unfollow user');
        } else {
          setFollowStatuses((prev) => {
            const updated = new Map(prev);

--- ./src/hooks/social/useUserProfile.ts ---
  if (coverImageIds.length === 0) {
    outfits.forEach(o => imageMap.set(o.id, null));
    return imageMap;
  }

  const { data: coverImages } = await supabase
    .from('images')
    .select('id, storage_bucket, storage_key')
    .in('id', coverImageIds);

  const coverImageLookup = new Map(
      // Load profile and content in parallel
      const [
        { data: profileData },
        { data: outfitsData },
        { data: lookbooksData },
      ] = await Promise.all([
        getFullUserProfile(userId),
        getUserOutfits(userId),
        getUserLookbooks(userId),
      ]);

      setLookbooks(lookbooksData || []);

      //  OPTIMIZATION: Batch load wear counts and lookbook data
      const outfitIds = (outfitsData || []).map(outfit => outfit.id);

      const [wearCountsData, lookbookOutfitsData] = await Promise.all([
        // Get wear counts in ONE query
        outfitIds.length > 0
          ? supabase
              .from('calendar_entries')
              .select('outfit_id, calendar_day:calendar_day_id(owner_user_id)')
        setOutfitWearCounts(wearCounts);
      }

      //  OPTIMIZATION: Batch get outfit images
      if (outfitsData && outfitsData.length > 0) {
        const outfitImageCache = await batchGetOutfitCoverImages(outfitsData);
        setOutfitImages(outfitImageCache);
      }

      //  OPTIMIZATION: Process lookbook images
      if (lookbooksData && lookbooksData.length > 0 && outfitsData) {
        // Get images for first outfits
        const firstOutfits = Array.from(firstOutfitsByLookbook.values())
          .map(outfitId => outfitsData.find(o => o.id === outfitId))
          .filter(Boolean);

        const firstOutfitImages = await batchGetOutfitCoverImages(firstOutfits);

        // Map back to lookbooks
        lookbooksData.forEach(lookbook => {
          const firstOutfitId = firstOutfitsByLookbook.get(lookbook.id);
          if (firstOutfitId) {
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadProfile();
  };

  useEffect(() => {
    loadProfile();
  }, [userId]);

--- ./src/hooks/social/useEngagementActions.ts ---
    if (!userId) return;

    const currentlyLiked = engagementCounts[postId]?.hasLiked || false;

    if (currentlyLiked) {
      await unlikeEntity(userId, 'post', postId);
    } else {
      await likeEntity(userId, 'post', postId);
    }

    // Refresh counts
    const currentlyLiked = engagementCounts[postId]?.hasLiked || false;

    if (currentlyLiked) {
      await unlikeEntity(userId, 'post', postId);
    } else {
      await likeEntity(userId, 'post', postId);
    }

    // Refresh counts
    const [likes, liked] = await Promise.all([
      getLikeCount('post', postId),
    } else {
      await likeEntity(userId, 'post', postId);
    }

    // Refresh counts
    const [likes, liked] = await Promise.all([
      getLikeCount('post', postId),
      hasLiked(userId, 'post', postId),
    ]);

    setEngagementCounts((prev) => ({
    if (!userId) return;

    const currentlySaved = engagementCounts[postId]?.hasSaved || false;

    if (currentlySaved) {
      await unsaveEntity(userId, 'post', postId);
    } else {
      await saveEntity(userId, 'post', postId);
    }

    // Refresh counts
    const currentlySaved = engagementCounts[postId]?.hasSaved || false;

    if (currentlySaved) {
      await unsaveEntity(userId, 'post', postId);
    } else {
      await saveEntity(userId, 'post', postId);
    }

    // Refresh counts
    const [saves, saved] = await Promise.all([
      getSaveCount('post', postId),
    } else {
      await saveEntity(userId, 'post', postId);
    }

    // Refresh counts
    const [saves, saved] = await Promise.all([
      getSaveCount('post', postId),
      hasSaved(userId, 'post', postId),
    ]);

    setEngagementCounts((prev) => ({
    if (!userId) return;

    const currentlyReposted = engagementCounts[postId]?.hasReposted || false;

    if (currentlyReposted) {
      await removeRepost(userId, postId);
    } else {
      await createRepost(userId, postId);
    }

    // Refresh counts
    const currentlyReposted = engagementCounts[postId]?.hasReposted || false;

    if (currentlyReposted) {
      await removeRepost(userId, postId);
    } else {
      await createRepost(userId, postId);
    }

    // Refresh counts
    const [reposts, reposted] = await Promise.all([
      getRepostCount(postId),
    } else {
      await createRepost(userId, postId);
    }

    // Refresh counts
    const [reposts, reposted] = await Promise.all([
      getRepostCount(postId),
      hasReposted(userId, postId),
    ]);

    setEngagementCounts((prev) => ({
      },
    }));

    // Refresh feed to show new repost
    if (onRefresh) {
      await onRefresh();
    }
  };

  const updateCommentCount = (postId: string, count: number) => {
    setEngagementCounts((prev) => ({

--- ./src/hooks/social/useTryOnOutfit.ts ---
    }

    setTryingOnOutfit(true);

    try {
      const { data: userSettings } = await supabase
        .from('user_settings')
        .select('body_shot_image_id, headshot_image_id, ai_model_preference')
        .eq('user_id', userId)
        .single();

        Alert.alert('Setup Required', 'Please upload a body photo and generate a headshot before trying on outfits.');
        setTryingOnOutfit(false);
        return;
      }

      const { data: outfitData } = await getOutfit(outfitId);
      if (!outfitData?.outfit || !outfitData.items || outfitData.items.length === 0) {
        throw new Error('Outfit not found or has no items');
      }

      const { data: categories } = await getWardrobeCategories();
      const { data: outfitData } = await getOutfit(outfitId);
      if (!outfitData?.outfit || !outfitData.items || outfitData.items.length === 0) {
        throw new Error('Outfit not found or has no items');
      }

      const { data: categories } = await getWardrobeCategories();
      const categoriesMap = new Map(categories?.map(cat => [cat.id, cat.name]) || []);

      const outfitItems = outfitData.items.map((item, index) => ({
        category_id: item.category_id,
        wardrobe_item_id: item.wardrobe_item_id,
        wardrobe_item_id: item.wardrobe_item_id,
        position: item.position ?? index,
      }));

      const originalOutfitTitle = outfitData.outfit.title || 'Outfit';
      const { data: savedOutfit, error: saveError } = await saveOutfit(
        userId,
        {
          title: `Try on: ${originalOutfitTitle}`,
          visibility: 'private',
        },
      }

      const newOutfitId = savedOutfit.outfit.id;

      const wardrobeItemIds = outfitData.items.map(item => item.wardrobe_item_id);
      const { data: wardrobeItems, error: wardrobeError } = await getWardrobeItemsByIds(wardrobeItemIds);
      
      if (wardrobeError) {
        await supabase
          .from('outfits')
          .update({ archived_at: new Date().toISOString() })

      const wardrobeItemIds = outfitData.items.map(item => item.wardrobe_item_id);
      const { data: wardrobeItems, error: wardrobeError } = await getWardrobeItemsByIds(wardrobeItemIds);
      
      if (wardrobeError) {
        await supabase
          .from('outfits')
          .update({ archived_at: new Date().toISOString() })
          .eq('id', newOutfitId);
        console.error('[Social] Error fetching wardrobe items:', wardrobeError);
        throw new Error('Failed to access outfit items. Please try again.');
        console.error('[Social] Error fetching wardrobe items:', wardrobeError);
        throw new Error('Failed to access outfit items. Please try again.');
      }
      
      if (!wardrobeItems || wardrobeItems.length === 0) {
        await supabase
          .from('outfits')
          .update({ archived_at: new Date().toISOString() })
          .eq('id', newOutfitId);
        throw new Error('Could not access outfit items. The outfit may contain items from users you don\'t follow.');
      }
      const modelPreference = userSettings?.ai_model_preference || 'gemini-2.5-flash-image';
      const renderLimit = getOutfitRenderItemLimit(modelPreference);
      let mannequinImageId: string | undefined;

      if (selected.length > renderLimit) {
        const { data: mannequinJob, error: mannequinError } = await createAIJob(userId, 'outfit_mannequin', {
          user_id: userId,
          outfit_id: newOutfitId,
          selected,
        });


        if (mannequinError || !mannequinJob) {
          throw new Error('Failed to start mannequin generation');
        }

        await triggerAIJobExecution(mannequinJob.id);
        const { data: mannequinResult, error: mannequinPollError } = await pollAIJobWithFinalCheck(
          mannequinJob.id,
          60,
          2000,
          '[Social] Mannequin'
        if (mannequinError || !mannequinJob) {
          throw new Error('Failed to start mannequin generation');
        }

        await triggerAIJobExecution(mannequinJob.id);
        const { data: mannequinResult, error: mannequinPollError } = await pollAIJobWithFinalCheck(
          mannequinJob.id,
          60,
          2000,
          '[Social] Mannequin'
        );
        }

        mannequinImageId = mannequinResult.result.mannequin_image_id;
      }

      const { data: renderJob, error: jobError } = await createAIJob(userId, 'outfit_render', {
        user_id: userId,
        outfit_id: newOutfitId,
        selected,
        mannequin_image_id: mannequinImageId,
      });

      if (jobError || !renderJob) {
        throw new Error('Failed to start render job');
      }

      const triggerResult = await triggerAIJobExecution(renderJob.id);
      if (triggerResult.error) {
        console.error('[Social] Job trigger returned error:', triggerResult.error);
        if (triggerResult.error.message?.includes('URL') || triggerResult.error.message?.includes('configuration')) {
          await supabase
            .from('outfits')

      const triggerResult = await triggerAIJobExecution(renderJob.id);
      if (triggerResult.error) {
        console.error('[Social] Job trigger returned error:', triggerResult.error);
        if (triggerResult.error.message?.includes('URL') || triggerResult.error.message?.includes('configuration')) {
          await supabase
            .from('outfits')
            .update({ archived_at: new Date().toISOString() })
            .eq('id', newOutfitId);
          throw new Error('Failed to start outfit generation. Please check your network connection and try again.');
        }
      }

      setGeneratingOutfitId(newOutfitId);
      
      try {
        const { data: finalJob, error: pollError } = await pollAIJobWithFinalCheck(
          renderJob.id,
          120,
          2000,
          '[Social]'
        );
          );
          return;
        }
        
        if (finalJob.status === 'succeeded') {
          const { data: outfitData } = await getOutfit(newOutfitId);
          setGeneratingOutfitId(null);
          router.push(`/outfits/${newOutfitId}/view`);
        } else if (finalJob.status === 'failed') {
          setGeneratingOutfitId(null);
          Alert.alert('Generation Failed', finalJob.error || 'Outfit generation failed');

--- ./src/hooks/social/useSocialEngagement.ts ---

    try {
      const currentlyLiked = engagementCounts[postId]?.hasLiked || false;

      if (currentlyLiked) {
        await unlikeEntity(userId, 'post', postId);
      } else {
        await likeEntity(userId, 'post', postId);
      }

      // Refresh counts
      const currentlyLiked = engagementCounts[postId]?.hasLiked || false;

      if (currentlyLiked) {
        await unlikeEntity(userId, 'post', postId);
      } else {
        await likeEntity(userId, 'post', postId);
      }

      // Refresh counts
      const [likes, liked] = await Promise.all([
        getLikeCount('post', postId),
      } else {
        await likeEntity(userId, 'post', postId);
      }

      // Refresh counts
      const [likes, liked] = await Promise.all([
        getLikeCount('post', postId),
        hasLiked(userId, 'post', postId),
      ]);

      setEngagementCounts((prev) => ({

    try {
      const currentlySaved = engagementCounts[postId]?.hasSaved || false;

      if (currentlySaved) {
        await unsaveEntity(userId, 'post', postId);
      } else {
        await saveEntity(userId, 'post', postId);
      }

      // Refresh counts
      const currentlySaved = engagementCounts[postId]?.hasSaved || false;

      if (currentlySaved) {
        await unsaveEntity(userId, 'post', postId);
      } else {
        await saveEntity(userId, 'post', postId);
      }

      // Refresh counts
      const [saves, saved] = await Promise.all([
        getSaveCount('post', postId),
      } else {
        await saveEntity(userId, 'post', postId);
      }

      // Refresh counts
      const [saves, saved] = await Promise.all([
        getSaveCount('post', postId),
        hasSaved(userId, 'post', postId),
      ]);

      setEngagementCounts((prev) => ({

    try {
      const currentlyReposted = engagementCounts[postId]?.hasReposted || false;

      if (currentlyReposted) {
        await removeRepost(userId, postId);
      } else {
        await createRepost(userId, postId);
      }

      // Refresh counts
      const currentlyReposted = engagementCounts[postId]?.hasReposted || false;

      if (currentlyReposted) {
        await removeRepost(userId, postId);
      } else {
        await createRepost(userId, postId);
      }

      // Refresh counts
      const [reposts, reposted] = await Promise.all([
        getRepostCount(postId),
      } else {
        await createRepost(userId, postId);
      }

      // Refresh counts
      const [reposts, reposted] = await Promise.all([
        getRepostCount(postId),
        hasReposted(userId, postId),
      ]);

      setEngagementCounts((prev) => ({
        },
      }));

      // Callback to refresh feed if provided
      if (onRepost) {
        await onRepost();
      }
    } catch (error) {
      console.error('Error reposting:', error);
    } finally {
      setReposting((prev) => {

--- ./src/hooks/social/useFeed.ts ---
  if (coverImageIds.length === 0) {
    outfits.forEach(o => imageMap.set(o.id, null));
    return imageMap;
  }

  const { data: coverImages } = await supabase
    .from('images')
    .select('id, storage_bucket, storage_key')
    .in('id', coverImageIds);

  const coverImageLookup = new Map(
    { data: likesData },
    { data: savesData },
    { data: commentsData },
    { data: userLikes },
    { data: userSaves },
  ] = await Promise.all([
    // Get all likes grouped by post
    supabase
      .from('likes')
      .select('entity_id')
      .eq('entity_type', 'post')
    }

    setLoading(true);

    try {
      const { data: feedItems } = await getFeed(userId, limit, 0);
      if (!feedItems) {
        setLoading(false);
        return;
      }

      const [
        engagementData,
        repostData,
        userRepostData,
        followData,
      ] = await Promise.all([
        // Batch get engagement counts (1 query instead of 5*N queries!)
        batchGetEngagementCounts(postIds, userId),
        
        // Get all repost counts
        Promise.all(postIds.map(async (postId) => ({
        batchGetEngagementCounts(postIds, userId),
        
        // Get all repost counts
        Promise.all(postIds.map(async (postId) => ({
          postId,
          count: await getRepostCount(postId),
        }))),
        
        // Get user's reposts
        Promise.all(postIds.map(async (postId) => ({
          postId,
        }))),
        
        // Get user's reposts
        Promise.all(postIds.map(async (postId) => ({
          postId,
          hasReposted: await hasReposted(userId, postId),
        }))),
        
        // Get follow statuses
        Promise.all(
          Array.from(ownerIds).map(async (ownerId) => ({
        
        // Get follow statuses
        Promise.all(
          Array.from(ownerIds).map(async (ownerId) => ({
            ownerId,
            following: (await isFollowing(userId, ownerId)).isFollowing,
          }))
        ),
      ]);

      // Combine engagement data with reposts
          const post = item.type === 'post' ? item.post : item.repost?.original_post;
          return post?.entity_type === 'outfit' && item.entity?.outfit;
        });

      const outfits = outfitItems.map(item => item.entity!.outfit);
      const outfitImageCache = await batchGetOutfitCoverImages(outfits);
      setOutfitImages(outfitImageCache);

      // Handle lookbooks (this is already relatively optimized)
      const lookbookImageCache = new Map<string, any>();
      const lookbookItems = filteredFeed.filter(item => {
      const lookbookItems = filteredFeed.filter(item => {
        const post = item.type === 'post' ? item.post : item.repost?.original_post;
        return post?.entity_type === 'lookbook' && item.entity?.lookbook;
      });

      await Promise.all(
        lookbookItems.map(async (item) => {
          const lookbookId = item.entity!.lookbook.id;
          const { data } = await getLookbook(lookbookId);
          
          if (data && data.outfits.length > 0) {
      });

      await Promise.all(
        lookbookItems.map(async (item) => {
          const lookbookId = item.entity!.lookbook.id;
          const { data } = await getLookbook(lookbookId);
          
          if (data && data.outfits.length > 0) {
            const lookbookOwnerId = data.lookbook.owner_user_id;
            const { data: allOutfits } = await getUserOutfits(lookbookOwnerId);

          const lookbookId = item.entity!.lookbook.id;
          const { data } = await getLookbook(lookbookId);
          
          if (data && data.outfits.length > 0) {
            const lookbookOwnerId = data.lookbook.owner_user_id;
            const { data: allOutfits } = await getUserOutfits(lookbookOwnerId);

            if (allOutfits) {
              const lookbookOutfits = data.outfits
                .map((lo: any) => allOutfits.find((o: any) => o.id === lo.outfit_id))
                .filter(Boolean);
                .map((lo: any) => allOutfits.find((o: any) => o.id === lo.outfit_id))
                .filter(Boolean);

              lookbookImageCache.set(`${lookbookId}_outfits`, lookbookOutfits);

              const imageUrls = await batchGetOutfitCoverImages(lookbookOutfits);
              
              if (lookbookOutfits.length > 0) {
                const firstUrl = imageUrls.get(lookbookOutfits[0].id);
                lookbookImageCache.set(lookbookId, firstUrl);
              }
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadFeed();
  };

  useEffect(() => {
    loadFeed();
  }, [userId, filterByUserId, limit]);

--- ./src/hooks/social/useFeedSlideshow.ts ---
    if (!userId) return;

    setSlideshowLoading(true);
    
    try {
      const { data } = await getLookbook(lookbookId);
      let outfitsToShow: any[] = [];
      
      if (data && data.outfits.length > 0) {
        // Get outfits from the lookbook owner (not current user!)
        const lookbookOwnerId = data.lookbook.owner_user_id;
      let outfitsToShow: any[] = [];
      
      if (data && data.outfits.length > 0) {
        // Get outfits from the lookbook owner (not current user!)
        const lookbookOwnerId = data.lookbook.owner_user_id;
        const { data: allOutfits } = await getUserOutfits(lookbookOwnerId);
        
        // DEBUG: Show what we got
        Alert.alert('Debug Info', 
          `Lookbook has ${data.outfits.length} outfit refs\n` +
          `Owner: ${lookbookOwnerId}\n` +

      if (outfitsToShow.length > 0) {
        // Pre-load all images BEFORE opening slideshow
        const imageMap = new Map<string, string | null>();
        const loadPromises = outfitsToShow.map(async (outfit) => {
          const url = await getOutfitCoverImageUrl(outfit);
          imageMap.set(outfit.id, url);
        });
        await Promise.all(loadPromises);
        
        // Now open the slideshow with images ready
        const imageMap = new Map<string, string | null>();
        const loadPromises = outfitsToShow.map(async (outfit) => {
          const url = await getOutfitCoverImageUrl(outfit);
          imageMap.set(outfit.id, url);
        });
        await Promise.all(loadPromises);
        
        // Now open the slideshow with images ready
        setSlideshowImages(imageMap);
        setSlideshowOutfits(outfitsToShow);
        setCurrentSlideIndex(0);

--- ./src/hooks/outfits/useOutfits.ts ---

  const loadOutfits = useCallback(async () => {
    if (!userId) return;

    try {
      const { data, error } = await getUserOutfitsWithOptions(userId, {
        search: searchQuery || undefined,
        favorites: favoritesOnly || undefined,
        sortBy,
        sortOrder,
      });
      setOutfits(data || []);

      // Load images in parallel
      const imageMap = new Map<string, string | null>();
      const loadPromises = (data || []).map(async (outfit) => {
        const url = await getOutfitCoverImageUrl(outfit);
        imageMap.set(outfit.id, url);
      });
      await Promise.all(loadPromises);
      setImageCache(imageMap);
    } catch (error) {
      const imageMap = new Map<string, string | null>();
      const loadPromises = (data || []).map(async (outfit) => {
        const url = await getOutfitCoverImageUrl(outfit);
        imageMap.set(outfit.id, url);
      });
      await Promise.all(loadPromises);
      setImageCache(imageMap);
    } catch (error) {
      console.error('Error loading outfits:', error);
    }
  }, [userId, searchQuery, favoritesOnly, sortBy, sortOrder]);
    }
  }, [userId, searchQuery, favoritesOnly, sortBy, sortOrder]);

  const refresh = useCallback(async () => {
    setRefreshing(true);
    await loadOutfits();
    setRefreshing(false);
  }, [loadOutfits]);

  useEffect(() => {
    if (userId) {

--- ./src/hooks/outfits/useOutfitViewActions.ts ---

    try {
      const idsArray = outfitIds.split(',').filter(Boolean);
      if (idsArray.length === 0) return;

      const { data: outfitsData } = await supabase
        .from('outfits')
        .select('*')
        .in('id', idsArray)
        .eq('owner_user_id', user.id)
        .is('archived_at', null);

      if (outfitsData) {
        const outfitMap = new Map(
          outfitsData.map((outfit) => [outfit.id, outfit])
        );
        const navItems = await Promise.all(
          idsArray.map(async (outfitId) => {
            const foundOutfit = outfitMap.get(outfitId);
            if (!foundOutfit) return null;
            const imageUrl = await getOutfitCoverImageUrl(foundOutfit);
            return {
        );
        const navItems = await Promise.all(
          idsArray.map(async (outfitId) => {
            const foundOutfit = outfitMap.get(outfitId);
            if (!foundOutfit) return null;
            const imageUrl = await getOutfitCoverImageUrl(foundOutfit);
            return {
              id: outfitId,
              title: foundOutfit.title || 'Untitled Outfit',
              imageUrl,
            };
  const confirmDelete = useCallback(async () => {
    if (!user || !outfit) return;

    setDeleting(true);
    try {
      await deleteOutfit();
      setShowDeleteConfirm(false);
      setDeleting(false);
      
      // Use replace instead of back to avoid navigation timing issues
      if (returnTo === 'outfits' || outfitIds) {
  const toggleFavorite = useCallback(async () => {
    if (!outfitId || !user || !outfit) return;

    try {
      const newFavoriteStatus = !outfit.is_favorite;
      const { error } = await supabase
        .from('outfits')
        .update({ is_favorite: newFavoriteStatus })
        .eq('id', outfitId)
        .eq('owner_user_id', user.id);

  }, [outfitId, user, outfit]);

  const handleCommentPress = useCallback(
    async (comments: any[], loadComments: () => Promise<void>) => {
      if (!showComments && comments.length === 0) {
        await loadComments();
      }
      setShowComments(!showComments);
    },
    [showComments]
  );

--- ./src/hooks/outfits/useOutfitGeneration.ts ---
  const startDescriptionPolling = useCallback((outfitId: string) => {
    console.log('[OutfitGeneration] Starting description polling...');

    descriptionPollingInterval.current = setInterval(async () => {
      try {
        const { data: outfitData } = await supabase
          .from('outfits')
          .select('description, occasions, style_tags, season, description_generated_at')
          .eq('id', outfitId)
          .single();

          category_id: item.category_id || null,
          wardrobe_item_id: item.id,
          position: index,
        }));

        const { data: savedData, error: saveError } = await saveOutfit(
          userId,
          {
            title: 'Generated Outfit',
            notes: 'AI-generated outfit',
          },
          phase: 'preparing',
          message: 'Preparing generation...',
          progress: 20,
        });

        const { data: userSettings } = await getUserSettings(userId);
        if (!userSettings?.body_shot_image_id) {
          throw new Error('Please upload a body photo in settings before generating outfits');
        }

        // NEW: Start item reveal animation

        const selectionKey = selectedItems.map((item) => item.id).join(',');
        let stackedResult: { imageId: string; publicUrl: string; storagePath: string } | null = null;

        if (backgroundGrid) {
          const storedKey = await backgroundGrid.getStoredKeyOrAwaitPending(selectionKey);
          if (storedKey) {
            stackedResult = {
              imageId: storedKey,
              publicUrl: supabase.storage.from('media').getPublicUrl(storedKey).data.publicUrl,
              storagePath: storedKey,
        if (!stackedResult) {
          console.log(`[OutfitGeneration] Fetching images for ${selectedItems.length} items`);

          // Get image links for all selected items
          const wardrobeItemIds = selectedItems.map(item => item.id);
          const { data: imageLinks, error: linksError } = await supabase
            .from('wardrobe_item_images')
            .select(`
              image_id,
              wardrobe_item_id,
              type,
            progress: 50,
          });

          console.log(`[OutfitGeneration] Starting grid generation...`);

          const gridBase64 = await generateClothingGrid(imageUrls);
          console.log(`[OutfitGeneration] Grid generated successfully, base64 length: ${gridBase64.length}`);

          // Convert base64 to Blob and upload to storage
          setProgress({
            phase: 'stacking',
            message: `Uploading grid image...`,
            progress: 60,
          });

          // Verify user session
          const { data: { session }, error: sessionError } = await supabase.auth.getSession();
          if (sessionError || !session?.user?.id || session.user.id !== userId) {
            throw new Error('User not authenticated or session mismatch');
          }

          // Convert base64 to Blob
          // Upload to Supabase storage
          const timestamp = Date.now();
          const fileName = `grid-${timestamp}.jpg`;
          const storagePath = `${userId}/ai/stacked/${fileName}`;

          const arrayBuffer = await gridBlob.arrayBuffer();
          const uploadData = new Uint8Array(arrayBuffer);

          const { data: uploadDataResult, error: uploadError } = await supabase.storage
            .from('media')
            .upload(storagePath, uploadData, {
          const storagePath = `${userId}/ai/stacked/${fileName}`;

          const arrayBuffer = await gridBlob.arrayBuffer();
          const uploadData = new Uint8Array(arrayBuffer);

          const { data: uploadDataResult, error: uploadError } = await supabase.storage
            .from('media')
            .upload(storagePath, uploadData, {
              cacheControl: '3600',
              upsert: false,
              contentType: 'image/jpeg',
          progress: 80,
        });

        console.log(`[OutfitGeneration] Creating AI job with stacked image ID: ${stackedResult.imageId}`);

        const { data: jobData, error: jobError } = await createAndTriggerJob(
          userId,
          'outfit_render',
          {
            user_id: userId,
            outfit_id: outfitId,

        console.log(`[OutfitGeneration] Creating AI job with stacked image ID: ${stackedResult.imageId}`);

        const { data: jobData, error: jobError } = await createAndTriggerJob(
          userId,
          'outfit_render',
          {
            user_id: userId,
            outfit_id: outfitId,
            selected: selectedForJob,
            stacked_image_id: stackedResult.imageId,
          phase: 'generating',
          message: 'AI is working on your outfit...',
          progress: 90,
        });

        const { data: completedJob, error: pollError } = await pollAIJobWithFinalCheck(
          jobData.jobId,
          60,
          2000,
          '[OutfitGeneration]'
        );

--- ./src/hooks/outfits/useBackgroundGridGenerator.ts ---
  preUploadedGridKey: string | null;
  /** Selection key for which preUploadedGridKey was produced */
  selectionKeyForStored: string | null;
  /** True while background upload is in progress */
  isUploading: boolean;
  /** For submit: use stored key if it matches current selection, else await pending upload and return key if match, else null */
  getStoredKeyOrAwaitPending: (currentSelectionKey: string) => Promise<string | null>;
}

export function useBackgroundGridGenerator(
  selectedItems: WardrobeItem[],

      const currentSelectionKey = selectionKey(items);

      try {
        const wardrobeItemIds = items.map((item) => item.id);
        const { data: imageLinks, error: linksError } = await supabase
          .from('wardrobe_item_images')
          .select(
            `
            image_id,
            wardrobe_item_id,
          return urlData?.publicUrl ?? '';
        }).filter(Boolean);

        if (imageUrls.length === 0) return null;

        const gridBase64 = await generateClothingGrid(imageUrls);

        const byteCharacters = atob(gridBase64);
        const byteNumbers = new Array(byteCharacters.length);
        for (let i = 0; i < byteCharacters.length; i++) {
          byteNumbers[i] = byteCharacters.charCodeAt(i);

        const timestamp = Date.now();
        const fileName = `${STORAGE_PREFIX}-${timestamp}.jpg`;
        const storagePath = `${userId}/ai/stacked/${fileName}`;

        const arrayBuffer = await gridBlob.arrayBuffer();
        const uploadData = new Uint8Array(arrayBuffer);

        const { data: uploadDataResult, error: uploadError } = await supabase.storage
          .from('media')
          .upload(storagePath, uploadData, {
        const storagePath = `${userId}/ai/stacked/${fileName}`;

        const arrayBuffer = await gridBlob.arrayBuffer();
        const uploadData = new Uint8Array(arrayBuffer);

        const { data: uploadDataResult, error: uploadError } = await supabase.storage
          .from('media')
          .upload(storagePath, uploadData, {
            cacheControl: '3600',
            upsert: false,
            contentType: 'image/jpeg',
      if (preUploadedGridKey && selectionKeyForStored === currentSelectionKey) {
        return preUploadedGridKey;
      }
      const pending = pendingUploadPromiseRef.current;
      if (pending) {
        const result = await pending;
        return result?.selectionKey === currentSelectionKey ? result.key : null;
      }
      return null;
    },
    [preUploadedGridKey, selectionKeyForStored]

--- ./src/hooks/outfits/useOutfitEditorActions.ts ---
    async (categoryId: string) => {
      if (!user) return;

      setSelectedCategory(categoryId);

      const { getDefaultWardrobeId } = await import('@/lib/wardrobe');
      const { data: defaultWardrobeId } = await getDefaultWardrobeId(user.id);
      if (!defaultWardrobeId) return;

      const { data: ownedItems } = await getWardrobeItems(defaultWardrobeId, {
        category_id: categoryId,
      if (!user) return;

      setSelectedCategory(categoryId);

      const { getDefaultWardrobeId } = await import('@/lib/wardrobe');
      const { data: defaultWardrobeId } = await getDefaultWardrobeId(user.id);
      if (!defaultWardrobeId) return;

      const { data: ownedItems } = await getWardrobeItems(defaultWardrobeId, {
        category_id: categoryId,
      });

      const { getDefaultWardrobeId } = await import('@/lib/wardrobe');
      const { data: defaultWardrobeId } = await getDefaultWardrobeId(user.id);
      if (!defaultWardrobeId) return;

      const { data: ownedItems } = await getWardrobeItems(defaultWardrobeId, {
        category_id: categoryId,
      });

      const { data: savedItems } = await getSavedWardrobeItems(user.id, {
        category_id: categoryId,

      const { data: ownedItems } = await getWardrobeItems(defaultWardrobeId, {
        category_id: categoryId,
      });

      const { data: savedItems } = await getSavedWardrobeItems(user.id, {
        category_id: categoryId,
      });

      const items = [...(ownedItems || []), ...(savedItems || [])];
      setCategoryItems(items);
      const items = [...(ownedItems || []), ...(savedItems || [])];
      setCategoryItems(items);

      if (items && items.length > 0) {
        const imagePromises = items.map(async (item) => {
          const url = await getItemImageUrl(item.id);
          return { itemId: item.id, url };
        });
        const imageResults = await Promise.all(imagePromises);
        // Note: itemImageUrls is managed by useOutfitEditor, so we don't update it here
        // The hook should handle image URL caching
      if (items && items.length > 0) {
        const imagePromises = items.map(async (item) => {
          const url = await getItemImageUrl(item.id);
          return { itemId: item.id, url };
        });
        const imageResults = await Promise.all(imagePromises);
        // Note: itemImageUrls is managed by useOutfitEditor, so we don't update it here
        // The hook should handle image URL caching
      }

      setShowItemPicker(true);
  const handleSave = useCallback(async () => {
    if (!user) return;

    setSaving(true);
    try {
      const savedOutfitId = await saveOutfit();
      if (savedOutfitId) {
        if (isNew) {
          Alert.alert(
            'Success',
            'Outfit saved! You can now generate the outfit image.',
    setRevealedItemsCount(0);
    setCompletedItemsCount(0);

    try {
      // Save outfit first
      const savedOutfitId = await saveOutfit();
      if (!savedOutfitId) {
        Alert.alert('Error', 'Failed to save outfit before rendering');
        setRendering(false);
        return;
      }
          if (!url) throw new Error(`No image URL for item ${item.id}`);
          return url;
        });

        console.log(`[OutfitEditor] Generating grid for ${imageUrls.length} items...`);
        const gridBase64 = await generateClothingGrid(imageUrls);
        console.log(`[OutfitEditor] Grid generated successfully, base64 length: ${gridBase64.length}`);

        // Convert base64 to Blob and upload to storage
        const byteCharacters = atob(gridBase64);
        const byteNumbers = new Array(byteCharacters.length);
        // Upload to Supabase storage
        const timestamp = Date.now();
        const fileName = `grid-${timestamp}.jpg`;
        const storagePath = `${user.id}/ai/stacked/${fileName}`;

        const arrayBuffer = await gridBlob.arrayBuffer();
        const uploadData = new Uint8Array(arrayBuffer);

        const { data: uploadDataResult, error: uploadError } = await supabase.storage
          .from('media')
          .upload(storagePath, uploadData, {
        const storagePath = `${user.id}/ai/stacked/${fileName}`;

        const arrayBuffer = await gridBlob.arrayBuffer();
        const uploadData = new Uint8Array(arrayBuffer);

        const { data: uploadDataResult, error: uploadError } = await supabase.storage
          .from('media')
          .upload(storagePath, uploadData, {
            cacheControl: '3600',
            upsert: false,
            contentType: 'image/jpeg',
            },
          };
        }
      );

      const { data: userSettings } = await getUserSettings(user.id);
      if (!userSettings?.body_shot_image_id) {
        Alert.alert(
          'Setup Required',
          'Please upload a body photo before generating outfits.'
        );

      const modelPreference =
        userSettings?.ai_model_preference || 'gemini-2.5-flash-image';

      // Create render job
      const { data: renderJob, error } = await createAIJob(
        user.id,
        'outfit_render',
        {
          user_id: user.id,
          outfit_id: savedOutfitId,
        userSettings?.ai_model_preference || 'gemini-2.5-flash-image';

      // Create render job
      const { data: renderJob, error } = await createAIJob(
        user.id,
        'outfit_render',
        {
          user_id: user.id,
          outfit_id: savedOutfitId,
          stacked_image_id: stackedImageId,
          selected,
        Alert.alert('Error', 'Failed to start render job');
        setRendering(false);
        return;
      }

      await triggerAIJobExecution(renderJob.id);
      setRendering(false);
      router.push(
        `/outfits/${savedOutfitId}/view?renderJobId=${renderJob.id}`
      );
    } catch (error: any) {
        text: 'Delete',
        style: 'destructive',
        onPress: async () => {
          setSaving(true);
          try {
            const { supabase } = await import('@/lib/supabase');
            const { error } = await supabase
              .from('outfits')
              .update({ archived_at: new Date().toISOString() })
              .eq('id', outfit.id)
              .eq('owner_user_id', user.id);
        style: 'destructive',
        onPress: async () => {
          setSaving(true);
          try {
            const { supabase } = await import('@/lib/supabase');
            const { error } = await supabase
              .from('outfits')
              .update({ archived_at: new Date().toISOString() })
              .eq('id', outfit.id)
              .eq('owner_user_id', user.id);


--- ./src/hooks/outfits/useOutfitView.ts ---
  const [isGenerating, setIsGenerating] = useState(false);
  const [renderJobId, setRenderJobId] = useState<string | null>(null);

  const startPollingForOutfitRender = async (jobId: string) => {
    try {
      const { data: finalJob } = await pollAIJobWithFinalCheck(
        jobId,
        120,
        2000,
        '[OutfitView]'
      );
        setIsGenerating(false);
        // Instant render: use base64 from job result to avoid a second fetch
        if (finalJob.result?.base64_result) {
          setCoverImageDataUri('data:image/jpeg;base64,' + finalJob.result.base64_result);
        }
        await refreshOutfit();
      } else if (finalJob && finalJob.status === 'failed') {
        setRenderJobId(null);
        setIsGenerating(false);
        Alert.alert('Error', 'Outfit generation failed');
      }
  };

  const refreshOutfit = async () => {
    if (!outfitId) return;

    const { data } = await getOutfit(outfitId);
    if (data) {
      setOutfit(data.outfit);
      setCoverImage(data.coverImage);
      setOutfitItems(data.items);

  };

  const deleteOutfitAction = async () => {
    if (!userId || !outfit) return;

    const { error } = await deleteOutfit(userId, outfit.id);
    if (error) {
      throw error;
    }
  };

    const loadOutfitData = async () => {
      setLoading(true);
      setCoverImageDataUri(null);

      try {
        const { data, error } = await getOutfit(outfitId);
        if (error || !data) {
          Alert.alert('Error', 'Failed to load outfit');
          return;
        }

        setOutfit(data.outfit);
        setCoverImage(data.coverImage);
        setOutfitItems(data.items);

        // Check for active render jobs
        const { data: activeJob } = await getActiveOutfitRenderJob(
          outfitId,
          userId
        );

        if (activeJob) {
          const wardrobeItemIds = data.items.map(
            (item) => item.wardrobe_item_id
          );

          try {
            const { data: items } = await supabase
              .from('wardrobe_items')
              .select('*')
              .in('id', wardrobeItemIds);

            if (items) {
              });
              setWardrobeItems(itemsMap);

              // Load images
              const imagePromises = items.map(async (item: any) => {
                const { data: imageData } = await getWardrobeItemImages(
                  item.id
                );
                if (imageData && imageData.length > 0) {
                  const imageRecord = imageData[0].image;
                  if (imageRecord) {
                  }
                }
                return { itemId: item.id, url: null };
              });

              const imageResults = await Promise.all(imagePromises);
              const newImageUrls = new Map<string, string>();
              imageResults.forEach(({ itemId, url }) => {
                if (url) {
                  newImageUrls.set(itemId, url);
                }

--- ./src/hooks/outfits/useOutfitEditor.ts ---
    new Map()
  );
  const [coverImage, setCoverImage] = useState<any | null>(null);

  const getItemImageUrl = async (itemId: string): Promise<string | null> => {
    const { data } = await getWardrobeItemImages(itemId);
    if (data && data.length > 0) {
      const imageData = data[0].image;
      if (imageData) {
        const { data: urlData } = supabase.storage
          .from(imageData.storage_bucket || 'media')
        wardrobe_item_id: item.id,
        position: index,
      })
    );

    const { data, error } = await saveOutfit(
      userId,
      {
        id: outfitId === 'new' ? undefined : outfit?.id,
        title: title.trim() || undefined,
        notes: notes.trim() || undefined,
  };

  const refreshOutfit = async () => {
    if (!outfitId || outfitId === 'new' || !userId) return;

    const { data, error } = await getOutfit(outfitId);
    if (error || !data) {
      return;
    }

    setOutfit(data.outfit);
    setNotes(data.outfit.notes || '');
    setCoverImage(data.coverImage);

    if (data.items.length > 0) {
      const wardrobeItemIds = data.items.map((oi) => oi.wardrobe_item_id);
      const { data: wardrobeItems } = await getWardrobeItemsByIds(
        wardrobeItemIds
      );
      if (wardrobeItems) {
        const wardrobeItemsById = new Map(
          wardrobeItems.map((wi) => [wi.id, wi])
        }
        setOutfitItems(itemsMap);

        const imagePromises = Array.from(itemsMap.values()).map(
          async (item) => {
            const url = await getItemImageUrl(item.id);
            return { itemId: item.id, url };
          }
        );
        const imageResults = await Promise.all(imagePromises);
        const newImageUrls = new Map<string, string>();
          async (item) => {
            const url = await getItemImageUrl(item.id);
            return { itemId: item.id, url };
          }
        );
        const imageResults = await Promise.all(imagePromises);
        const newImageUrls = new Map<string, string>();
        imageResults.forEach(({ itemId, url }) => {
          if (url) {
            newImageUrls.set(itemId, url);
          }

    const initialize = async () => {
      setLoading(true);

      // Load categories
      const { data: categoriesData } = await getWardrobeCategories();
      if (categoriesData) {
        setCategories(categoriesData);
      }

      // Handle preselected items
      }

      // Handle preselected items
      if (outfitId === 'new' && itemsParam && userId) {
        const itemIds = itemsParam.split(',');
        const { data: preselectedItems } = await getWardrobeItemsByIds(itemIds);

        if (preselectedItems && preselectedItems.length > 0) {
          const itemsMap = new Map<string, WardrobeItem>();
          const imageUrls = new Map<string, string>();


          for (const item of preselectedItems) {
            if (item.category_id) {
              itemsMap.set(item.category_id, item);
            }
            const url = await getItemImageUrl(item.id);
            if (url) {
              imageUrls.set(item.id, url);
            }
          }

        }
      }

      // Load existing outfit
      if (outfitId && outfitId !== 'new') {
        await refreshOutfit();
      }

      setLoading(false);
    };


--- ./src/hooks/outfits/useSocialEngagement.ts ---
  const loadEngagement = useCallback(async () => {
    if (!entityId || !userId || !engagementEntityType) return;

    try {
      const [likedRes, likeCountRes, savedRes, saveCountRes, commentCountRes] =
        await Promise.all([
          hasLiked(userId, engagementEntityType, entityId),
          getLikeCount(engagementEntityType, entityId),
          hasSaved(userId, engagementEntityType, entityId),
          getSaveCount(engagementEntityType, entityId),
          getCommentCount(engagementEntityType, entityId),
  const loadComments = useCallback(async () => {
    if (!entityId || !engagementEntityType) return;

    setLoadingComments(true);
    try {
      const { data } = await getComments(engagementEntityType, entityId);
      if (data) {
        setComments(data);
      }
    } catch (error) {
      console.error('Failed to load comments:', error);
  const toggleLike = useCallback(async () => {
    if (!userId || !entityId) return;

    try {
      if (liked) {
        await unlikeEntity(userId, engagementEntityType!, entityId);
        setLiked(false);
        setLikeCount((prev) => Math.max(0, prev - 1));
      } else {
        await likeEntity(userId, engagementEntityType!, entityId);
        setLiked(true);
      if (liked) {
        await unlikeEntity(userId, engagementEntityType!, entityId);
        setLiked(false);
        setLikeCount((prev) => Math.max(0, prev - 1));
      } else {
        await likeEntity(userId, engagementEntityType!, entityId);
        setLiked(true);
        setLikeCount((prev) => prev + 1);
      }
    } catch (error) {
      console.error('Failed to toggle like:', error);
  const toggleSave = useCallback(async () => {
    if (!userId || !entityId) return;

    try {
      if (saved) {
        await unsaveEntity(userId, engagementEntityType!, entityId);
        setSaved(false);
        setSaveCount((prev) => Math.max(0, prev - 1));
      } else {
        await saveEntity(userId, engagementEntityType!, entityId);
        setSaved(true);
      if (saved) {
        await unsaveEntity(userId, engagementEntityType!, entityId);
        setSaved(false);
        setSaveCount((prev) => Math.max(0, prev - 1));
      } else {
        await saveEntity(userId, engagementEntityType!, entityId);
        setSaved(true);
        setSaveCount((prev) => prev + 1);
      }
    } catch (error) {
      console.error('Failed to toggle save:', error);
  const submitComment = useCallback(
    async (text: string) => {
      if (!userId || !entityId || !text.trim() || !engagementEntityType) return false;

      try {
        const { data, error } = await createComment(
          userId,
          engagementEntityType,
          entityId,
          text.trim()
        );

--- ./src/hooks/profile/useAccountSettings.ts ---
    if (!user) return;

    setLoading(true);

    // Load settings
    const { data: settingsData, error: settingsError } = await getUserSettings(user.id);
    if (settingsError) {
      console.log('[AccountSettings] Settings not found, user may need to complete onboarding');
      setSettings(null);
    } else {
      setSettings(settingsData);
      if (!user || !settings) return;

      setSaving(true);

      try {
        const { error } = await updateUserSettings(user.id, { [key]: value });

        if (error) {
          Alert.alert('Error', 'Failed to update setting');
        } else {
          setSettings({ ...settings, [key]: value });
          return;
        }

        setSaving(true);
        try {
          const { valid, error } = await validateModelPassword(password, user.id);
          
          if (!valid) {
            Alert.alert('Error', error || 'Incorrect password');
            setSaving(false);
            return;
      } else {
        setSaving(true);
      }

      try {
        const { error: updateError } = await updateUserSettings(user.id, {
          ai_model_preference: model,
        } as any);

        if (updateError) {
          Alert.alert('Error', 'Failed to update model preference');
          Alert.alert('Error', 'Failed to update model preference');
          return;
        }

        setAiModelPreference(model);
        await loadData();
      } catch (error: any) {
        Alert.alert('Error', error.message || 'An unexpected error occurred');
      } finally {
        setSaving(false);
      }
      if (!user || !settings) return;

      // Validate password via Netlify function (same as model selection)
      setSaving(true);
      try {
        const { valid, error } = await validateModelPassword(password, user.id);
        
        if (!valid) {
          Alert.alert('Error', error || 'Incorrect password');
          setSaving(false);
          return;
        setSaving(false);
        return;
      }

      try {
        const { error: updateError } = await updateUserSettings(user.id, {
          include_headshot_in_generation: enabled,
        } as any);

        if (updateError) {
          Alert.alert('Error', 'Failed to update headshot setting');
          Alert.alert('Error', 'Failed to update headshot setting');
          return;
        }

        setIncludeHeadshotInGeneration(enabled);
        await loadData();
      } catch (error: any) {
        Alert.alert('Error', error.message || 'An unexpected error occurred');
      } finally {
        setSaving(false);
      }
    if (Platform.OS === 'web') {
      const confirmed = window.confirm('Are you sure you want to sign out?');

      if (confirmed) {
        try {
          await signOut();
          router.replace('/');
        } catch (error: any) {
          Alert.alert('Error', 'Failed to sign out. Please try again.');
        }
      }
        {
          text: 'Sign Out',
          style: 'destructive',
          onPress: async () => {
            try {
              await signOut();
              router.replace('/');
            } catch (error: any) {
              Alert.alert('Error', 'Failed to sign out. Please try again.');
            }
          },

--- ./src/hooks/profile/useProfileData.ts ---
    outfits.forEach(o => imageMap.set(o.id, null));
    return imageMap;
  }

  //  Single query to get all cover images
  const { data: coverImages } = await supabase
    .from('images')
    .select('id, storage_bucket, storage_key')
    .in('id', coverImageIds);

  // Create lookup map
      const [
        { data: profileData },
        { data: settingsData },
        { data: feedData },
        { data: allImages },
      ] = await Promise.all([
        getFullUserProfile(userId),
        getUserSettings(userId),
        getFeed(userId, 50, 0),
        supabase
          .from('images')
        //  OPTIMIZATION: Batch get outfit cover images
        const outfits = userPosts
          .map(item => item.entity?.outfit)
          .filter(Boolean);
        
        const imageCache = await batchGetOutfitCoverImages(outfits);
        setPostImages(imageCache);
      }

      //  OPTIMIZATION: Batch generate URLs for profile images (no async!)
      if (allImages) {
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadData();
  };

  useEffect(() => {
    loadData();
  }, [userId]);

--- ./src/hooks/profile/useOnboarding.ts ---
    }

    setLoading(true);

    try {
      const { error } = await initializeUserProfile(
        userId,
        handle.trim(),
        displayName.trim(),
        {
          account_privacy: accountPrivacy,

--- ./src/hooks/profile/useProfileImageGeneration.ts ---
  // Image generation hooks
  const headshotGeneration = useImageGeneration();
  const bodyShotGeneration = useImageGeneration();

  const handleUploadSelfie = useCallback(async () => {
    await headshotGeneration.pickImage(false);
  }, [headshotGeneration]);

  const handleGenerateHeadshot = useCallback(
    async (userId: string, onSuccess: () => Promise<void>) => {
      if (!headshotGeneration.uploadedBlob) {
      if (!headshotGeneration.uploadedBlob) {
        Alert.alert('Error', 'Please upload a photo first');
        return;
      }

      const imageId = await headshotGeneration.generateHeadshot(
        userId,
        headshotHairStyle || undefined,
        headshotMakeupStyle || undefined
      );

      if (imageId) {
        Alert.alert('Success', 'Headshot generated successfully!');
        setHeadshotHairStyle('');
        setHeadshotMakeupStyle('');
        headshotGeneration.clearImage();
        await onSuccess();
      }
    },
    [headshotGeneration, headshotHairStyle, headshotMakeupStyle]
  );

          'Please generate your professional headshot first before uploading a body photo.'
        );
        return;
      }

      await bodyShotGeneration.pickImage(false);
    },
    [bodyShotGeneration]
  );

  const handleGenerateBodyShot = useCallback(
      if (!bodyShotGeneration.uploadedBlob) {
        Alert.alert('Error', 'Please upload a body photo first');
        return;
      }

      const imageId = await bodyShotGeneration.generateBodyShot(
        userId,
        activeHeadshotId
      );

      if (imageId) {
      );

      if (imageId) {
        Alert.alert('Success', 'Studio model generated successfully!');
        bodyShotGeneration.clearImage();
        await onSuccess();
      }
    },
    [bodyShotGeneration]
  );


--- ./src/hooks/profile/useProfileEdit.ts ---
    }

    setSavingProfile(true);

    try {
      const { error } = await updateUserProfile(userId, {
        handle: handle.trim(),
        display_name: displayName.trim(),
      });

      if (error) {
        return false;
      }

      Alert.alert('Success', 'Profile updated successfully');
      if (onSuccess) {
        await onSuccess();
      }
      return true;
    } catch (error: any) {
      Alert.alert('Error', error.message || 'An unexpected error occurred');
      return false;
  };

  const uploadAvatar = async () => {
    if (!userId) return;

    const { status } = await ImagePicker.requestMediaLibraryPermissionsAsync();
    if (status !== 'granted') {
      Alert.alert('Permission Required', 'Please grant camera roll permissions');
      return;
    }

      return;
    }

    const mediaTypes = (ImagePicker as any).MediaType?.Images || 'images';

    const result = await ImagePicker.launchImageLibraryAsync({
      mediaTypes,
      allowsEditing: true,
      aspect: [1, 1],
      quality: 0.8,
    });

    if (result.canceled || !result.assets[0]) return;

    setUploadingAvatar(true);
    try {
      const response = await fetch(result.assets[0].uri);
      const blob = await response.blob();

      const uploadResult = await uploadImageToStorage(
        userId,
        blob,
    if (result.canceled || !result.assets[0]) return;

    setUploadingAvatar(true);
    try {
      const response = await fetch(result.assets[0].uri);
      const blob = await response.blob();

      const uploadResult = await uploadImageToStorage(
        userId,
        blob,
        `avatar-${Date.now()}.jpg`
    setUploadingAvatar(true);
    try {
      const response = await fetch(result.assets[0].uri);
      const blob = await response.blob();

      const uploadResult = await uploadImageToStorage(
        userId,
        blob,
        `avatar-${Date.now()}.jpg`
      );
      if (uploadResult.error) throw uploadResult.error;
        blob,
        `avatar-${Date.now()}.jpg`
      );
      if (uploadResult.error) throw uploadResult.error;

      const { data: imageRecord, error: imageError } = await supabase
        .from('images')
        .insert({
          owner_user_id: userId,
          storage_bucket: 'media',
          storage_key: uploadResult.data!.path,

      if (imageError || !imageRecord) {
        throw imageError || new Error('Failed to create image record');
      }

      const { error: updateError } = await updateUserSettings(userId, {
        headshot_image_id: imageRecord.id,
      } as any);

      if (updateError) throw updateError;


      if (updateError) throw updateError;

      Alert.alert('Success', 'Avatar updated successfully');
      if (onSuccess) {
        await onSuccess();
      }
    } catch (error: any) {
      Alert.alert('Error', error.message || 'Failed to upload avatar');
    } finally {
      setUploadingAvatar(false);

--- ./src/hooks/profile/useImageGeneration.ts ---
import {
  triggerHeadshotGenerate,
  triggerBodyShotGenerate,
  triggerAIJobExecution,
  waitForAIJobCompletion,
  isGeminiPolicyBlockError,
} from '@/lib/ai-jobs';

interface UseImageGenerationReturn {
  generating: boolean;
  loadingMessage: string;
    
    const permissionFn = useCamera
      ? ImagePicker.requestCameraPermissionsAsync
      : ImagePicker.requestMediaLibraryPermissionsAsync;

    const { status } = await permissionFn();
    if (status !== 'granted') {
      console.log('[pickImage] Permission denied');
      Alert.alert(
        'Permission Required',
        'Please grant ' + (useCamera ? 'camera' : 'camera roll') + ' permissions'
    const launchFn = useCamera
      ? ImagePicker.launchCameraAsync
      : ImagePicker.launchImageLibraryAsync;

    console.log('[pickImage] Launching picker...');
    const result = await launchFn({
      mediaTypes,
      allowsEditing: true,
      aspect: [3, 4],
      quality: 0.8,
    });
      console.log('[pickImage] User canceled or no assets');
      return;
    }

    console.log('[pickImage] Converting to blob...');
    const blob = await uriToBlob(result.assets[0].uri, 'image/jpeg');
    console.log('[pickImage] Blob created, size:', blob.size);

    setUploadedUri(result.assets[0].uri);
    setUploadedBlob(blob);
    console.log('[pickImage] Done!');
    setGenerating(true);
    setLoadingMessage('Uploading photo...');

    try {
      console.log('-> Uploading...');
      const uploadResult = await uploadImageToStorage(
        userId,
        uploadedBlob,
        'selfie-' + Date.now() + '.jpg'
      );
      console.log('Upload done, error:', !!uploadResult.error);
      if (uploadResult.error) throw uploadResult.error;

      setLoadingMessage('Creating headshot job...');

      console.log('-> Creating image record...');
      const { data: imageRecord, error: imageError } = await supabase
        .from('images')
        .insert({
          owner_user_id: userId,
          storage_bucket: 'media',
          storage_key: uploadResult.data.path,
      if (imageError || !imageRecord) {
        throw imageError || new Error('Failed to create image record');
      }

      console.log('-> Creating job...');
      const { data: job, error: jobError } = await triggerHeadshotGenerate(
        userId,
        imageRecord.id,
        hairStyle,
        makeupStyle
      );
      if (!job || jobError) {
        throw jobError || new Error('Failed to create headshot job');
      }

      console.log('-> Executing job...');
      await triggerAIJobExecution(job.id);
      console.log('Execution triggered');
      
      setLoadingMessage('Generating professional headshot...\nThis may take 20-30 seconds.');

      console.log('-> Waiting for completion...');
      console.log('Execution triggered');
      
      setLoadingMessage('Generating professional headshot...\nThis may take 20-30 seconds.');

      console.log('-> Waiting for completion...');
      const { data: completedJob, error: pollError } = await waitForAIJobCompletion(
        job.id,
        30,
        2000,
        '[Headshot]'
      );

      if (completedJob.status === 'failed') {
        const failureMessage = completedJob.error || 'Unknown error';
        console.log('Job failed:', failureMessage);
        
        if (isGeminiPolicyBlockError(failureMessage)) {
          setPolicyMessage(
            'Gemini could not generate this headshot because it conflicts with safety policy. No credits were charged.'
          );
          setPolicyModalVisible(true);
          return null;
        const failureMessage = completedJob.error || 'Unknown error';
        console.log('Job failed:', failureMessage);
        
        if (isGeminiPolicyBlockError(failureMessage)) {
          setPolicyMessage(
            'Gemini could not generate this headshot because it conflicts with safety policy. No credits were charged.'
          );
          setPolicyModalVisible(true);
          return null;
        }
        throw new Error('Generation failed: ' + failureMessage);
      console.log('=== SUCCESS! Image ID:', generatedImageId);
      return generatedImageId || null;
    } catch (error: any) {
      console.error('=== ERROR:', error.message);
      const message = error.message || 'Failed to generate headshot';
      if (isGeminiPolicyBlockError(message)) {
        setPolicyMessage(
          'Gemini could not generate this headshot because it conflicts with safety policy. No credits were charged.'
        );
        setPolicyModalVisible(true);
        return null;
    } catch (error: any) {
      console.error('=== ERROR:', error.message);
      const message = error.message || 'Failed to generate headshot';
      if (isGeminiPolicyBlockError(message)) {
        setPolicyMessage(
          'Gemini could not generate this headshot because it conflicts with safety policy. No credits were charged.'
        );
        setPolicyModalVisible(true);
        return null;
      }
      setError(message);

    setGenerating(true);
    setLoadingMessage('Uploading photo...');

    try {
      const uploadResult = await uploadImageToStorage(
        userId,
        uploadedBlob,
        'body-' + Date.now() + '.jpg'
      );
      if (uploadResult.error) throw uploadResult.error;
      );
      if (uploadResult.error) throw uploadResult.error;

      setLoadingMessage('Creating studio model job...');

      const { data: imageRecord, error: imageError } = await supabase
        .from('images')
        .insert({
          owner_user_id: userId,
          storage_bucket: 'media',
          storage_key: uploadResult.data.path,

      if (imageError || !imageRecord) {
        throw imageError || new Error('Failed to create image record');
      }

      const { data: job, error: jobError } = await triggerBodyShotGenerate(
        userId,
        imageRecord.id,
        headshotId
      );


      if (!job || jobError) {
        throw jobError || new Error('Failed to create body shot job');
      }

      await triggerAIJobExecution(job.id);
      setLoadingMessage('Generating studio model...\nThis may take 30-40 seconds.');

      const { data: completedJob, error: pollError } = await waitForAIJobCompletion(
        job.id,
        60,
      }

      await triggerAIJobExecution(job.id);
      setLoadingMessage('Generating studio model...\nThis may take 30-40 seconds.');

      const { data: completedJob, error: pollError } = await waitForAIJobCompletion(
        job.id,
        60,
        2000,
        '[BodyShot]'
      );
        );
      }

      if (completedJob.status === 'failed') {
        const failureMessage = completedJob.error || 'Unknown error';
        if (isGeminiPolicyBlockError(failureMessage)) {
          setPolicyMessage(
            'Gemini could not generate this studio model because it conflicts with safety policy. No credits were charged.'
          );
          setPolicyModalVisible(true);
          return null;

      if (completedJob.status === 'failed') {
        const failureMessage = completedJob.error || 'Unknown error';
        if (isGeminiPolicyBlockError(failureMessage)) {
          setPolicyMessage(
            'Gemini could not generate this studio model because it conflicts with safety policy. No credits were charged.'
          );
          setPolicyModalVisible(true);
          return null;
        }
        throw new Error('Generation failed: ' + failureMessage);
        completedJob.result?.image_id || completedJob.result?.generated_image_id;

      return generatedImageId || null;
    } catch (error: any) {
      const message = error.message || 'Failed to generate studio model';
      if (isGeminiPolicyBlockError(message)) {
        setPolicyMessage(
          'Gemini could not generate this studio model because it conflicts with safety policy. No credits were charged.'
        );
        setPolicyModalVisible(true);
        return null;
      return generatedImageId || null;
    } catch (error: any) {
      const message = error.message || 'Failed to generate studio model';
      if (isGeminiPolicyBlockError(message)) {
        setPolicyMessage(
          'Gemini could not generate this studio model because it conflicts with safety policy. No credits were charged.'
        );
        setPolicyModalVisible(true);
        return null;
      }
      setError(message);

--- ./src/hooks/profile/useImageEdit.ts ---

    setLoading(true);

    try {
      // Load image record
      const { data: imageRecord, error: imageError } = await supabase
        .from('images')
        .select('*')
        .eq('id', imageId)
        .single();

        .from(imageRecord.storage_bucket || 'media')
        .getPublicUrl(imageRecord.storage_key);

      // Find AI job that created this image
      const jobType = imageType === 'headshot' ? 'headshot_generate' : 'body_shot_generate';
      const { data: jobs } = await supabase
        .from('ai_jobs')
        .select('*')
        .eq('owner_user_id', userId)
        .eq('job_type', jobType)
        .order('created_at', { ascending: false })
      setLoading(false);
    }
  };

  const refresh = async () => {
    await loadImage();
  };

  const duplicate = async (): Promise<string | null> => {
    if (!userId || !image) return null;


    setDuplicating(true);

    try {
      // Fetch image as blob
      const response = await fetch(image.url);
      const blob = await response.blob();

      // Upload duplicate
      const timestamp = Date.now();
      const folder = imageType === 'headshot' ? 'headshots' : 'body_shots';
    setDuplicating(true);

    try {
      // Fetch image as blob
      const response = await fetch(image.url);
      const blob = await response.blob();

      // Upload duplicate
      const timestamp = Date.now();
      const folder = imageType === 'headshot' ? 'headshots' : 'body_shots';
      const storagePath = `${userId}/ai/${folder}/${timestamp}.jpg`;
      // Upload duplicate
      const timestamp = Date.now();
      const folder = imageType === 'headshot' ? 'headshots' : 'body_shots';
      const storagePath = `${userId}/ai/${folder}/${timestamp}.jpg`;

      const { data: uploadData, error: uploadError } = await supabase.storage
        .from('media')
        .upload(storagePath, blob, {
          cacheControl: '3600',
          upsert: false,
        });
        });

      if (uploadError) throw uploadError;

      // Create image record
      const { data: imageRecord, error: imageError } = await supabase
        .from('images')
        .insert({
          owner_user_id: userId,
          storage_bucket: 'media',
          storage_key: uploadData.path,

    setDeleting(true);

    try {
      // Get image record for storage key
      const { data: imageRecord } = await supabase
        .from('images')
        .select('storage_bucket, storage_key')
        .eq('id', imageId)
        .single();

        .eq('id', imageId)
        .single();

      // Delete from storage
      if (imageRecord?.storage_key) {
        await supabase.storage
          .from(imageRecord.storage_bucket || 'media')
          .remove([imageRecord.storage_key]);
      }

      // Delete from images table
          .from(imageRecord.storage_bucket || 'media')
          .remove([imageRecord.storage_key]);
      }

      // Delete from images table
      const { error } = await supabase
        .from('images')
        .delete()
        .eq('id', imageId)
        .eq('owner_user_id', userId);


      if (error) throw error;

      // If this was the active image, clear it
      const field = imageType === 'headshot' ? 'headshot_image_id' : 'body_shot_image_id';
      const { data: settings } = await supabase
        .from('user_settings')
        .select(field)
        .eq('user_id', userId)
        .single();

        .select(field)
        .eq('user_id', userId)
        .single();

      if (settings && settings[field] === imageId) {
        await updateUserSettings(userId, {
          [field]: null,
        } as any);
      }

      return true;

    try {
      const field = imageType === 'headshot' ? 'headshot_image_id' : 'body_shot_image_id';
      const displayName = imageType === 'headshot' ? 'Headshot' : 'Studio model';
      
      const { error } = await updateUserSettings(userId, {
        [field]: imageId,
      } as any);

      if (error) throw error;


--- ./src/hooks/profile/useHeadshotDetailActions.ts ---
import { useImageGeneration } from './useImageGeneration';
import {
  triggerHeadshotGenerate,
  triggerAIJobExecution,
  waitForAIJobCompletion,
  isGeminiPolicyBlockError,
} from '@/lib/ai-jobs';

interface UseHeadshotDetailActionsProps {
  headshotId: string | undefined;
  userId: string | undefined;

    setRegenerating(true);
    setLoadingMessage('Creating headshot job...');

    try {
      const { data: job, error: jobError } = await triggerHeadshotGenerate(
        user.id,
        headshot.originalSelfieId,
        hairStyle || undefined,
        makeupStyle || undefined
      );

      if (!job || jobError) {
        throw jobError || new Error('Failed to create headshot job');
      }

      await triggerAIJobExecution(job.id);
      setLoadingMessage('Regenerating headshot...\nThis may take 20-30 seconds.');

      const { data: completedJob, error: pollError } = await waitForAIJobCompletion(
        job.id,
        30,
      }

      await triggerAIJobExecution(job.id);
      setLoadingMessage('Regenerating headshot...\nThis may take 20-30 seconds.');

      const { data: completedJob, error: pollError } = await waitForAIJobCompletion(
        job.id,
        30,
        2000,
        '[Headshot]'
      );
        throw new Error('Headshot generation timed out');
      }

      if (completedJob.status === 'failed') {
        const failureMessage = completedJob.error || 'Unknown error';
        if (isGeminiPolicyBlockError(failureMessage)) {
          setLocalPolicyMessage(
            'Gemini could not generate this headshot because it conflicts with safety policy. No credits were charged.'
          );
          setLocalPolicyVisible(true);
          return;

      if (completedJob.status === 'failed') {
        const failureMessage = completedJob.error || 'Unknown error';
        if (isGeminiPolicyBlockError(failureMessage)) {
          setLocalPolicyMessage(
            'Gemini could not generate this headshot because it conflicts with safety policy. No credits were charged.'
          );
          setLocalPolicyVisible(true);
          return;
        }
        throw new Error(`Generation failed: ${failureMessage}`);
        completedJob.result?.image_id || completedJob.result?.generated_image_id;

      if (generatedImageId) {
        router.replace(`/headshot/${generatedImageId}` as any);
      } else {
        await refresh();
      }
    } catch (error: any) {
      const message = error.message || 'Failed to generate headshot';
      if (isGeminiPolicyBlockError(message)) {
        setLocalPolicyMessage(
      } else {
        await refresh();
      }
    } catch (error: any) {
      const message = error.message || 'Failed to generate headshot';
      if (isGeminiPolicyBlockError(message)) {
        setLocalPolicyMessage(
          'Gemini could not generate this headshot because it conflicts with safety policy. No credits were charged.'
        );
        setLocalPolicyVisible(true);
        return;
      }
    } catch (error: any) {
      const message = error.message || 'Failed to generate headshot';
      if (isGeminiPolicyBlockError(message)) {
        setLocalPolicyMessage(
          'Gemini could not generate this headshot because it conflicts with safety policy. No credits were charged.'
        );
        setLocalPolicyVisible(true);
        return;
      }
      Alert.alert('Error', message);
      setLoadingMessage('');
    }
  }, [effectiveUserId, headshot, hairStyle, makeupStyle, refresh, router]);

  const handleDuplicate = useCallback(async () => {
    const newId = await duplicateImage();
    if (newId) {
      router.replace(`/headshot/${newId}` as any);
    }
  }, [duplicateImage, router]);

      router.replace(`/headshot/${newId}` as any);
    }
  }, [duplicateImage, router]);

  const handleDelete = useCallback(async () => {
    const success = await deleteHeadshotImage();
    if (success) {
      setShowDeleteConfirm(false);
      router.back();
    }
  }, [deleteHeadshotImage, router]);

--- ./src/hooks/profile/useProfileImages.ts ---
    const urls = new Map<string, string | null>();
    if (imageIds.length === 0) {
      return urls;
    }

    const { data: images } = await supabase
      .from('images')
      .select('id, storage_bucket, storage_key')
      .in('id', imageIds);

    images?.forEach((image) => {
    if (!userId) return;

    setLoading(true);

    try {
      const { data: settings, error: settingsError } = await getUserSettings(
        userId
      );

      if (settingsError) {
        console.error('Settings load error:', settingsError);
          imageIds.push(settings.body_shot_image_id);
        }

        if (imageIds.length > 0) {
          try {
            const imageUrls = await Promise.race([
              loadImageUrls(imageIds),
              new Promise<Map<string, string | null>>((resolve) =>
                setTimeout(() => resolve(new Map()), 5000)
              ),
            ]);
          }
        }
      }

      try {
        await Promise.race([
          loadAllGeneratedImages(),
          new Promise((resolve) => setTimeout(resolve, 10000)),
        ]);
      } catch (e) {
        console.warn('Gallery load timeout');

  const loadAllGeneratedImages = async () => {
    if (!userId) return;

    try {
      const { headshots, bodyShots } = await getUserGeneratedImages(userId);
      setAllHeadshots(headshots);
      setAllBodyShots(bodyShots);
    } catch (error: any) {
      console.error('Error loading generated images:', error);
    }

  const setActiveHeadshot = async (imageId: string) => {
    if (!userId) return;

    try {
      const { error } = await updateUserSettings(userId, {
        headshot_image_id: imageId,
      });
      if (error) throw error;

      setActiveHeadshotId(imageId);
        headshot_image_id: imageId,
      });
      if (error) throw error;

      setActiveHeadshotId(imageId);
      const imageUrls = await loadImageUrls([imageId]);
      setHeadshotImageUrl(imageUrls.get(imageId) || null);
    } catch (error: any) {
      Alert.alert('Error', 'Failed to set active headshot');
    }
  };

  const setActiveBodyShot = async (imageId: string) => {
    if (!userId) return;

    try {
      const { error } = await updateUserSettings(userId, {
        body_shot_image_id: imageId,
      });
      if (error) throw error;

      setActiveBodyShotId(imageId);
        body_shot_image_id: imageId,
      });
      if (error) throw error;

      setActiveBodyShotId(imageId);
      const imageUrls = await loadImageUrls([imageId]);
      setBodyShotImageUrl(imageUrls.get(imageId) || null);
    } catch (error: any) {
      Alert.alert('Error', 'Failed to set active body shot');
    }
  };

--- ./src/hooks/profile/useNewBodyshot.ts ---

    setLoadingHeadshots(true);

    try {
      // Get all headshots
      const { data: images } = await supabase
        .from('images')
        .select('*')
        .eq('owner_user_id', user.id)
        .eq('source', 'ai_generated')
        .order('created_at', { ascending: false });
        .eq('source', 'ai_generated')
        .order('created_at', { ascending: false });

      if (images) {
        // Filter headshots by checking AI jobs
        const { data: jobs } = await supabase
          .from('ai_jobs')
          .select('*')
          .eq('owner_user_id', user.id)
          .eq('job_type', 'headshot_generate')
          .eq('status', 'succeeded');
  }, [user, loadHeadshots]);

  const handleGenerate = useCallback(async () => {
    if (!user || !selectedHeadshotId) return;

    const generatedImageId = await imageGeneration.generateBodyShot(
      user.id,
      selectedHeadshotId
    );
    if (generatedImageId) {
      router.replace(`/bodyshot/${generatedImageId}` as any);

--- ./src/hooks/ai/useProductShot.ts ---
  const checkExistingJob = useCallback(async () => {
    if (!itemId || !userId) return;

    try {
      // Check for active job
      const { data: activeJob } = await getActiveProductShotJob(itemId, userId);
      
      if (activeJob) {
        setJobId(activeJob.id);
        setIsGenerating(true);
        return;
        setIsGenerating(true);
        return;
      }

      // Check for recent job (within last 60 seconds)
      const { data: recentJob } = await getRecentProductShotJob(itemId, userId);
      
      if (recentJob && recentJob.status === 'succeeded') {
        // Job recently completed - trigger completion callback
        onComplete?.();
      }
    setIsGenerating(true);
    setError(null);

    try {
      // Create product shot job
      const { data: productShotJob, error: jobError } = await triggerProductShot(
        userId,
        imageId,
        itemId
      );

      if (jobError || !productShotJob) {
        throw jobError || new Error('Failed to create product shot job');
      }

      // Trigger job execution
      const { error: execError } = await triggerAIJobExecution(productShotJob.id);
      
      if (execError) {
        console.warn('Job trigger returned error (may still work):', execError);
        // Continue anyway - job might still be triggered
      }

--- ./src/hooks/ai/useAIJobPolling.ts ---
        attemptsRef.current += 1;
        setAttempts(attemptsRef.current);
        
        console.log(`[useAIJobPolling] Polling attempt ${attemptsRef.current} for job:`, jobId);

        const { data: jobData, error: jobError } = await getAIJob(jobId);

        if (jobError) {
          throw jobError;
        }

        stopPolling();
      }
    };

    // Initial poll
    await poll();

    // Set up interval polling
    pollingIntervalRef.current = setInterval(poll, interval);
  }, [jobId, enabled, isPolling, interval, maxAttempts, onComplete, onError, stopPolling]);


--- ./src/lib/settings.ts ---
 */
export async function getUserSettings(userId: string): Promise<{
  data: UserSettings | null;
  error: any;
}> {
  const { data, error } = await supabase
    .from('user_settings')
    .select('*')
    .eq('user_id', userId)
    .single();

 */
export async function updateUserSettings(
  userId: string,
  updates: Partial<UserSettings>
): Promise<{ error: any }> {
  const { error } = await supabase
    .from('user_settings')
    .upsert({
      user_id: userId,
      ...updates,
      updated_at: new Date().toISOString(),
      }
    }

    const functionUrl = `${baseUrl}/.netlify/functions/validate-model-password`;

    const response = await fetch(functionUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ password, userId }),
      },
      body: JSON.stringify({ password, userId }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      return { 
        valid: false, 
        error: errorData.error || `Server error: ${response.status}` 
      };
    }
        valid: false, 
        error: errorData.error || `Server error: ${response.status}` 
      };
    }

    const data = await response.json();
    return { valid: data.valid === true, error: data.error };
  } catch (error: any) {
    console.error('[validateModelPassword] Error:', error);
    return { 
      valid: false, 

--- ./src/lib/images.ts ---
 * 2. Fallback to first image from first outfit item
 */
export async function getOutfitCoverImageUrl(outfit: { id: string; cover_image_id?: string }): Promise<string | null> {
  // Try cover_image_id first
  if (outfit.cover_image_id) {
    const { data: imageData } = await supabase
      .from('images')
      .select('*')
      .eq('id', outfit.cover_image_id)
      .single();

    }
  }

  // Fallback: get first image from first outfit item
  if (outfit.id) {
    const { data: outfitData } = await getOutfit(outfit.id);
    if (outfitData?.items && outfitData.items.length > 0) {
      const firstItem = outfitData.items[0];
      const { data: images } = await getWardrobeItemImages(firstItem.wardrobe_item_id);
      if (images && images.length > 0) {
        const url = getPublicImageUrl(images[0].image);
  // Fallback: get first image from first outfit item
  if (outfit.id) {
    const { data: outfitData } = await getOutfit(outfit.id);
    if (outfitData?.items && outfitData.items.length > 0) {
      const firstItem = outfitData.items[0];
      const { data: images } = await getWardrobeItemImages(firstItem.wardrobe_item_id);
      if (images && images.length > 0) {
        const url = getPublicImageUrl(images[0].image);
        if (url) {
          return url;
        }

export async function getUserGeneratedImages(userId: string): Promise<{
  headshots: Array<{ id: string; url: string | null; created_at: string }>;
  bodyShots: Array<{ id: string; url: string | null; created_at: string }>;
}> {
  const { data: allImages, error } = await supabase
    .from('images')
    .select('id, storage_bucket, storage_key, created_at')
    .eq('owner_user_id', userId)
    .order('created_at', { ascending: false })
    .limit(100);

--- ./src/lib/reposts.ts ---
  data: Repost | null;
  error: any;
}> {
  try {
    // Check if post exists and is public
    const { data: post, error: postError } = await getPost(originalPostId);
    if (postError || !post) {
      throw new Error('Post not found');
    }

    if (post.visibility !== 'public') {
    if (post.visibility !== 'public') {
      throw new Error('Can only repost public posts');
    }

    // Check if already reposted
    const { data: existing } = await supabase
      .from('reposts')
      .select('id')
      .eq('user_id', userId)
      .eq('original_post_id', originalPostId)
      .single();
      .eq('original_post_id', originalPostId)
      .single();

    if (existing) {
      // Already reposted, return existing
      const { data: repost } = await supabase
        .from('reposts')
        .select('*')
        .eq('id', existing.id)
        .single();
      return { data: repost, error: null };
        .single();
      return { data: repost, error: null };
    }

    // Create new repost
    const { data: repost, error } = await supabase
      .from('reposts')
      .insert({
        user_id: userId,
        original_post_id: originalPostId,
        caption: caption,
  originalPostId: string
): Promise<{
  error: any;
}> {
  try {
    const { error } = await supabase
      .from('reposts')
      .delete()
      .eq('user_id', userId)
      .eq('original_post_id', originalPostId);

 */
export async function hasReposted(
  userId: string,
  originalPostId: string
): Promise<boolean> {
  const { data } = await supabase
    .from('reposts')
    .select('id')
    .eq('user_id', userId)
    .eq('original_post_id', originalPostId)
    .single();

/**
 * Get repost count for a post
 */
export async function getRepostCount(originalPostId: string): Promise<number> {
  const { count } = await supabase
    .from('reposts')
    .select('*', { count: 'exact', head: true })
    .eq('original_post_id', originalPostId);

  return count || 0;

--- ./src/lib/posts.ts ---
): Promise<{
  data: Post | null;
  error: any;
}> {
  try {
    const { data: post, error } = await supabase
      .from('posts')
      .insert({
        owner_user_id: userId,
        entity_type: entityType,
        entity_id: entityId,
export async function getPost(postId: string): Promise<{
  data: Post | null;
  error: any;
}> {
  try {
    const { data: post, error } = await supabase
      .from('posts')
      .select('*')
      .eq('id', postId)
      .single();

  userId: string
): Promise<{
  error: any;
}> {
  try {
    const { error } = await supabase
      .from('posts')
      .delete()
      .eq('id', postId)
      .eq('owner_user_id', userId);

  data: FeedItem[];
  error: any;
}> {
  try {
    // Get list of followed user IDs
    const { data: follows } = await supabase
      .from('follows')
      .select('followed_user_id, status')
      .eq('follower_user_id', userId);
    
    const acceptedFollows = follows?.filter(f => f.status === 'accepted') || [];
    } else {
      filterString = `owner_user_id.eq.${userId},visibility.eq.public`;
      postsQuery = postsQuery.or(filterString);
    }

    const { data: posts, error: postsError } = await postsQuery
      .order('created_at', { ascending: false })
      .limit(limit * 2);

    if (postsError) throw postsError;

      .limit(limit * 2);

    if (postsError) throw postsError;

    // Get reposts
    const { data: allReposts, error: repostsError } = await supabase
      .from('reposts')
      .select(`
        *,
        user:users!reposts_user_id_fkey(id, handle, display_name),
        original_post:posts!reposts_original_post_id_fkey(*)
    });

    // Fetch all outfits in ONE query
    let outfitsMap = new Map<string, any>();
    if (outfitIds.size > 0) {
      const { data: outfits } = await supabase
        .from('outfits')
        .select('*')
        .in('id', Array.from(outfitIds));
      
      if (outfits) {
    }

    // Fetch all lookbooks in ONE query
    let lookbooksMap = new Map<string, any>();
    if (lookbookIds.size > 0) {
      const { data: lookbooks } = await supabase
        .from('lookbooks')
        .select('*')
        .in('id', Array.from(lookbookIds));
      
      if (lookbooks) {

--- ./src/lib/feedback.ts ---

    if (filters?.status) {
      query = query.eq('status', filters.status);
    }

    const { data: threads, error } = await query;

    if (error) {
      throw error;
    }

    if (error) {
      throw error;
    }

    // Get comment counts for each thread
    const threadsWithCounts = await Promise.all(
      (threads || []).map(async (thread) => {
        const { count } = await supabase
          .from('comments')
          .select('*', { count: 'exact', head: true })
          .eq('entity_type', 'feedback_thread')
    }

    // Get comment counts for each thread
    const threadsWithCounts = await Promise.all(
      (threads || []).map(async (thread) => {
        const { count } = await supabase
          .from('comments')
          .select('*', { count: 'exact', head: true })
          .eq('entity_type', 'feedback_thread')
          .eq('entity_id', thread.id)
          .is('deleted_at', null);
): Promise<{
  data: FeedbackThread | null;
  error: any;
}> {
  try {
    const { data: thread, error } = await supabase
      .from('feedback_threads')
      .select(
        `
        *,
        user:users(id, handle, display_name, avatar_url)
    if (error) {
      throw error;
    }

    // Get comment count
    const { count } = await supabase
      .from('comments')
      .select('*', { count: 'exact', head: true })
      .eq('entity_type', 'feedback_thread')
      .eq('entity_id', id)
      .is('deleted_at', null);
): Promise<{
  data: FeedbackThread | null;
  error: any;
}> {
  try {
    const { data: thread, error } = await supabase
      .from('feedback_threads')
      .insert({
        user_id: userId,
        title: data.title,
        body: data.body,
): Promise<{
  data: FeedbackThread | null;
  error: any;
}> {
  try {
    const { data: thread, error } = await supabase
      .from('feedback_threads')
      .update(updates)
      .eq('id', threadId)
      .eq('user_id', userId)
      .select(
    if (error) {
      throw error;
    }

    // Get comment count
    const { count } = await supabase
      .from('comments')
      .select('*', { count: 'exact', head: true })
      .eq('entity_type', 'feedback_thread')
      .eq('entity_id', threadId)
      .is('deleted_at', null);

--- ./src/lib/transactions.ts ---
): Promise<{
  data: Transaction | null;
  error: any;
}> {
  try {
    const { data: transaction, error } = await supabase
      .from('transactions')
      .insert({
        buyer_user_id: buyerId,
        seller_user_id: sellerId,
        listing_id: listingId,
export async function getUserBuyerTransactions(userId: string): Promise<{
  data: Transaction[];
  error: any;
}> {
  try {
    const { data: transactions, error } = await supabase
      .from('transactions')
      .select('*, listings(*, wardrobe_items(*))')
      .eq('buyer_user_id', userId)
      .order('created_at', { ascending: false });

export async function getUserSellerTransactions(userId: string): Promise<{
  data: Transaction[];
  error: any;
}> {
  try {
    const { data: transactions, error } = await supabase
      .from('transactions')
      .select('*, listings(*, wardrobe_items(*))')
      .eq('seller_user_id', userId)
      .order('created_at', { ascending: false });

export async function getTransaction(transactionId: string): Promise<{
  data: Transaction | null;
  error: any;
}> {
  try {
    const { data: transaction, error } = await supabase
      .from('transactions')
      .select('*, listings(*, wardrobe_items(*))')
      .eq('id', transactionId)
      .single();

): Promise<{
  data: Transaction | null;
  error: any;
}> {
  try {
    const { data: transaction, error } = await supabase
      .from('transactions')
      .update({ status })
      .eq('id', transactionId)
      .select()
      .single();

--- ./src/lib/wardrobe/items-mutations.ts ---
  data: { item: WardrobeItem; images: any[] } | null;
  error: any;
}> {
  try {
    // Upload images first
    const { data: imageIds, errors: uploadErrors } = await batchUploadImages(
      userId,
      imageFiles,
      'upload'
    );

        error: new Error('Failed to upload any images'),
      };
    }

    // Create wardrobe item
    const { data: item, error: itemError } = await supabase
      .from('wardrobe_items')
      .insert({
        wardrobe_id: wardrobeId,
        owner_user_id: userId,
        ...itemData,
      image_id: imageId,
      type: 'original' as const,
      sort_order: index,
    }));

    const { data: itemImages, error: linkError } = await supabase
      .from('wardrobe_item_images')
      .insert(imageLinks)
      .select();

    if (linkError) {

    if (linkError) {
      console.error('Failed to create image links:', linkError);
      
      // Try to verify if links exist despite error
      const { data: existingLinks } = await supabase
        .from('wardrobe_item_images')
        .select('*, images(*)')
        .eq('wardrobe_item_id', item.id)
        .order('sort_order', { ascending: true });

  itemId: string,
  userId: string,
  updates: Partial<Omit<WardrobeItem, 'id' | 'owner_user_id' | 'created_at'>>
): Promise<QueryResult<WardrobeItem>> {
  try {
    const { data, error } = await supabase
      .from('wardrobe_items')
      .update({
        ...updates,
        updated_at: new Date().toISOString(),
      })
export async function deleteWardrobeItem(
  itemId: string,
  userId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('wardrobe_items')
      .update({ archived_at: new Date().toISOString() })
      .eq('id', itemId)
      .eq('owner_user_id', userId);

export async function saveWardrobeItem(
  userId: string,
  wardrobeItemId: string
): Promise<QueryResult<{ id: string }>> {
  try {
    const { data, error } = await supabase
      .from('saved_wardrobe_items')
      .insert({
        user_id: userId,
        wardrobe_item_id: wardrobeItemId,
      })
export async function unsaveWardrobeItem(
  userId: string,
  wardrobeItemId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('saved_wardrobe_items')
      .delete()
      .eq('user_id', userId)
      .eq('wardrobe_item_id', wardrobeItemId);


--- ./src/lib/wardrobe/images.ts ---
  }>;
  error: any;
}> {
  try {
    // Fetch wardrobe_item_images links first
    const { data: links, error: linksError } = await supabase
      .from('wardrobe_item_images')
      .select('*')
      .eq('wardrobe_item_id', itemId)
      .order('sort_order', { ascending: true });

      return { data: [], error: null };
    }

    // Fetch images directly using the image IDs
    const linkImageIds = links.map((link) => link.image_id);
    const { data: images, error: imagesError } = await supabase
      .from('images')
      .select('*')
      .in('id', linkImageIds);

    if (imagesError) {
    return { data: new Map(), error: null };
  }

  try {
    // Fetch all links for all items at once
    const { data: links, error: linksError } = await supabase
      .from('wardrobe_item_images')
      .select('*')
      .in('wardrobe_item_id', itemIds)
      .order('sort_order', { ascending: true });


    // Get all unique image IDs
    const imageIds = [...new Set(links.map((link) => link.image_id))];

    // Fetch all images at once
    const { data: images, error: imagesError } = await supabase
      .from('images')
      .select('*')
      .in('id', imageIds);

    if (imagesError) {
  sortOrder?: number
): Promise<{ error: any }> {
  try {
    // Get current max sort_order if not provided
    if (sortOrder === undefined) {
      const { data: existing } = await supabase
        .from('wardrobe_item_images')
        .select('sort_order')
        .eq('wardrobe_item_id', itemId)
        .order('sort_order', { ascending: false })
        .limit(1)
        .single();

      sortOrder = existing ? existing.sort_order + 1 : 0;
    }

    const { error } = await supabase.from('wardrobe_item_images').insert({
      wardrobe_item_id: itemId,
      image_id: imageId,
      type,
      sort_order: sortOrder,
    });
export async function removeImageFromWardrobeItem(
  itemId: string,
  imageId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('wardrobe_item_images')
      .delete()
      .eq('wardrobe_item_id', itemId)
      .eq('image_id', imageId);

  imageUpdates: Array<{ image_id: string; sort_order: number }>
): Promise<{ error: any }> {
  try {
    // Update each image's sort order
    for (const update of imageUpdates) {
      const { error } = await supabase
        .from('wardrobe_item_images')
        .update({ sort_order: update.sort_order })
        .eq('wardrobe_item_id', itemId)
        .eq('image_id', update.image_id);

  itemId: string,
  imageId: string
): Promise<{ error: any }> {
  try {
    // Get all current images
    const { data: images } = await supabase
      .from('wardrobe_item_images')
      .select('image_id, sort_order')
      .eq('wardrobe_item_id', itemId)
      .order('sort_order', { ascending: true });

export async function getPrimaryImage(itemId: string): Promise<{
  data: { id: string; image_id: string; image: any } | null;
  error: any;
}> {
  try {
    const { data: link, error: linkError } = await supabase
      .from('wardrobe_item_images')
      .select('*')
      .eq('wardrobe_item_id', itemId)
      .order('sort_order', { ascending: true })
      .limit(1)

    if (linkError || !link) {
      return { data: null, error: linkError };
    }

    const { data: image, error: imageError } = await supabase
      .from('images')
      .select('*')
      .eq('id', link.image_id)
      .single();


--- ./src/lib/wardrobe/categories.ts ---
 */
export async function getCategory(categoryId: string): Promise<{
  data: WardrobeCategory | null;
  error: any;
}> {
  const result = await fetchList<WardrobeCategory>(
    'wardrobe_categories',
    '*',
    {
      filters: { id: categoryId },
      limit: 1,
 */
export async function getSubcategory(subcategoryId: string): Promise<{
  data: WardrobeSubcategory | null;
  error: any;
}> {
  const result = await fetchList<WardrobeSubcategory>(
    'wardrobe_subcategories',
    '*',
    {
      filters: { id: subcategoryId },
      limit: 1,
  data: Array<WardrobeCategory & { subcategories?: WardrobeSubcategory[] }>;
  error: any;
}> {
  try {
    const { data: categories, error: catError } =
      await getWardrobeCategories();
    
    if (catError || !categories) {
      return { data: [], error: catError };
    }

    
    if (catError || !categories) {
      return { data: [], error: catError };
    }

    const categoriesWithSubs = await Promise.all(
      categories.map(async (category) => {
        const { data: subcategories } = await getSubcategories(category.id);
        return {
          ...category,
          subcategories: subcategories || [],
      return { data: [], error: catError };
    }

    const categoriesWithSubs = await Promise.all(
      categories.map(async (category) => {
        const { data: subcategories } = await getSubcategories(category.id);
        return {
          ...category,
          subcategories: subcategories || [],
        };
      })

--- ./src/lib/wardrobe/diagnostics.ts ---
  } | null;
  error: any;
}> {
  try {
    // Get all images owned by user
    const { data: allImages, error: imagesError } = await supabase
      .from('images')
      .select('id, storage_key, created_at, owner_user_id')
      .eq('owner_user_id', userId)
      .order('created_at', { ascending: false });

      throw imagesError;
    }

    // Get all image links
    const imageIds = allImages?.map((img) => img.id) || [];
    const { data: allLinks, error: linksError } = await supabase
      .from('wardrobe_item_images')
      .select('image_id')
      .in(
        'image_id',
        imageIds.length > 0 ? imageIds : ['00000000-0000-0000-0000-000000000000']
    const orphanedImages = (allImages || []).filter(
      (img) => !linkedImageIds.has(img.id)
    );

    // Get all wardrobe items owned by user
    const { data: allItems, error: itemsError } = await supabase
      .from('wardrobe_items')
      .select('id, title, created_at, owner_user_id')
      .eq('owner_user_id', userId)
      .is('archived_at', null)
      .order('created_at', { ascending: false });
      throw itemsError;
    }

    // Get all item links to find items without images
    const itemIds = allItems?.map((item) => item.id) || [];
    const { data: itemLinks, error: itemLinksError } = await supabase
      .from('wardrobe_item_images')
      .select('wardrobe_item_id')
      .in(
        'wardrobe_item_id',
        itemIds.length > 0 ? itemIds : ['00000000-0000-0000-0000-000000000000']
  error: any;
}> {
  try {
    // Find orphaned images and items without images
    const { data: diagnostic, error: diagnosticError } =
      await findOrphanedImages(userId);
    
    if (diagnosticError || !diagnostic) {
      throw diagnosticError || new Error('Failed to find orphaned images');
    }

          return timeDiff <= 5 * 60 * 1000; // 5 minutes
        });

      if (matchingImages.length > 0) {
        // Check if this item already has links
        const { data: existingLinks } = await supabase
          .from('wardrobe_item_images')
          .select('image_id')
          .eq('wardrobe_item_id', item.id);

        if (existingLinks && existingLinks.length > 0) {
          image_id: img.id,
          type: 'original' as const,
          sort_order: index,
        }));

        const { data: insertedLinks, error: insertError } = await supabase
          .from('wardrobe_item_images')
          .insert(imageLinks)
          .select();

        if (insertError) {

        if (insertError) {
          // Check if it's a duplicate key error
          if (insertError.code === '23505') {
            imagesToLink.forEach((img) => linkedImageIds.add(img.id));
            const { data: verifiedLinks } = await supabase
              .from('wardrobe_item_images')
              .select('image_id')
              .eq('wardrobe_item_id', item.id);
            if (verifiedLinks && verifiedLinks.length > 0) {
              repaired++;
          linked.push({ itemId: item.id, imageId: img.id });
        });

        // Verify links were created
        if (!insertedLinks || insertedLinks.length === 0) {
          const { data: verifiedLinks } = await supabase
            .from('wardrobe_item_images')
            .select('image_id')
            .eq('wardrobe_item_id', item.id);
          if (!verifiedLinks || verifiedLinks.length === 0) {
            continue;
  } | null;
  error: any;
}> {
  try {
    // Check if wardrobe_item_images records exist
    const { data: linkData, error: linkError } = await supabase
      .from('wardrobe_item_images')
      .select('id, image_id, wardrobe_item_id, type, sort_order')
      .eq('wardrobe_item_id', itemId);

    if (linkError) {
      };
    }

    // Check if we can access the image records directly
    const imageIds = linkData.map((link) => link.image_id);
    const { data: imageData, error: imageError } = await supabase
      .from('images')
      .select('id, storage_bucket, storage_key, owner_user_id')
      .in('id', imageIds);

    const accessibleCount = imageData?.length || 0;
  data: { applied: boolean } | null;
  error: any;
}> {
  try {
    // Try to query the policy information
    const { data: testData, error: testError } = await supabase
      .from('wardrobe_item_images')
      .select('id')
      .limit(1);

    if (testError) {

--- ./src/lib/wardrobe/items-queries.ts ---
 */
export async function getDefaultWardrobeId(userId: string): Promise<{
  data: string | null;
  error: any;
}> {
  const result = await fetchSingle<{ id: string }>(
    'wardrobes',
    'id',
    { owner_user_id: userId }
  );
  

  if (filters?.is_favorite !== undefined) {
    queryFilters.is_favorite = filters.is_favorite;
  }

  let result = await fetchList<WardrobeItem>('wardrobe_items', '*', {
    filters: queryFilters,
    orderBy: { column: 'created_at', ascending: false },
  });

  // Apply search filter if provided (client-side for now)
    search?: string;
  }
): Promise<QueryListResult<WardrobeItem>> {
  try {
    const { data: wardrobeId, error: wardrobeError } =
      await getDefaultWardrobeId(userId);
    
    if (wardrobeError || !wardrobeId) {
      return { data: [], error: wardrobeError };
    }

export async function isWardrobeItemSaved(
  userId: string,
  wardrobeItemId: string
): Promise<{ data: boolean; error: any }> {
  try {
    const { data, error } = await supabase
      .from('saved_wardrobe_items')
      .select('id')
      .eq('user_id', userId)
      .eq('wardrobe_item_id', wardrobeItemId)
      .maybeSingle();
    search?: string;
  }
): Promise<QueryListResult<WardrobeItem>> {
  try {
    // Get saved item IDs
    const { data: savedItems, error: savedError } = await supabase
      .from('saved_wardrobe_items')
      .select('wardrobe_item_id')
      .eq('user_id', userId);

    if (savedError || !savedItems || savedItems.length === 0) {

    if (filters?.category_id) {
      queryFilters.category_id = filters.category_id;
    }

    let result = await fetchList<WardrobeItem>('wardrobe_items', '*', {
      filters: queryFilters,
      orderBy: { column: 'created_at', ascending: false },
    });

    // Apply search filter if provided

--- ./src/lib/calendar/entries.ts ---
  endDate: string
): Promise<{
  data: Array<CalendarEntry & { calendar_day?: any; outfit?: any; slot_preset?: CalendarSlotPreset }>;
  error: any;
}> {
  const { data: days, error: daysError } = await supabase
    .from('calendar_days')
    .select('*')
    .eq('owner_user_id', userId)
    .gte('date', startDate)
    .lte('date', endDate);

  if (dayIds.length === 0) {
    return { data: [], error: null };
  }

  const { data: entries, error: entriesError } = await supabase
    .from('calendar_entries')
    .select('*, calendar_days(*), outfits(*), calendar_slot_presets(*)')
    .in('calendar_day_id', dayIds)
    .order('sort_order', { ascending: true });

  }
): Promise<{
  data: CalendarEntry | null;
  error: any;
}> {
  const { data: calendarDay, error: dayError } = await getOrCreateCalendarDay(userId, date);
  if (dayError || !calendarDay) {
    return { data: null, error: dayError };
  }

  const { data: entry, error: entryError } = await supabase
  const { data: calendarDay, error: dayError } = await getOrCreateCalendarDay(userId, date);
  if (dayError || !calendarDay) {
    return { data: null, error: dayError };
  }

  const { data: entry, error: entryError } = await supabase
    .from('calendar_entries')
    .insert({
      calendar_day_id: calendarDay.id,
      outfit_id: entryData.outfit_id || null,
      slot_preset_id: entryData.slot_preset_id || null,
  updates: Partial<Omit<CalendarEntry, 'id' | 'calendar_day_id' | 'created_at'>>
): Promise<{
  data: CalendarEntry | null;
  error: any;
}> {
  const { data, error } = await supabase
    .from('calendar_entries')
    .update({
      ...updates,
      updated_at: new Date().toISOString(),
    })

/**
 * Delete calendar entry
 */
export async function deleteCalendarEntry(entryId: string): Promise<{ error: any }> {
  const { error } = await supabase
    .from('calendar_entries')
    .delete()
    .eq('id', entryId);

  return { error };
  date: string
): Promise<{
  data: Array<CalendarEntry & { outfit?: any; slot_preset?: CalendarSlotPreset }>;
  error: any;
}> {
  const { data: day } = await getOrCreateCalendarDay(userId, date);
  if (!day) {
    return { data: [], error: null };
  }

  const { data: entries, error } = await supabase
  const { data: day } = await getOrCreateCalendarDay(userId, date);
  if (!day) {
    return { data: [], error: null };
  }

  const { data: entries, error } = await supabase
    .from('calendar_entries')
    .select('*, outfits(*), calendar_slot_presets(*)')
    .eq('calendar_day_id', day.id)
    .order('sort_order', { ascending: true });

): Promise<{
  data: Array<{ date: string; entry: CalendarEntry }>;
  error: any;
}> {
  try {
    const { data: entries, error } = await supabase
      .from('calendar_entries')
      .select('*, calendar_day:calendar_days!calendar_day_id(date, owner_user_id)')
      .eq('outfit_id', outfitId);

    if (error) {

--- ./src/lib/calendar/presets.ts ---
export async function getSlotPresets(userId: string): Promise<{
  data: CalendarSlotPreset[];
  error: any;
}> {
  // Fetch system and user presets in parallel
  const [systemResult, userResult] = await Promise.all([
    supabase
      .from('calendar_slot_presets')
      .select('*')
      .eq('scope', 'system')
      .order('sort_order', { ascending: true }),
  sortOrder?: number
): Promise<{
  data: CalendarSlotPreset | null;
  error: any;
}> {
  const { data, error } = await supabase
    .from('calendar_slot_presets')
    .insert({
      scope: 'user',
      owner_user_id: userId,
      name,

--- ./src/lib/calendar/days.ts ---
): Promise<{
  data: CalendarDay | null;
  error: any;
}> {
  // Try to get existing day
  const { data: existing, error: findError } = await supabase
    .from('calendar_days')
    .select('*')
    .eq('owner_user_id', userId)
    .eq('date', date)
    .single();
  if (existing) {
    return { data: existing, error: null };
  }

  // Create new day
  const { data: newDay, error: createError } = await supabase
    .from('calendar_days')
    .insert({
      owner_user_id: userId,
      date,
    })

--- ./src/lib/lookbooks/core.ts ---
      return { data: [], error: null };
    }

    const searchTerm = `%${query.toLowerCase()}%`;
    
    const { data, error } = await supabase
      .from('lookbooks')
      .select('id, owner_user_id, title, description, visibility, created_at, owner:users!owner_user_id(handle, display_name)')
      .or(`title.ilike.${searchTerm},description.ilike.${searchTerm}`)
      .in('visibility', ['public', 'followers'])
      .limit(limit);
 */
export async function getUserLookbooks(userId: string): Promise<{
  data: Lookbook[];
  error: any;
}> {
  const { data, error } = await supabase
    .from('lookbooks')
    .select('*')
    .eq('owner_user_id', userId)
    .order('created_at', { ascending: false });

export async function getLookbook(lookbookId: string): Promise<{
  data: { lookbook: Lookbook; outfits: LookbookOutfit[] } | null;
  error: any;
}> {
  // Get lookbook
  const { data: lookbook, error: lookbookError } = await supabase
    .from('lookbooks')
    .select('*')
    .eq('id', lookbookId)
    .single();

    return { data: null, error: lookbookError };
  }

  // Get lookbook outfits (if custom_manual)
  if (lookbook.type === 'custom_manual') {
    const { data: lookbookOutfits, error: outfitsError } = await supabase
      .from('lookbook_outfits')
      .select('*')
      .eq('lookbook_id', lookbookId)
      .order('position', { ascending: true });

  try {
    let lookbook: Lookbook;

    if (lookbookData.id) {
      // Update existing lookbook
      const { data: updatedLookbook, error: updateError } = await supabase
        .from('lookbooks')
        .update({
          ...lookbookData,
          updated_at: new Date().toISOString(),
        })
      lookbook = updatedLookbook;

      // Update outfits if custom_manual
      if (lookbookData.type === 'custom_manual' && outfitIds) {
        // Delete existing outfits
        await supabase.from('lookbook_outfits').delete().eq('lookbook_id', lookbook.id);

        // Insert new outfits
        const lookbookOutfitsData = outfitIds.map((outfitId, index) => ({
          lookbook_id: lookbook.id,
          outfit_id: outfitId,
          lookbook_id: lookbook.id,
          outfit_id: outfitId,
          position: index,
        }));

        await supabase.from('lookbook_outfits').insert(lookbookOutfitsData);
      }
    } else {
      // Create new lookbook
      const { data: newLookbook, error: createError } = await supabase
        .from('lookbooks')

        await supabase.from('lookbook_outfits').insert(lookbookOutfitsData);
      }
    } else {
      // Create new lookbook
      const { data: newLookbook, error: createError } = await supabase
        .from('lookbooks')
        .insert({
          owner_user_id: userId,
          title: lookbookData.title,
          description: lookbookData.description,
          lookbook_id: lookbook.id,
          outfit_id: outfitId,
          position: index,
        }));

        await supabase.from('lookbook_outfits').insert(lookbookOutfitsData);
      }
    }

    return { data: lookbook, error: null };
  } catch (error: any) {
  data: any | null;
  error: any;
}> {
  try {
    // Get lookbook
    const { data: lookbook } = await getLookbook(lookbookId);
    if (!lookbook) {
      throw new Error('Lookbook not found');
    }

    // Create post
    if (!lookbook) {
      throw new Error('Lookbook not found');
    }

    // Create post
    const { data: post, error: postError } = await supabase
      .from('posts')
      .insert({
        owner_user_id: userId,
        entity_type: 'lookbook',
        entity_id: lookbookId,
 */
export async function deleteLookbook(
  userId: string,
  lookbookId: string
): Promise<{ error: any }> {
  const { error } = await supabase
    .from('lookbooks')
    .delete()
    .eq('id', lookbookId)
    .eq('owner_user_id', userId);


--- ./src/lib/lookbooks/system.ts ---
    // Apply default ordering (for non-top-rated types)
    if (type !== 'system_top') {
      query = query.order('created_at', { ascending: false });
    }

    const { data: outfits, error } = await query;

    if (error) {
      return { data: [], error };
    }

      const outfitIds = (outfits || []).map((o) => o.id);
      if (outfitIds.length === 0) {
        return { data: [], error: null };
      }

      const ratingMap = await calculateOutfitRatings(outfitIds);
      
      // Sort outfits by rating (descending)
      const outfitsWithRatings = (outfits || []).map((outfit) => ({
        outfit,
        rating: ratingMap.get(outfit.id) || 0,

--- ./src/lib/listings/validation.ts ---
    if (!imageIds || imageIds.length === 0) {
      return { valid: true };
    }

    // Get wardrobe item images with type
    const { data: itemImages, error } = await supabase
      .from('wardrobe_item_images')
      .select('image_id, type')
      .in('image_id', imageIds)
      .eq('wardrobe_item_id', wardrobeItemId);

export async function verifyListingItemOwnership(
  userId: string,
  wardrobeItemId: string
): Promise<{ owned: boolean; error?: string }> {
  try {
    const { data, error } = await supabase
      .from('wardrobe_items')
      .select('id, owner_user_id')
      .eq('id', wardrobeItemId)
      .eq('owner_user_id', userId)
      .single();
export async function verifyListingOwnership(
  userId: string,
  listingId: string
): Promise<{ owned: boolean; listingData?: any; error?: string }> {
  try {
    const { data, error } = await supabase
      .from('listings')
      .select('id, seller_user_id, wardrobe_item_id')
      .eq('id', listingId)
      .eq('seller_user_id', userId)
      .single();

--- ./src/lib/listings/core.ts ---
export async function getUserListings(userId: string): Promise<{
  data: ListingWithImages[];
  error: any;
}> {
  try {
    const { data: listings, error } = await supabase
      .from('listings')
      .select(
        `
        *,
        listing_images(*, images(*)),
export async function getListing(listingId: string): Promise<{
  data: ListingWithImages | null;
  error: any;
}> {
  try {
    const { data: listing, error } = await supabase
      .from('listings')
      .select(
        `
        *,
        listing_images(*, images(*)),
  data: ListingWithImages | null;
  error: any;
}> {
  try {
    // Verify wardrobe item ownership
    const { owned, error: ownershipError } = await verifyListingItemOwnership(userId, wardrobeItemId);
    if (!owned || ownershipError) {
      throw new Error(ownershipError || 'Wardrobe item not found or access denied');
    }

    // Verify images are original
      throw new Error(ownershipError || 'Wardrobe item not found or access denied');
    }

    // Verify images are original
    if (listingData.imageIds && listingData.imageIds.length > 0) {
      const { valid, error: imageError } = await verifyOriginalImages(wardrobeItemId, listingData.imageIds);
      if (!valid || imageError) {
        throw new Error(imageError || 'Invalid images');
      }
    }

        throw new Error(imageError || 'Invalid images');
      }
    }

    // Create listing
    const { data: listing, error: listingError } = await supabase
      .from('listings')
      .insert({
        seller_user_id: userId,
        wardrobe_item_id: wardrobeItemId,
        price: listingData.price,
        listing_id: listing.id,
        image_id: imageId,
        sort_order: index,
      }));

      const { error: imagesError } = await supabase
        .from('listing_images')
        .insert(listingImagesData);

      if (imagesError) {
        throw imagesError;
        throw imagesError;
      }
    }

    // Get full listing with images
    const { data: fullListing } = await getListing(listing.id);

    return { data: fullListing, error: null };
  } catch (error: any) {
    return { data: null, error };
  }
  data: ListingWithImages | null;
  error: any;
}> {
  try {
    // Verify listing ownership
    const { owned, listingData: existingListing, error: ownershipError } = await verifyListingOwnership(userId, listingId);
    if (!owned || ownershipError) {
      throw new Error(ownershipError || 'Listing not found or access denied');
    }

    // Verify images are original if provided
      throw new Error(ownershipError || 'Listing not found or access denied');
    }

    // Verify images are original if provided
    if (listingData.imageIds && listingData.imageIds.length > 0) {
      const { valid, error: imageError } = await verifyOriginalImages(
        existingListing.wardrobe_item_id,
        listingData.imageIds
      );
      if (!valid || imageError) {
        throw new Error(imageError || 'Invalid images');
    if (listingData.price !== undefined) updateData.price = listingData.price;
    if (listingData.currency !== undefined) updateData.currency = listingData.currency;
    if (listingData.condition !== undefined) updateData.condition = listingData.condition;
    if (listingData.status !== undefined) updateData.status = listingData.status;

    const { data: listing, error: listingError } = await supabase
      .from('listings')
      .update(updateData)
      .eq('id', listingId)
      .eq('seller_user_id', userId)
      .select()
    }

    // Update images if provided
    if (listingData.imageIds !== undefined) {
      // Delete existing listing images
      await supabase.from('listing_images').delete().eq('listing_id', listingId);

      // Insert new listing images
      if (listingData.imageIds.length > 0) {
        const listingImagesData = listingData.imageIds.map((imageId, index) => ({
          listing_id: listingId,
          listing_id: listingId,
          image_id: imageId,
          sort_order: index,
        }));

        const { error: imagesError } = await supabase
          .from('listing_images')
          .insert(listingImagesData);

        if (imagesError) {
          throw imagesError;
        }
      }
    }

    // Get full listing with images
    const { data: fullListing } = await getListing(listingId);

    return { data: fullListing, error: null };
  } catch (error: any) {
    return { data: null, error };
  }
  listingId: string
): Promise<{
  error: any;
}> {
  try {
    const { error } = await supabase
      .from('listings')
      .delete()
      .eq('id', listingId)
      .eq('seller_user_id', userId);

): Promise<{
  data: ListingWithImages[];
  error: any;
}> {
  try {
    const { data: listings, error } = await supabase
      .from('listings')
      .select(
        `
        *,
        listing_images(*, images(*)),

--- ./src/lib/similarity/wardrobe-search.ts ---
    let sourceAttrs: any[] = [];
    let attrsError: any = null;
    
    if (sourceEntityType === 'outfit') {
      // Get outfit items and collect attributes from each wardrobe item
      const { data: outfitItems, error: outfitItemsError } = await supabase
        .from('outfit_items')
        .select('wardrobe_item_id')
        .eq('outfit_id', sourceEntityId);
      
      if (outfitItemsError) {
        attrsError = outfitItemsError;
      } else if (outfitItems && outfitItems.length > 0) {
        // Collect attributes from all wardrobe items in the outfit
        const allAttrs: any[] = [];
        for (const item of outfitItems) {
          const { data: itemAttrs } = await getEntityAttributes('wardrobe_item', item.wardrobe_item_id);
          if (itemAttrs && itemAttrs.length > 0) {
            allAttrs.push(...itemAttrs);
          }
        }
        sourceAttrs = allAttrs;
        }
        sourceAttrs = allAttrs;
      }
    } else {
      // For wardrobe items, get attributes directly
      const result = await getEntityAttributes(sourceEntityType, sourceEntityId);
      sourceAttrs = result.data || [];
      attrsError = result.error;
    }

    if (attrsError) {

    if (categoryId) {
      wardrobeQuery = wardrobeQuery.eq('category_id', categoryId);
    }

    const { data: wardrobeItems, error: itemsError } = await wardrobeQuery;

    if (itemsError) {
      throw itemsError;
    }


    // Get attributes for all items and calculate similarity
    const results: SimilarityResult[] = [];

    for (const item of wardrobeItems) {
      const { data: itemAttrs } = await getEntityAttributes('wardrobe_item', item.id);

      if (itemAttrs && itemAttrs.length > 0) {
        const { score, matchingAttributes } = calculateSimilarityScore(
          sourceAttrs,
          itemAttrs

--- ./src/lib/similarity/sellable-search.ts ---
  data: SimilarityResult[];
  error: any;
}> {
  try {
    // Get source entity attributes
    const { data: sourceAttrs, error: attrsError } = await getEntityAttributes(
      sourceEntityType,
      sourceEntityId
    );

    if (attrsError) {

    if (categoryId) {
      sellableQuery = sellableQuery.eq('category_id', categoryId);
    }

    const { data: sellableItems, error: itemsError } = await sellableQuery;

    if (itemsError) {
      throw itemsError;
    }


    // Get attributes for all items and calculate similarity
    const results: SimilarityResult[] = [];

    for (const item of sellableItems) {
      const { data: itemAttrs } = await getEntityAttributes('wardrobe_item', item.id);

      if (itemAttrs && itemAttrs.length > 0) {
        const { score, matchingAttributes } = calculateSimilarityScore(
          sourceAttrs,
          itemAttrs

--- ./src/lib/ai-jobs/polling.ts ---
  try {
    let intervalMs = initialIntervalMs;
    const maxIntervalMs = 10000;

    for (let attempt = 0; attempt < maxAttempts; attempt++) {
      const { data, error } = await getAIJob(jobId);

      // #region agent log
      if (attempt % 5 === 0 || data?.status === 'succeeded' || data?.status === 'failed') {
        fetch('http://127.0.0.1:7243/ingest/3a269559-16ce-41e5-879a-1155393947c5',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'polling.ts:38',message:'pollAIJob attempt',data:{jobId,attempt,maxAttempts,hasError:!!error,errorMessage:error?.message,hasData:!!data,status:data?.status},timestamp:Date.now(),sessionId:'debug-session',runId:'run1',hypothesisId:'E'})}).catch(()=>{});
      }
        return { data: null, error };
      }

      if (!data) {
        if (attempt < maxAttempts - 1) {
          await new Promise((resolve) => setTimeout(resolve, intervalMs));
          intervalMs = Math.min(intervalMs * 2, maxIntervalMs);
          continue;
        }
        failureCountByJob.set(jobId, failureCount + 1);
        return { data: null, error: new Error('Job not found') };
        // #endregion
        return { data, error: null };
      }

      if (attempt < maxAttempts - 1) {
        await new Promise((resolve) => setTimeout(resolve, intervalMs));
        intervalMs = Math.min(intervalMs * 2, maxIntervalMs);
      }
    }

    // #region agent log
  jobId: string,
  maxAttempts: number = SUPABASE_CONFIG.DEV_MODE ? 30 : 60,
  initialIntervalMs: number = 2000,
  logPrefix?: string
): Promise<QueryResult<AIJob>> {
  const { data: completedJob, error: pollError } = await pollAIJob(
    jobId,
    maxAttempts,
    initialIntervalMs
  );


  if (logPrefix) {
    console.log(`${logPrefix} polling timed out, doing final check...`);
  }

  const { data: finalCheck } = await getAIJob(jobId);
  if (
    finalCheck &&
    (finalCheck.status === 'succeeded' || finalCheck.status === 'failed')
  ) {
    return { data: finalCheck, error: null };
  // #region agent log
  fetch('http://127.0.0.1:7243/ingest/3a269559-16ce-41e5-879a-1155393947c5',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'polling.ts:114',message:'waitForAIJobCompletion entry',data:{jobId,maxAttempts,initialIntervalMs,logPrefix},timestamp:Date.now(),sessionId:'debug-session',runId:'run1',hypothesisId:'E'})}).catch(()=>{});
  // #endregion

  while (true) {
    const { data: completedJob, error } = await pollAIJobWithFinalCheck(
      jobId,
      maxAttempts,
      initialIntervalMs,
      logPrefix
    );

--- ./src/lib/ai-jobs/types.ts ---
  success: boolean;
  error: any;
}> {
  try {
    // Import here to avoid circular dependency
    const { createEntityAttributesFromAutoTag } = await import(
      '../attributes'
    );

    // Create entity attributes
    const { errors } = await createEntityAttributesFromAutoTag(
    const { createEntityAttributesFromAutoTag } = await import(
      '../attributes'
    );

    // Create entity attributes
    const { errors } = await createEntityAttributesFromAutoTag(
      'wardrobe_item',
      wardrobeItemId,
      result.attributes
    );

    if (result.suggested_notes) {
      updates.description = result.suggested_notes;
    }

    if (Object.keys(updates).length > 0) {
      const { error: updateError } = await supabase
        .from('wardrobe_items')
        .update(updates)
        .eq('id', wardrobeItemId);

      if (updateError) {

  return createAIJob(userId, 'body_shot_generate', input);
}

/**
 * Get active outfit_render job for an outfit
 */
export async function getActiveOutfitRenderJob(
  outfitId: string,
  userId: string
): Promise<QueryResult<AIJob>> {
 */
export async function getActiveOutfitRenderJob(
  outfitId: string,
  userId: string
): Promise<QueryResult<AIJob>> {
  return getActiveJob(userId, 'outfit_render', (job) => {
    try {
      const input = job.input as any;
      return input?.outfit_id === outfitId;
    } catch {
      return false;
    }
  });
}

/**
 * Get recently completed outfit_render job for an outfit
 */
export async function getRecentOutfitRenderJob(
  outfitId: string,
  userId: string
): Promise<QueryResult<AIJob>> {
 */
export async function getRecentOutfitRenderJob(
  outfitId: string,
  userId: string
): Promise<QueryResult<AIJob>> {
  return getRecentJob(userId, 'outfit_render', (job) => {
    try {
      const input = job.input as any;
      return input?.outfit_id === outfitId;
    } catch {
      return false;

--- ./src/lib/ai-jobs/core.ts ---
    | 'product_shot'
    | 'headshot_generate'
    | 'body_shot_generate'
    | 'outfit_suggest'
    | 'reference_match'
    | 'outfit_render'
    | 'outfit_mannequin'
    | 'lookbook_generate'
    | 'batch';
  input: any;
  status: 'queued' | 'running' | 'succeeded' | 'failed';
  error?: string;
  created_at: string;
  updated_at: string;
}

// Policy block patterns for Gemini errors
const POLICY_BLOCK_PATTERNS = [
  'safety',
  'blocked',
  'policy',
  'harassment',
  userId: string,
  jobType: AIJob['job_type'],
  input: any
): Promise<QueryResult<AIJob>> {
  try {
    const { data, error } = await supabase
      .from('ai_jobs')
      .insert({
        owner_user_id: userId,
        job_type: jobType,
        input,
/**
 * Get AI job by ID
 */
export async function getAIJob(jobId: string): Promise<QueryResult<AIJob>> {
  try {
    const { data, error } = await supabase
      .from('ai_jobs')
      .select('*')
      .eq('id', jobId)
      .maybeSingle();

    return { data: null, error };
  }
}

/**
 * Check if an error message indicates a Gemini policy block
 */
export function isGeminiPolicyBlockError(message?: string | null): boolean {
  if (!message) return false;
  const normalized = message.toLowerCase();
  return POLICY_BLOCK_PATTERNS.some((pattern) => normalized.includes(pattern));
}

/**
 * Check if an error message indicates a Gemini policy block
 */
export function isGeminiPolicyBlockError(message?: string | null): boolean {
  if (!message) return false;
  const normalized = message.toLowerCase();
  return POLICY_BLOCK_PATTERNS.some((pattern) => normalized.includes(pattern));
}

  userId: string,
  jobType: AIJob['job_type'],
  filterFn: (job: AIJob) => boolean
): Promise<QueryResult<AIJob>> {
  try {
    const { data, error } = await supabase
      .from('ai_jobs')
      .select('*')
      .eq('job_type', jobType)
      .in('status', ['queued', 'running'])
      .eq('owner_user_id', userId)
  filterFn: (job: AIJob) => boolean
): Promise<QueryResult<AIJob>> {
  try {
    const sixtySecondsAgo = new Date(Date.now() - 60 * 1000).toISOString();

    const { data, error } = await supabase
      .from('ai_jobs')
      .select('*')
      .eq('job_type', jobType)
      .in('status', ['succeeded', 'failed'])
      .eq('owner_user_id', userId)

--- ./src/lib/ai-jobs/index.ts ---
// Re-export from core
export {
  type AIJob,
  createAIJob,
  getAIJob,
  isGeminiPolicyBlockError,
  getActiveJob,
  getRecentJob,
  getOutfitRenderItemLimit,
} from './core';


--- ./src/lib/ai-jobs/execution.ts ---

  try {
    // Get current session for auth token
    const {
      data: { session },
    } = await supabase.auth.getSession();
    
    // #region agent log
    fetch('http://127.0.0.1:7243/ingest/3a269559-16ce-41e5-879a-1155393947c5',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'execution.ts:18',message:'triggerAIJobExecution session check',data:{jobId,hasSession:!!session},timestamp:Date.now(),sessionId:'debug-session',runId:'run1',hypothesisId:'D'})}).catch(()=>{});
    // #endregion

        // #region agent log
        fetch('http://127.0.0.1:7243/ingest/3a269559-16ce-41e5-879a-1155393947c5',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'execution.ts:78',message:'triggerAIJobExecution fetch response',data:{jobId,status:response.status,statusText:response.statusText,ok:response.ok},timestamp:Date.now(),sessionId:'debug-session',runId:'run1',hypothesisId:'D'})}).catch(()=>{});
        // #endregion

        if (!response.ok) {
          const responseText = await response
            .text()
            .catch(() => 'could not read response');
          console.warn('[AIJobs] Function trigger returned non-OK response', {
            status: response.status,
            statusText: response.statusText,
  data: { jobId: string } | null;
  error: any;
}> {
  try {
    // Import here to avoid circular dependency
    const { createAIJob } = await import('./core');

    const { data: job, error } = await createAIJob(userId, jobType, input);

    if (error || !job) {
      return { data: null, error };
}> {
  try {
    // Import here to avoid circular dependency
    const { createAIJob } = await import('./core');

    const { data: job, error } = await createAIJob(userId, jobType, input);

    if (error || !job) {
      return { data: null, error };
    }

    if (error || !job) {
      return { data: null, error };
    }

    // Trigger execution
    const { error: triggerError } = await triggerAIJobExecution(job.id);

    if (triggerError) {
      console.warn(
        '[AIJobs] Failed to trigger job execution, but job was created:',
        triggerError

--- ./src/lib/utils/validation.ts ---
export async function verifyWardrobeItemOwnership(
  itemId: string,
  userId: string
): Promise<{ isOwner: boolean; error: any }> {
  try {
    const { data, error } = await supabase
      .from('wardrobe_items')
      .select('id')
      .eq('id', itemId)
      .eq('owner_user_id', userId)
      .single();
export async function verifyOutfitOwnership(
  outfitId: string,
  userId: string
): Promise<{ isOwner: boolean; error: any }> {
  try {
    const { data, error } = await supabase
      .from('outfits')
      .select('id')
      .eq('id', outfitId)
      .eq('owner_user_id', userId)
      .single();
export async function verifyLookbookOwnership(
  lookbookId: string,
  userId: string
): Promise<{ isOwner: boolean; error: any }> {
  try {
    const { data, error } = await supabase
      .from('lookbooks')
      .select('id')
      .eq('id', lookbookId)
      .eq('owner_user_id', userId)
      .single();
export async function verifyOriginalImages(
  imageIds: string[],
  wardrobeItemId: string
): Promise<{ valid: boolean; error: any }> {
  try {
    const { data: itemImages, error } = await supabase
      .from('wardrobe_item_images')
      .select('image_id, type')
      .in('image_id', imageIds)
      .eq('wardrobe_item_id', wardrobeItemId);

        ? 'wardrobe_items'
        : entityType === 'outfit'
        ? 'outfits'
        : 'lookbooks';

    const { data, error } = await supabase
      .from(table)
      .select('owner_user_id, visibility, visibility_override')
      .eq('id', entityId)
      .single();

      return { canAccess: false, error: null };
    }

    if (visibility === 'followers') {
      // Check if viewer follows owner
      const { data: followData } = await supabase
        .from('follows')
        .select('id')
        .eq('follower_user_id', viewerId)
        .eq('followed_user_id', data.owner_user_id)
        .eq('status', 'accepted')
export async function validatePostVisibility(
  postId: string,
  viewerId: string
): Promise<{ canView: boolean; error: any }> {
  try {
    const { data: post, error } = await supabase
      .from('posts')
      .select('owner_user_id, visibility, entity_type, entity_id')
      .eq('id', postId)
      .single();

    if (post.visibility === 'private') {
      return { canView: false, error: null };
    }

    if (post.visibility === 'followers') {
      const { data: followData } = await supabase
        .from('follows')
        .select('id')
        .eq('follower_user_id', viewerId)
        .eq('followed_user_id', post.owner_user_id)
        .eq('status', 'accepted')
      return { canView: !!followData, error: null };
    }

    // Check if visibility is 'inherit' - check entity visibility
    if (post.visibility === 'inherit') {
      const res = await canAccessEntity(post.entity_type, post.entity_id, viewerId);
      return { canView: res.canAccess, error: res.error };
    }

    return { canView: false, error: null };
  } catch (error: any) {

--- ./src/lib/utils/image-helpers.ts ---
export async function uriToBlob(uri: string, mimeType: string): Promise<Blob> {
  console.log('[uriToBlob] Converting URI:', { uri: uri.substring(0, 50), mimeType });
  
  if (uri.startsWith('file://') && Platform.OS !== 'web') {
    console.log('[uriToBlob] Using FileSystem for file:// URI');
    const base64 = await FileSystem.readAsStringAsync(uri, {
      encoding: 'base64' as any,
    });
    
    const dataUrl = `data:${mimeType};base64,${base64}`;
    const response = await fetch(dataUrl);
    const base64 = await FileSystem.readAsStringAsync(uri, {
      encoding: 'base64' as any,
    });
    
    const dataUrl = `data:${mimeType};base64,${base64}`;
    const response = await fetch(dataUrl);
    return await response.blob();
  }
  
  console.log('[uriToBlob] Using fetch for URI');
  const response = await fetch(uri);
      encoding: 'base64' as any,
    });
    
    const dataUrl = `data:${mimeType};base64,${base64}`;
    const response = await fetch(dataUrl);
    return await response.blob();
  }
  
  console.log('[uriToBlob] Using fetch for URI');
  const response = await fetch(uri);
  const blob = await response.blob();
    const response = await fetch(dataUrl);
    return await response.blob();
  }
  
  console.log('[uriToBlob] Using fetch for URI');
  const response = await fetch(uri);
  const blob = await response.blob();
  console.log('[uriToBlob] Created blob:', { size: blob.size, type: blob.type });
  return blob;
}

    return await response.blob();
  }
  
  console.log('[uriToBlob] Using fetch for URI');
  const response = await fetch(uri);
  const blob = await response.blob();
  console.log('[uriToBlob] Created blob:', { size: blob.size, type: blob.type });
  return blob;
}

/**
    });

    // Convert Blob to ArrayBuffer to ensure raw binary upload
    // This prevents the multipart form data issue
    console.log('[uploadImageToStorage] Converting blob to ArrayBuffer...');
    const arrayBuffer = await file.arrayBuffer();
    console.log('[uploadImageToStorage] ArrayBuffer size:', arrayBuffer.byteLength);
    
    // Verify it's a valid image
    const bytes = new Uint8Array(arrayBuffer);
    const isJPEG = bytes[0] === 0xFF && bytes[1] === 0xD8;
      };
    }

    // Upload as ArrayBuffer (raw bytes)
    console.log('[uploadImageToStorage] Uploading to Supabase...');
    const { data, error } = await supabase.storage
      .from(bucket)
      .upload(filePath, arrayBuffer, {
        cacheControl: '3600',
        upsert: false,
        contentType: file.type || 'image/webp',
): Promise<{
  data: { id: string } | null;
  error: any;
}> {
  try {
    const { data, error } = await supabase
      .from('images')
      .insert({
        owner_user_id: userId,
        storage_bucket: bucket,
        storage_key: storagePath,
): Promise<{
  data: { imageId: string; path: string; url: string } | null;
  error: any;
}> {
  try {
    const uploadResult = await uploadImageToStorage(userId, file, fileName);
    if (uploadResult.error || !uploadResult.data) {
      return { data: null, error: uploadResult.error };
    }

    const imageResult = await createImageRecord(
    const uploadResult = await uploadImageToStorage(userId, file, fileName);
    if (uploadResult.error || !uploadResult.data) {
      return { data: null, error: uploadResult.error };
    }

    const imageResult = await createImageRecord(
      userId,
      uploadResult.data.path,
      file.type || 'image/webp',
      source
    );
export async function deleteImage(
  imageId: string,
  userId: string
): Promise<{ error: any }> {
  try {
    const { data: image } = await supabase
      .from('images')
      .select('storage_bucket, storage_key')
      .eq('id', imageId)
      .eq('owner_user_id', userId)
      .single();

    if (!image) {
      return { error: new Error('Image not found or access denied') };
    }

    const { error: storageError } = await supabase.storage
      .from(image.storage_bucket)
      .remove([image.storage_key]);

    if (storageError) {
      console.warn('Failed to delete from storage:', storageError);

    if (storageError) {
      console.warn('Failed to delete from storage:', storageError);
    }

    const { error: dbError } = await supabase
      .from('images')
      .delete()
      .eq('id', imageId)
      .eq('owner_user_id', userId);

  const imageIds: string[] = [];
  const errors: any[] = [];

  for (const file of files) {
    try {
      let blob = await uriToBlob(file.uri, file.type);
      
      // Compress on web platform before upload
      if (Platform.OS === 'web' && source === 'upload') {
        try {
          // Capture original file metrics before compression
          // Start compression timer
          const compressionStartTime = performance.now();
          
          // Convert Blob to File for compression
          const fileObj = new File([blob], file.name, { type: file.type });
          const compressedFile = await compressImageFile(fileObj);
          
          // Calculate compression metrics
          const compressionEndTime = performance.now();
          const compressionTimeMs = (compressionEndTime - compressionStartTime).toFixed(0);
          const compressedSizeBytes = compressedFile.size;
          console.warn('[batchUploadImages] Compression failed, using original:', compressionError);
          // Continue with original blob if compression fails
        }
      }
      
      const result = await uploadAndCreateImage(userId, blob, file.name, source);
      
      if (result.error || !result.data) {
        errors.push({ file: file.name, error: result.error });
      } else {
        imageIds.push(result.data.imageId);

--- ./src/lib/utils/supabase-helpers.ts ---
): Promise<QueryResult<T>> {
  try {
    let query = supabase.from(table).select(selectQuery);
    query = applyFilters(query, filters);

    const { data, error } = await query.single();
    return { data: (data as T) ?? null, error };
  } catch (error: any) {
    return { data: null, error };
  }
}
    let query = supabase.from(table).select(selectQuery);

    query = applyFilters(query, options?.filters);
    query = applyOrderLimitOffset(query, options);

    const { data, error } = await query;
    return { data: ((data as T[]) ?? []) as T[], error };
  } catch (error: any) {
    return { data: [], error };
  }
}
    }

    query = applyFilters(query, options?.additionalFilters);
    query = applyOrderLimitOffset(query, options);

    const { data, error } = await query;
    return { data: ((data as T[]) ?? []) as T[], error };
  } catch (error: any) {
    return { data: [], error };
  }
}

--- ./src/lib/user/initialization.ts ---
    allow_external_sharing?: boolean;
  }
) {
  try {
    // Create user profile
    const { error: userError } = await supabase
      .from('users')
      .insert({
        id: userId,
        handle,
        display_name: displayName,
        throw userError;
      }
    }

    // Create user settings
    const { error: settingsError } = await supabase
      .from('user_settings')
      .insert({
        user_id: userId,
        account_privacy: settings?.account_privacy || 'public',
        search_visibility: settings?.search_visibility || 'visible',
        throw settingsError;
      }
    }

    // Create default wardrobe
    const { error: wardrobeError } = await supabase
      .from('wardrobes')
      .insert({
        owner_user_id: userId,
        title: 'My Wardrobe',
        visibility: settings?.default_visibility || 'followers',
export async function isUserProfileComplete(userId: string): Promise<boolean> {
  try {
    console.log('[isUserProfileComplete] Checking profile for user:', userId);
    
    // Check if user exists
    const { data: user, error: userError } = await supabase
      .from('users')
      .select('id')
      .eq('id', userId)
      .single();

    }

    console.log('[isUserProfileComplete] User found, checking settings...');

    // Check settings exist
    const { data: settings, error: settingsError } = await supabase
      .from('user_settings')
      .select('user_id')
      .eq('user_id', userId)
      .single();

    }

    console.log('[isUserProfileComplete] Settings found, checking wardrobe...');

    // Check if at least one wardrobe exists (user might have multiple)
    const { data: wardrobes, error: wardrobeError } = await supabase
      .from('wardrobes')
      .select('id')
      .eq('owner_user_id', userId)
      .limit(1);


--- ./src/lib/user/follows.ts ---
  try {
    if (followerId === followedId) {
      return { error: new Error('Cannot follow yourself') };
    }

    const { error } = await supabase
      .from('follows')
      .insert({
        follower_user_id: followerId,
        followed_user_id: followedId,
        status: 'requested', // Database trigger will auto-accept for public accounts
export async function unfollowUser(
  followerId: string,
  followedId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('follows')
      .delete()
      .eq('follower_user_id', followerId)
      .eq('followed_user_id', followedId);

export async function isFollowing(
  followerId: string,
  followedId: string
): Promise<{ isFollowing: boolean; status: 'requested' | 'accepted' | 'blocked' | null }> {
  try {
    const { data, error } = await supabase
      .from('follows')
      .select('status')
      .eq('follower_user_id', followerId)
      .eq('followed_user_id', followedId)
      .single();
    };
  }>;
  error: any;
}> {
  try {
    const { data, error } = await supabase
      .from('follows')
      .select('*, follower:users!follower_user_id(id, handle, display_name)')
      .eq('followed_user_id', userId)
      .eq('status', 'accepted')
      .order('created_at', { ascending: false })
    };
  }>;
  error: any;
}> {
  try {
    const { data, error } = await supabase
      .from('follows')
      .select('*, followed:users!followed_user_id(id, handle, display_name)')
      .eq('follower_user_id', userId)
      .eq('status', 'accepted')
      .order('created_at', { ascending: false })
    };
  }>;
  error: any;
}> {
  try {
    const { data, error } = await supabase
      .from('follows')
      .select('*, follower:users!follower_user_id(id, handle, display_name)')
      .eq('followed_user_id', userId)
      .eq('status', 'requested')
      .order('created_at', { ascending: false });
export async function acceptFollowRequest(
  followerId: string,
  followedId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('follows')
      .update({ status: 'accepted' })
      .eq('follower_user_id', followerId)
      .eq('followed_user_id', followedId)
      .eq('status', 'requested');
export async function rejectFollowRequest(
  followerId: string,
  followedId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('follows')
      .delete()
      .eq('follower_user_id', followerId)
      .eq('followed_user_id', followedId)
      .eq('status', 'requested');

--- ./src/lib/user/profile.ts ---
 */
export async function getUserProfile(userId: string): Promise<{
  data: { handle: string; display_name: string } | null;
  error: any;
}> {
  const { data, error } = await supabase
    .from('users')
    .select('handle, display_name')
    .eq('id', userId)
    .single();

 */
export async function updateUserProfile(
  userId: string,
  updates: { handle?: string; display_name?: string }
): Promise<{ error: any }> {
  const { error } = await supabase
    .from('users')
    .update({
      ...updates,
      updated_at: new Date().toISOString(),
    })
      return { data: [], error: null };
    }

    const searchTerm = `%${query.toLowerCase()}%`;
    
    const { data, error } = await supabase
      .from('users')
      .select('id, handle, display_name')
      .or(`handle.ilike.${searchTerm},display_name.ilike.${searchTerm}`)
      .limit(limit);

  } | null;
  error: any;
}> {
  try {
    // Get user basic info
    const { data: user, error: userError } = await supabase
      .from('users')
      .select('id, handle, display_name, created_at')
      .eq('id', userId)
      .single();


    if (userError) throw userError;
    if (!user) return { data: null, error: null };

    // Get user settings with headshot image
    const { data: settings } = await supabase
      .from('user_settings')
      .select(`
        headshot_image_id,
        headshot_image:headshot_image_id(storage_bucket, storage_key)
      `)
        .getPublicUrl(storage_key);
      headshotUrl = urlData?.publicUrl;
    }

    // Get stats
    const [postsCount, followersCount, followingCount] = await Promise.all([
      supabase
        .from('posts')
        .select('*', { count: 'exact', head: true })
        .eq('owner_user_id', userId),
      supabase

--- ./src/lib/engagement/comments.ts ---
): Promise<{
  data: Comment | null;
  error: any;
}> {
  try {
    const { data: comment, error } = await supabase
      .from('comments')
      .insert({
        user_id: userId,
        entity_type: entityType,
        entity_id: entityId,
): Promise<{
  data: Comment[];
  error: any;
}> {
  try {
    const { data: comments, error } = await supabase
      .from('comments')
      .select(
        `
        *,
        user:users(id, handle, display_name, avatar_url)
 */
export async function getCommentCount(
  entityType: 'post' | 'outfit' | 'lookbook' | 'feedback_thread',
  entityId: string
): Promise<number> {
  const { count } = await supabase
    .from('comments')
    .select('*', { count: 'exact', head: true })
    .eq('entity_type', entityType)
    .eq('entity_id', entityId)
    .is('deleted_at', null);
  commentId: string
): Promise<{
  error: any;
}> {
  try {
    const { error } = await supabase
      .from('comments')
      .update({ deleted_at: new Date().toISOString() })
      .eq('id', commentId)
      .eq('user_id', userId);

): Promise<{
  data: Comment | null;
  error: any;
}> {
  try {
    const { data: comment, error } = await supabase
      .from('comments')
      .update({
        body,
        updated_at: new Date().toISOString(),
      })
): Promise<{
  data: Comment[];
  error: any;
}> {
  try {
    const { data: replies, error } = await supabase
      .from('comments')
      .select(
        `
        *,
        user:users(id, handle, display_name, avatar_url)

--- ./src/lib/engagement/saves.ts ---
  data: Save | null;
  error: any;
}> {
  try {
    // Check if already saved
    const { data: existing } = await supabase
      .from('saves')
      .select('id')
      .eq('user_id', userId)
      .eq('entity_type', entityType)
      .eq('entity_id', entityId)
      .eq('entity_id', entityId)
      .single();

    if (existing) {
      // Already saved, return existing
      const { data: save } = await supabase
        .from('saves')
        .select('*')
        .eq('id', existing.id)
        .single();
      return { data: save, error: null };
        .single();
      return { data: save, error: null };
    }

    // Create new save
    const { data: save, error } = await supabase
      .from('saves')
      .insert({
        user_id: userId,
        entity_type: entityType,
        entity_id: entityId,
  entityId: string
): Promise<{
  error: any;
}> {
  try {
    const { error } = await supabase
      .from('saves')
      .delete()
      .eq('user_id', userId)
      .eq('entity_type', entityType)
      .eq('entity_id', entityId);
export async function hasSaved(
  userId: string,
  entityType: 'post' | 'outfit' | 'lookbook',
  entityId: string
): Promise<boolean> {
  const { data } = await supabase
    .from('saves')
    .select('id')
    .eq('user_id', userId)
    .eq('entity_type', entityType)
    .eq('entity_id', entityId)
 */
export async function getSaveCount(
  entityType: 'post' | 'outfit' | 'lookbook',
  entityId: string
): Promise<number> {
  const { count } = await supabase
    .from('saves')
    .select('*', { count: 'exact', head: true })
    .eq('entity_type', entityType)
    .eq('entity_id', entityId);


    if (entityType) {
      query = query.eq('entity_type', entityType);
    }

    const { data, error } = await query;

    if (error) {
      throw error;
    }


--- ./src/lib/engagement/likes.ts ---
  data: Like | null;
  error: any;
}> {
  try {
    // Check if already liked
    const { data: existing } = await supabase
      .from('likes')
      .select('id')
      .eq('user_id', userId)
      .eq('entity_type', entityType)
      .eq('entity_id', entityId)
      .eq('entity_id', entityId)
      .single();

    if (existing) {
      // Already liked, return existing
      const { data: like } = await supabase
        .from('likes')
        .select('*')
        .eq('id', existing.id)
        .single();
      return { data: like, error: null };
        .single();
      return { data: like, error: null };
    }

    // Create new like
    const { data: like, error } = await supabase
      .from('likes')
      .insert({
        user_id: userId,
        entity_type: entityType,
        entity_id: entityId,
  entityId: string
): Promise<{
  error: any;
}> {
  try {
    const { error } = await supabase
      .from('likes')
      .delete()
      .eq('user_id', userId)
      .eq('entity_type', entityType)
      .eq('entity_id', entityId);
export async function hasLiked(
  userId: string,
  entityType: 'post' | 'outfit' | 'lookbook',
  entityId: string
): Promise<boolean> {
  const { data } = await supabase
    .from('likes')
    .select('id')
    .eq('user_id', userId)
    .eq('entity_type', entityType)
    .eq('entity_id', entityId)
 */
export async function getLikeCount(
  entityType: 'post' | 'outfit' | 'lookbook',
  entityId: string
): Promise<number> {
  const { count } = await supabase
    .from('likes')
    .select('*', { count: 'exact', head: true })
    .eq('entity_type', entityType)
    .eq('entity_id', entityId);

): Promise<{
  data: Array<Like & { user?: { id: string; handle: string; display_name?: string } }>;
  error: any;
}> {
  try {
    const { data, error } = await supabase
      .from('likes')
      .select('*, user:users(id, handle, display_name)')
      .eq('entity_type', entityType)
      .eq('entity_id', entityId)
      .order('created_at', { ascending: false })

--- ./src/lib/attributes/entity-attributes.ts ---
): Promise<{
  data: EntityAttribute | null;
  error: any;
}> {
  // Get attribute definition
  const { data: definition, error: defError } = await supabase
    .from('attribute_definitions')
    .select('id')
    .eq('key', attributeKey)
    .single();

  if (defError || !definition) {
    return { data: null, error: defError || new Error('Attribute definition not found') };
  }

  // Get or create attribute value
  const { data: attrValue, error: valueError } = await getOrCreateAttributeValue(
    definition.id,
    value
  );

  if (valueError) {
  if (valueError) {
    return { data: null, error: valueError };
  }

  // Create entity attribute
  const { data: entityAttr, error: createError } = await supabase
    .from('entity_attributes')
    .insert({
      entity_type: entityType,
      entity_id: entityId,
      definition_id: definition.id,
  entityId: string
): Promise<{
  data: Array<EntityAttribute & { attribute_definitions?: AttributeDefinition; attribute_values?: AttributeValue }>;
  error: any;
}> {
  const { data, error } = await supabase
    .from('entity_attributes')
    .select('*, attribute_definitions(*), attribute_values(*)')
    .eq('entity_type', entityType)
    .eq('entity_id', entityId)
    .order('created_at', { ascending: true });
): Promise<{
  data: EntityAttribute | null;
  error: any;
}> {
  // Get the existing attribute to find its definition
  const { data: existing, error: fetchError } = await supabase
    .from('entity_attributes')
    .select('*, attribute_definitions(*)')
    .eq('id', attributeId)
    .single();

  }

  const definitionId = existing.definition_id;

  // Get or create the new attribute value
  const { data: attrValue, error: valueError } = await getOrCreateAttributeValue(
    definitionId,
    value
  );

  if (valueError) {
  if (valueError) {
    return { data: null, error: valueError };
  }

  // Update the entity attribute
  const { data: updated, error: updateError } = await supabase
    .from('entity_attributes')
    .update({
      value_id: attrValue?.id,
      raw_value: value.trim(),
      source: 'user', // Mark as user-edited
export async function deleteEntityAttribute(
  attributeId: string
): Promise<{
  error: any;
}> {
  const { error } = await supabase
    .from('entity_attributes')
    .delete()
    .eq('id', attributeId);

  return { error };
  const errors: any[] = [];
  let created = 0;

  for (const attr of attributes) {
    for (const val of attr.values) {
      const { error } = await createEntityAttribute(
        entityType,
        entityId,
        attr.key,
        val.value,
        val.confidence,

--- ./src/lib/attributes/definitions.ts ---
 */
export async function getAttributeDefinitions(): Promise<{
  data: AttributeDefinition[];
  error: any;
}> {
  const { data, error } = await supabase
    .from('attribute_definitions')
    .select('*')
    .order('key', { ascending: true });

  return { data: data || [], error };
 */
export async function getAttributeDefinitionByKey(key: string): Promise<{
  data: AttributeDefinition | null;
  error: any;
}> {
  const { data, error } = await supabase
    .from('attribute_definitions')
    .select('*')
    .eq('key', key)
    .single();

 */
export async function getAttributeDefinitionById(id: string): Promise<{
  data: AttributeDefinition | null;
  error: any;
}> {
  const { data, error } = await supabase
    .from('attribute_definitions')
    .select('*')
    .eq('id', id)
    .single();


--- ./src/lib/attributes/values.ts ---
 */
export async function getAttributeValues(definitionId: string): Promise<{
  data: AttributeValue[];
  error: any;
}> {
  const { data, error } = await supabase
    .from('attribute_values')
    .select('*')
    .eq('definition_id', definitionId)
    .order('value', { ascending: true });

}> {
  // Normalize value (lowercase, trim)
  const normalizedValue = value.toLowerCase().trim();

  // Try to find existing value
  const { data: existing, error: findError } = await supabase
    .from('attribute_values')
    .select('*')
    .eq('definition_id', definitionId)
    .or(`value.eq.${value},normalized_value.eq.${normalizedValue}`)
    .single();
  if (existing) {
    return { data: existing, error: null };
  }

  // Create new value
  const { data: newValue, error: createError } = await supabase
    .from('attribute_values')
    .insert({
      definition_id: definitionId,
      value: value.trim(),
      normalized_value: normalizedValue,
  data: AttributeValue | null;
  error: any;
}> {
  const normalizedValue = value.toLowerCase().trim();

  const { data, error } = await supabase
    .from('attribute_values')
    .insert({
      definition_id: definitionId,
      value: value.trim(),
      normalized_value: normalizedValue,

--- ./src/lib/outfits/items.ts ---
  try {
    let outfitId: string;

    if (outfitData.id) {
      // Update existing outfit
      const { data: updatedOutfit, error: updateError } = await supabase
        .from('outfits')
        .update({
          ...outfitData,
          updated_at: new Date().toISOString(),
        })
      }

      outfitId = outfitData.id;

      // Delete existing items
      await supabase.from('outfit_items').delete().eq('outfit_id', outfitId);
    } else {
      // Create new outfit
      const { data: newOutfit, error: createError } = await supabase
        .from('outfits')
        .insert({

      // Delete existing items
      await supabase.from('outfit_items').delete().eq('outfit_id', outfitId);
    } else {
      // Create new outfit
      const { data: newOutfit, error: createError } = await supabase
        .from('outfits')
        .insert({
          owner_user_id: userId,
          title: outfitData.title,
          notes: outfitData.notes,
      category_id: item.category_id || null,
      wardrobe_item_id: item.wardrobe_item_id,
      position: item.position ?? index,
    }));

    const { data: outfitItems, error: itemsError } = await supabase
      .from('outfit_items')
      .insert(outfitItemsData)
      .select();

    if (itemsError) {
    if (itemsError) {
      throw itemsError;
    }

    // Get full outfit
    const { data: fullOutfit } = await supabase
      .from('outfits')
      .select('*')
      .eq('id', outfitId)
      .single();

  data: OutfitItem | null;
  error: any;
}> {
  try {
    // Delete existing item in category if present (unique constraint)
    await supabase
      .from('outfit_items')
      .delete()
      .eq('outfit_id', outfitId)
      .eq('category_id', categoryId);

      .delete()
      .eq('outfit_id', outfitId)
      .eq('category_id', categoryId);

    // Insert new item
    const { data, error } = await supabase
      .from('outfit_items')
      .insert({
        outfit_id: outfitId,
        category_id: categoryId,
        wardrobe_item_id: wardrobeItemId,
 */
export async function removeItemFromOutfit(
  outfitId: string,
  categoryId: string
): Promise<{ error: any }> {
  const { error } = await supabase
    .from('outfit_items')
    .delete()
    .eq('outfit_id', outfitId)
    .eq('category_id', categoryId);

 */
export async function updateOutfitItemPosition(
  outfitItemId: string,
  position: number
): Promise<{ error: any }> {
  const { error } = await supabase
    .from('outfit_items')
    .update({ position })
    .eq('id', outfitItemId);

  return { error };
  itemPositions: Array<{ id: string; position: number }>
): Promise<{ error: any }> {
  try {
    // Update each item's position
    for (const item of itemPositions) {
      const { error } = await supabase
        .from('outfit_items')
        .update({ position: item.position })
        .eq('id', item.id)
        .eq('outfit_id', outfitId);


--- ./src/lib/outfits/ratings.ts ---

/**
 * Calculate rating for an outfit based on engagement metrics
 */
export async function calculateOutfitRating(outfitId: string): Promise<number> {
  const [likes, comments, saves] = await Promise.all([
    getLikeCount('outfit', outfitId),
    getCommentCount('outfit', outfitId),
    getSaveCount('outfit', outfitId),
  ]);

export async function calculateOutfitRatings(outfitIds: string[]): Promise<Map<string, number>> {
  const ratingMap = new Map<string, number>();
  
  // Calculate all ratings in parallel
  const ratingPromises = outfitIds.map(async (id) => {
    const rating = await calculateOutfitRating(id);
    return { id, rating };
  });
  
  const results = await Promise.all(ratingPromises);
  results.forEach(({ id, rating }) => {
  const ratingPromises = outfitIds.map(async (id) => {
    const rating = await calculateOutfitRating(id);
    return { id, rating };
  });
  
  const results = await Promise.all(ratingPromises);
  results.forEach(({ id, rating }) => {
    ratingMap.set(id, rating);
  });
  
  return ratingMap;
  likes: number;
  comments: number;
  saves: number;
  rating: number;
}> {
  const [likes, comments, saves] = await Promise.all([
    getLikeCount('outfit', outfitId),
    getCommentCount('outfit', outfitId),
    getSaveCount('outfit', outfitId),
  ]);

 */
export async function getTopRatedOutfits(
  outfitIds: string[],
  limit: number = 10
): Promise<Array<{ id: string; rating: number }>> {
  const ratingMap = await calculateOutfitRatings(outfitIds);
  
  const outfitsWithRatings = outfitIds
    .map(id => ({ id, rating: ratingMap.get(id) || 0 }))
    .filter(item => item.rating > 0);


--- ./src/lib/outfits/core.ts ---
      return { data: [], error: null };
    }

    const searchTerm = `%${query.toLowerCase()}%`;
    
    const { data, error } = await supabase
      .from('outfits')
      .select('id, owner_user_id, title, visibility, created_at, owner:users!owner_user_id(handle, display_name)')
      .or(`title.ilike.${searchTerm},notes.ilike.${searchTerm}`)
      .is('archived_at', null)
      .in('visibility', ['public', 'followers'])
    owner?: { handle: string; display_name: string };
  }>;
  error: any;
}> {
  try {
    const { data, error } = await supabase
      .from('outfits')
      .select('id, owner_user_id, title, visibility, created_at, owner:users!owner_user_id(handle, display_name)')
      .eq('visibility', 'public')
      .is('archived_at', null)
      .order('created_at', { ascending: false })
 */
export async function getUserOutfits(userId: string): Promise<{
  data: Outfit[];
  error: any;
}> {
  const { data, error } = await supabase
    .from('outfits')
    .select('*')
    .eq('owner_user_id', userId)
    .is('archived_at', null)
    .order('created_at', { ascending: false });
  } else {
    // Default to date desc
    query = query.order('created_at', { ascending: false });
  }

  const { data: outfits, error } = await query;

  if (error) {
    return { data: [], error };
  }

  const outfitsList = (outfits || []) as Outfit[];

  // If sorting by rating, calculate ratings and sort
  if (options?.sortBy === 'rating') {
    const outfitIds = outfitsList.map((o) => o.id);
    const ratingMap = await calculateOutfitRatings(outfitIds);
    
    const outfitsWithRatings: OutfitWithRating[] = outfitsList.map((outfit) => ({
      ...outfit,
      rating: ratingMap.get(outfit.id) || 0,
    }));
export async function getOutfit(outfitId: string): Promise<{
  data: { outfit: Outfit; items: any[]; coverImage?: any } | null;
  error: any;
}> {
  // Get outfit with cover_image
  const { data: outfit, error: outfitError } = await supabase
    .from('outfits')
    .select('*, cover_image:images!cover_image_id(*)')
    .eq('id', outfitId)
    .single();

  if (outfitError || !outfit) {
    return { data: null, error: outfitError };
  }

  // Get outfit items
  const { data: items, error: itemsError } = await supabase
    .from('outfit_items')
    .select('*')
    .eq('outfit_id', outfitId)
    .order('position', { ascending: true });

export async function getOutfitWithDetails(outfitId: string, userId: string): Promise<{
  data: { outfit: Outfit; items: any[]; coverImage?: any } | null;
  error: any;
}> {
  // Get outfit with cover_image
  const { data: outfit, error: outfitError } = await supabase
    .from('outfits')
    .select('*, cover_image:images!cover_image_id(*)')
    .eq('id', outfitId)
    .single();

  if (outfitError || !outfit) {
    return { data: null, error: outfitError };
  }

  // Use the performant database function to get items with wardrobe details
  const { data, error } = await supabase
  .rpc('get_outfit_items_with_details', {
    p_outfit_id: outfitId,
    p_viewer_id: userId,
  });

 */
export async function deleteOutfit(
  userId: string,
  outfitId: string
): Promise<{ error: any }> {
  const { error } = await supabase
    .from('outfits')
    .update({ archived_at: new Date().toISOString() })
    .eq('id', outfitId)
    .eq('owner_user_id', userId);


--- ./src/lib/import/outfit-import.ts ---
        
        if (outfit.items && outfit.items.length > 0) {
          for (const oldItemId of outfit.items) {
            const newItemId = itemIdMap.get(oldItemId);
            if (newItemId) {
              const { data: item } = await supabase
                .from('wardrobe_items')
                .select('category_id')
                .eq('id', newItemId)
                .single();
              
              }
            }
          }
        }

        const { error: createError } = await saveOutfit(
          userId,
          {
            title: outfit.name || `Imported Outfit ${outfit.id}`,
          },
          outfitItems

--- ./src/lib/import/wardrobe-import.ts ---
import { supabase } from '../supabase';
import { getDefaultWardrobeId, createWardrobeItem } from '../wardrobe';
import type { LocalStorageWardrobeItem } from './reader';

async function findCategoryId(categoryName: string): Promise<string | null> {
  const { data: categories } = await supabase
    .from('wardrobe_categories')
    .select('id, name');
  
  if (!categories) return null;
  
): Promise<{
  data: { imported: number; errors: any[] };
  error: any;
}> {
  try {
    const { data: wardrobeId } = await getDefaultWardrobeId(userId);
    if (!wardrobeId) {
      throw new Error('Wardrobe not found');
    }

    const errors: any[] = [];

    for (let i = 0; i < wardrobeItems.length; i++) {
      const item = wardrobeItems[i];
      
      try {
        const categoryId = await findCategoryId(item.category);
        if (!categoryId) {
          errors.push({ item: item.name, error: 'Category not found' });
          continue;
        }

          uri: base64WithPrefix,
          type: 'image/png',
          name: `${item.name || `item_${item.id}`}.png`,
        }];

        const { error: createError } = await createWardrobeItem(
          userId,
          wardrobeId,
          {
            title: item.name || `Imported Item ${item.id}`,
            description: item.tags?.join(', ') || undefined,

--- ./src/lib/notifications/core.ts ---
): Promise<{
  data: Notification[];
  error: any;
}> {
  try {
    const { data: notifications, error } = await supabase
      .from('notifications')
      .select(`
        *,
        actor:actor_user_id(id, handle, display_name, avatar_url)
      `)
      throw error;
    }

    // Fetch entity data in batches
    if (notifications && notifications.length > 0) {
      await enrichNotificationsWithEntityData(notifications);
    }

    return { data: (notifications as any) || [], error: null };
  } catch (error: any) {
    return { data: [], error };

/**
 * Get count of unread notifications
 */
export async function getUnreadCount(userId: string): Promise<number> {
  const { count } = await supabase
    .from('notifications')
    .select('*', { count: 'exact', head: true })
    .eq('recipient_user_id', userId)
    .eq('is_read', false);

export async function markAsRead(
  userId: string,
  notificationId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('notifications')
      .update({ is_read: true })
      .eq('id', notificationId)
      .eq('recipient_user_id', userId);

/**
 * Mark all notifications as read
 */
export async function markAllAsRead(userId: string): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('notifications')
      .update({ is_read: true })
      .eq('recipient_user_id', userId)
      .eq('is_read', false);

export async function deleteNotification(
  userId: string,
  notificationId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('notifications')
      .delete()
      .eq('id', notificationId)
      .eq('recipient_user_id', userId);


--- ./src/lib/notifications/realtime.ts ---
        schema: 'public',
        table: 'notifications',
        filter: `recipient_user_id=eq.${userId}`,
      },
      async (payload) => {
        const { data } = await supabase
          .from('notifications')
          .select(`
            *,
            actor:actor_user_id(id, handle, display_name, avatar_url)
          `)

--- ./src/lib/notifications/enrichment.ts ---
    .filter((n) => n.entity_type === 'lookbook' && n.entity_id)
    .map((n) => n.entity_id!);

  // Batch fetch posts
  if (postIds.length > 0) {
    await enrichWithPosts(notifications, postIds);
  }

  // Batch fetch outfits
  if (outfitIds.length > 0) {
    await enrichWithOutfits(notifications, outfitIds);
    await enrichWithPosts(notifications, postIds);
  }

  // Batch fetch outfits
  if (outfitIds.length > 0) {
    await enrichWithOutfits(notifications, outfitIds);
  }

  // Batch fetch lookbooks
  if (lookbookIds.length > 0) {
    await enrichWithLookbooks(notifications, lookbookIds);
    await enrichWithOutfits(notifications, outfitIds);
  }

  // Batch fetch lookbooks
  if (lookbookIds.length > 0) {
    await enrichWithLookbooks(notifications, lookbookIds);
  }
}

/**
 * Enrich notifications with post data

/**
 * Enrich notifications with post data
 */
export async function enrichWithPosts(notifications: any[], postIds: string[]): Promise<void> {
  const { data: posts } = await supabase
    .from('posts')
    .select('id, entity_type, entity_id')
    .in('id', postIds);

  if (!posts) return;
  const postOutfitIds = posts.filter((p) => p.entity_type === 'outfit').map((p) => p.entity_id);
  const postLookbookIds = posts.filter((p) => p.entity_type === 'lookbook').map((p) => p.entity_id);

  // Fetch outfits for posts
  if (postOutfitIds.length > 0) {
    const { data: outfits } = await supabase
      .from('outfits')
      .select('id, cover_image_id, cover_image:cover_image_id(storage_bucket, storage_key)')
      .in('id', postOutfitIds);

    if (outfits) {
    }
  }

  // Fetch lookbooks for posts
  if (postLookbookIds.length > 0) {
    const { data: lookbooks } = await supabase
      .from('lookbooks')
      .select('id, cover_image_id, cover_image:cover_image_id(storage_bucket, storage_key)')
      .in('id', postLookbookIds);

    if (lookbooks) {

    if (lookbooks) {
      // For lookbooks without cover images, fetch first outfit's image
      const lookbooksNeedingFallback = lookbooks.filter((lb) => !lb.cover_image_id);
      if (lookbooksNeedingFallback.length > 0) {
        const { data: lookbookOutfits } = await supabase
          .from('lookbook_outfits')
          .select(`
            lookbook_id,
            outfit:outfit_id(
              id,

/**
 * Enrich notifications with outfit data
 */
export async function enrichWithOutfits(notifications: any[], outfitIds: string[]): Promise<void> {
  const { data: outfits } = await supabase
    .from('outfits')
    .select('id, cover_image_id, cover_image:cover_image_id(storage_bucket, storage_key)')
    .in('id', outfitIds);

  if (outfits) {
 */
export async function enrichWithLookbooks(
  notifications: any[],
  lookbookIds: string[]
): Promise<void> {
  const { data: lookbooks } = await supabase
    .from('lookbooks')
    .select('id, cover_image_id, cover_image:cover_image_id(storage_bucket, storage_key)')
    .in('id', lookbookIds);

  if (!lookbooks) return;
  if (!lookbooks) return;

  // For lookbooks without cover images, fetch first outfit's image
  const lookbooksNeedingFallback = lookbooks.filter((lb) => !lb.cover_image_id);
  if (lookbooksNeedingFallback.length > 0) {
    const { data: lookbookOutfits } = await supabase
      .from('lookbook_outfits')
      .select(`
        lookbook_id,
        outfit:outfit_id(
          id,

--- ./src/lib/bundles/groups.ts ---
): Promise<{
  data: BundleGroup | null;
  error: any;
}> {
  try {
    const { data: group, error: groupError } = await supabase
      .from('bundle_groups')
      .insert({
        bundle_id: bundleId,
        title: groupData.title,
        is_required: groupData.is_required,
        group_id: group.id,
        wardrobe_item_id: item.wardrobe_item_id,
        quantity: item.quantity || 1,
      }));

      const { error: itemsError } = await supabase
        .from('bundle_group_items')
        .insert(groupItemsData);

      if (itemsError) {
        throw itemsError;

--- ./src/lib/bundles/core.ts ---
export async function getOutfitBundles(outfitId: string): Promise<{
  data: any[];
  error: any;
}> {
  try {
    const { data: bundles, error } = await supabase
      .from('outfit_bundles')
      .select('*, bundle_groups(*, bundle_group_items(*))')
      .eq('outfit_id', outfitId)
      .eq('is_active', true)
      .order('created_at', { ascending: false });
export async function getUserOutfitBundles(userId: string): Promise<{
  data: any[];
  error: any;
}> {
  try {
    const { data: bundles, error } = await supabase
      .from('outfit_bundles')
      .select('*, bundle_groups(*, bundle_group_items(*)), outfit:outfits(id, title)')
      .eq('seller_user_id', userId)
      .order('created_at', { ascending: false });

export async function getOutfitBundle(bundleId: string): Promise<{
  data: any | null;
  error: any;
}> {
  try {
    const { data: bundle, error } = await supabase
      .from('outfit_bundles')
      .select('*, bundle_groups(*, bundle_group_items(*)), outfit:outfits(id, title)')
      .eq('id', bundleId)
      .single();

      }>;
    }>;
  }
): Promise<{ data: any | null; error: any }> {
  try {
    const { data: outfit, error: outfitError } = await supabase
      .from('outfits')
      .select('id, owner_user_id')
      .eq('id', outfitId)
      .eq('owner_user_id', userId)
      .single();

    if (outfitError || !outfit) {
      throw new Error('Outfit not found or access denied');
    }

    const { data: bundle, error: bundleError } = await supabase
      .from('outfit_bundles')
      .insert({
        outfit_id: outfitId,
        seller_user_id: userId,
        bundle_price: bundleData.bundle_price,
      .single();

    if (bundleError) throw bundleError;

    for (const groupData of bundleData.groups) {
      const { data: group, error: groupError } = await supabase
        .from('bundle_groups')
        .insert({
          bundle_id: bundle.id,
          title: groupData.title,
          is_required: groupData.is_required,
          group_id: group.id,
          wardrobe_item_id: item.wardrobe_item_id,
          quantity: item.quantity || 1,
        }));

        const { error: itemsError } = await supabase
          .from('bundle_group_items')
          .insert(groupItemsData);

        if (itemsError) throw itemsError;
      }

        if (itemsError) throw itemsError;
      }
    }

    const { data: fullBundle } = await getOutfitBundle(bundle.id);
    return { data: fullBundle, error: null };
  } catch (error: any) {
    return { data: null, error };
  }
}
    sale_mode?: 'items_only' | 'bundle_only' | 'both';
    is_active?: boolean;
  }
): Promise<{ data: any | null; error: any }> {
  try {
    const { data: bundle, error } = await supabase
      .from('outfit_bundles')
      .update(bundleData)
      .eq('id', bundleId)
      .eq('seller_user_id', userId)
      .select()
      .eq('seller_user_id', userId)
      .select()
      .single();

    if (error) throw error;
    const { data: fullBundle } = await getOutfitBundle(bundleId);
    return { data: fullBundle, error: null };
  } catch (error: any) {
    return { data: null, error };
  }
}
export async function deleteOutfitBundle(
  userId: string,
  bundleId: string
): Promise<{ error: any }> {
  try {
    const { error } = await supabase
      .from('outfit_bundles')
      .delete()
      .eq('id', bundleId)
      .eq('seller_user_id', userId);

